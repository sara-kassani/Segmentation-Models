{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 17725123178752385632, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 9214062756\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 10912176626631037263\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras import layers, metrics, models, optimizers\n",
    "from keras.optimizers import Adam, RMSprop,SGD\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, concatenate, Flatten, Dense, Activation, Dropout, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Version 2.2.4\n",
      "tensorflow Version 1.9.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Keras Version\", keras.__version__)\n",
    "print(\"tensorflow Version\", tf.__version__)\n",
    "# print(\"dim_ordering:\", K.image_dim_ordering())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "img_rows, img_cols = 256, 256\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data_augmented/cvc300_train/'\n",
    "validation_dir = 'data_augmented/cvc300_validation/'\n",
    "test_dir = 'data_augmented/cvc300_test/'\n",
    "\n",
    "image_folder = 'images'\n",
    "masks_folder = 'masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "def SmallCNN(img_size):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, 3, activation='relu', padding='same', input_shape=(img_size, img_size, 3)))\n",
    "    model.add(Conv2D(32, 3, activation='relu', padding='same'))\n",
    "    model.add(Conv2D(1, 5, activation='sigmoid', padding='same'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26112 images belonging to 1 classes.\n",
      "Found 26112 images belonging to 1 classes.\n",
      "Found 8704 images belonging to 1 classes.\n",
      "Found 8704 images belonging to 1 classes.\n",
      "Found 28 images belonging to 1 classes.\n",
      "Found 28 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "seed = 1142\n",
    "data_gen_args = dict(rescale=1. / 255, featurewise_center=True, featurewise_std_normalization=True)\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "masks_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "image_generator = image_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    classes = [image_folder],\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "mask_generator = masks_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    classes = [masks_folder],\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "validation_image_generator = image_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    classes = [image_folder],\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "validation_mask_generator = masks_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    classes = [masks_folder],\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "test_image_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    classes = [image_folder],\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "test_mask_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    classes = [masks_folder],\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = zip(image_generator, mask_generator)\n",
    "validation_generator = zip(validation_image_generator, validation_mask_generator)\n",
    "test_generator = zip(test_image_generator, test_mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_train_samples: 26112\n",
      "nb_validation_samples: 8704\n",
      "nb_test_samples: 28\n",
      "\n",
      "predict_size_train: 1632\n",
      "predict_size_validation: 544\n",
      "predict_size_test: 2\n"
     ]
    }
   ],
   "source": [
    "nb_train_samples = len(image_generator.filenames)\n",
    "nb_validation_samples = len(validation_image_generator.filenames)\n",
    "nb_test_samples = len(test_image_generator.filenames)\n",
    "\n",
    "predict_size_train = int(math.ceil(nb_train_samples / batch_size))\n",
    "predict_size_validation = int(math.ceil(nb_validation_samples / batch_size))\n",
    "predict_size_test = int(math.ceil(nb_test_samples / batch_size))\n",
    "\n",
    "print(\"nb_train_samples:\", nb_train_samples)\n",
    "print(\"nb_validation_samples:\", nb_validation_samples)\n",
    "print(\"nb_test_samples:\", nb_test_samples)\n",
    "\n",
    "print(\"\\npredict_size_train:\", predict_size_train)\n",
    "print(\"predict_size_validation:\", predict_size_validation)\n",
    "print(\"predict_size_test:\", predict_size_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 1.\n",
    "from keras import backend as K\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def Specificity(y_true, y_pred):\n",
    "    true_negatives = K.abs(y_pred)- K.abs(y_true)\n",
    "    return ((true_negatives+smooth)/(y_pred+ smooth))\n",
    "\n",
    "def Sensitivity(y_true, y_pred):\n",
    "    y_true = K.flatten(y_true)\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    return ((y_pred+smooth)/ (y_true+smooth))\n",
    "\n",
    "def Jaccard_index(y_true,y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return ((intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + smooth))\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "    Only computes a batch-wise average of precision.\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "    Only computes a batch-wise average of recall.\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def f1score(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "        Only computes a batch-wise average of recall.\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "        Only computes a batch-wise average of precision.\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 256, 256, 16)      448       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 256, 256, 32)      4640      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 256, 256, 1)       801       \n",
      "=================================================================\n",
      "Total params: 5,889\n",
      "Trainable params: 5,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = SmallCNN(img_size = 256)\n",
    "model.summary()\n",
    "adam_opt = Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(optimizer= adam_opt, loss=dice_coef_loss, \n",
    "              metrics=[dice_coef, 'acc','mse', Jaccard_index, Specificity, Sensitivity, precision, recall, f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 359s - loss: -1.2475e-01 - dice_coef: 0.1247 - acc: 0.4079 - mean_squared_error: 0.3587 - Jaccard_index: 0.0667 - Specificity: 0.9731 - Sensitivity: 1.4842 - precision: 0.0758 - recall: 0.7782 - f1score: 0.1375 - val_loss: -1.5984e-01 - val_dice_coef: 0.1598 - val_acc: 0.4998 - val_mean_squared_error: 0.2883 - val_Jaccard_index: 0.0873 - val_Specificity: 0.9648 - val_Sensitivity: 1.3732 - val_precision: 0.0944 - val_recall: 0.6313 - val_f1score: 0.1632\n",
      "Epoch 2/50\n",
      " - 356s - loss: -1.4226e-01 - dice_coef: 0.1423 - acc: 0.5214 - mean_squared_error: 0.2880 - Jaccard_index: 0.0768 - Specificity: 0.9710 - Sensitivity: 1.3572 - precision: 0.0839 - recall: 0.6409 - f1score: 0.1475 - val_loss: -1.6846e-01 - val_dice_coef: 0.1685 - val_acc: 0.5348 - val_mean_squared_error: 0.2782 - val_Jaccard_index: 0.0925 - val_Specificity: 0.9639 - val_Sensitivity: 1.3322 - val_precision: 0.1003 - val_recall: 0.6038 - val_f1score: 0.1708\n",
      "Epoch 3/50\n",
      " - 355s - loss: -1.4669e-01 - dice_coef: 0.1467 - acc: 0.5427 - mean_squared_error: 0.2807 - Jaccard_index: 0.0794 - Specificity: 0.9704 - Sensitivity: 1.3314 - precision: 0.0865 - recall: 0.6188 - f1score: 0.1509 - val_loss: -1.7089e-01 - val_dice_coef: 0.1709 - val_acc: 0.5577 - val_mean_squared_error: 0.2624 - val_Jaccard_index: 0.0940 - val_Specificity: 0.9629 - val_Sensitivity: 1.3044 - val_precision: 0.1025 - val_recall: 0.5701 - val_f1score: 0.1722\n",
      "Epoch 4/50\n",
      " - 355s - loss: -1.4902e-01 - dice_coef: 0.1490 - acc: 0.5498 - mean_squared_error: 0.2791 - Jaccard_index: 0.0808 - Specificity: 0.9701 - Sensitivity: 1.3212 - precision: 0.0881 - recall: 0.6125 - f1score: 0.1531 - val_loss: -1.7345e-01 - val_dice_coef: 0.1734 - val_acc: 0.5783 - val_mean_squared_error: 0.2450 - val_Jaccard_index: 0.0955 - val_Specificity: 0.9617 - val_Sensitivity: 1.2778 - val_precision: 0.1050 - val_recall: 0.5386 - val_f1score: 0.1742\n",
      "Epoch 5/50\n",
      " - 355s - loss: -1.4964e-01 - dice_coef: 0.1496 - acc: 0.5540 - mean_squared_error: 0.2794 - Jaccard_index: 0.0812 - Specificity: 0.9699 - Sensitivity: 1.3160 - precision: 0.0887 - recall: 0.6087 - f1score: 0.1538 - val_loss: -1.7610e-01 - val_dice_coef: 0.1761 - val_acc: 0.5916 - val_mean_squared_error: 0.2361 - val_Jaccard_index: 0.0972 - val_Specificity: 0.9611 - val_Sensitivity: 1.2634 - val_precision: 0.1084 - val_recall: 0.5249 - val_f1score: 0.1778\n",
      "Epoch 6/50\n",
      " - 355s - loss: -1.5111e-01 - dice_coef: 0.1511 - acc: 0.5607 - mean_squared_error: 0.2757 - Jaccard_index: 0.0820 - Specificity: 0.9696 - Sensitivity: 1.3084 - precision: 0.0900 - recall: 0.6031 - f1score: 0.1555 - val_loss: -1.7648e-01 - val_dice_coef: 0.1765 - val_acc: 0.5711 - val_mean_squared_error: 0.2591 - val_Jaccard_index: 0.0974 - val_Specificity: 0.9622 - val_Sensitivity: 1.2861 - val_precision: 0.1080 - val_recall: 0.5694 - val_f1score: 0.1798\n",
      "Epoch 7/50\n",
      " - 356s - loss: -1.5183e-01 - dice_coef: 0.1518 - acc: 0.5639 - mean_squared_error: 0.2745 - Jaccard_index: 0.0825 - Specificity: 0.9695 - Sensitivity: 1.3045 - precision: 0.0906 - recall: 0.5984 - f1score: 0.1563 - val_loss: -1.7936e-01 - val_dice_coef: 0.1794 - val_acc: 0.5737 - val_mean_squared_error: 0.2602 - val_Jaccard_index: 0.0992 - val_Specificity: 0.9622 - val_Sensitivity: 1.2852 - val_precision: 0.1105 - val_recall: 0.5786 - val_f1score: 0.1837\n",
      "Epoch 8/50\n",
      " - 356s - loss: -1.5328e-01 - dice_coef: 0.1533 - acc: 0.5700 - mean_squared_error: 0.2689 - Jaccard_index: 0.0834 - Specificity: 0.9693 - Sensitivity: 1.2970 - precision: 0.0917 - recall: 0.5916 - f1score: 0.1577 - val_loss: -1.7991e-01 - val_dice_coef: 0.1799 - val_acc: 0.5871 - val_mean_squared_error: 0.2460 - val_Jaccard_index: 0.0996 - val_Specificity: 0.9615 - val_Sensitivity: 1.2673 - val_precision: 0.1114 - val_recall: 0.5487 - val_f1score: 0.1834\n",
      "Epoch 9/50\n",
      " - 355s - loss: -1.5303e-01 - dice_coef: 0.1530 - acc: 0.5706 - mean_squared_error: 0.2699 - Jaccard_index: 0.0832 - Specificity: 0.9692 - Sensitivity: 1.2963 - precision: 0.0916 - recall: 0.5890 - f1score: 0.1574 - val_loss: -1.8232e-01 - val_dice_coef: 0.1823 - val_acc: 0.5914 - val_mean_squared_error: 0.2442 - val_Jaccard_index: 0.1011 - val_Specificity: 0.9614 - val_Sensitivity: 1.2641 - val_precision: 0.1138 - val_recall: 0.5507 - val_f1score: 0.1865\n",
      "Epoch 10/50\n",
      " - 356s - loss: -1.5388e-01 - dice_coef: 0.1539 - acc: 0.5792 - mean_squared_error: 0.2618 - Jaccard_index: 0.0837 - Specificity: 0.9690 - Sensitivity: 1.2865 - precision: 0.0924 - recall: 0.5766 - f1score: 0.1580 - val_loss: -1.8371e-01 - val_dice_coef: 0.1837 - val_acc: 0.6080 - val_mean_squared_error: 0.2288 - val_Jaccard_index: 0.1020 - val_Specificity: 0.9608 - val_Sensitivity: 1.2451 - val_precision: 0.1163 - val_recall: 0.5265 - val_f1score: 0.1882\n",
      "Epoch 11/50\n",
      " - 356s - loss: -1.5418e-01 - dice_coef: 0.1542 - acc: 0.5815 - mean_squared_error: 0.2611 - Jaccard_index: 0.0839 - Specificity: 0.9688 - Sensitivity: 1.2843 - precision: 0.0927 - recall: 0.5734 - f1score: 0.1583 - val_loss: -1.8345e-01 - val_dice_coef: 0.1835 - val_acc: 0.6011 - val_mean_squared_error: 0.2366 - val_Jaccard_index: 0.1018 - val_Specificity: 0.9612 - val_Sensitivity: 1.2529 - val_precision: 0.1152 - val_recall: 0.5398 - val_f1score: 0.1880\n",
      "Epoch 12/50\n",
      " - 356s - loss: -1.5504e-01 - dice_coef: 0.1550 - acc: 0.5887 - mean_squared_error: 0.2542 - Jaccard_index: 0.0844 - Specificity: 0.9686 - Sensitivity: 1.2760 - precision: 0.0937 - recall: 0.5629 - f1score: 0.1593 - val_loss: -1.8647e-01 - val_dice_coef: 0.1865 - val_acc: 0.5979 - val_mean_squared_error: 0.2395 - val_Jaccard_index: 0.1036 - val_Specificity: 0.9612 - val_Sensitivity: 1.2556 - val_precision: 0.1177 - val_recall: 0.5543 - val_f1score: 0.1921\n",
      "Epoch 13/50\n",
      " - 356s - loss: -1.5614e-01 - dice_coef: 0.1561 - acc: 0.5917 - mean_squared_error: 0.2505 - Jaccard_index: 0.0851 - Specificity: 0.9685 - Sensitivity: 1.2711 - precision: 0.0949 - recall: 0.5601 - f1score: 0.1608 - val_loss: -1.8753e-01 - val_dice_coef: 0.1875 - val_acc: 0.6073 - val_mean_squared_error: 0.2320 - val_Jaccard_index: 0.1043 - val_Specificity: 0.9610 - val_Sensitivity: 1.2459 - val_precision: 0.1196 - val_recall: 0.5420 - val_f1score: 0.1934\n",
      "Epoch 14/50\n",
      " - 355s - loss: -1.5589e-01 - dice_coef: 0.1559 - acc: 0.5944 - mean_squared_error: 0.2487 - Jaccard_index: 0.0849 - Specificity: 0.9682 - Sensitivity: 1.2679 - precision: 0.0949 - recall: 0.5541 - f1score: 0.1607 - val_loss: -1.9015e-01 - val_dice_coef: 0.1902 - val_acc: 0.6277 - val_mean_squared_error: 0.2112 - val_Jaccard_index: 0.1061 - val_Specificity: 0.9600 - val_Sensitivity: 1.2206 - val_precision: 0.1244 - val_recall: 0.5095 - val_f1score: 0.1970\n",
      "Epoch 15/50\n",
      " - 356s - loss: -1.5657e-01 - dice_coef: 0.1566 - acc: 0.5977 - mean_squared_error: 0.2473 - Jaccard_index: 0.0853 - Specificity: 0.9683 - Sensitivity: 1.2657 - precision: 0.0954 - recall: 0.5536 - f1score: 0.1613 - val_loss: -1.9114e-01 - val_dice_coef: 0.1911 - val_acc: 0.6159 - val_mean_squared_error: 0.2244 - val_Jaccard_index: 0.1065 - val_Specificity: 0.9607 - val_Sensitivity: 1.2354 - val_precision: 0.1234 - val_recall: 0.5385 - val_f1score: 0.1982\n",
      "Epoch 16/50\n",
      " - 358s - loss: -1.5677e-01 - dice_coef: 0.1568 - acc: 0.6010 - mean_squared_error: 0.2428 - Jaccard_index: 0.0855 - Specificity: 0.9680 - Sensitivity: 1.2597 - precision: 0.0960 - recall: 0.5446 - f1score: 0.1617 - val_loss: -1.9185e-01 - val_dice_coef: 0.1918 - val_acc: 0.6275 - val_mean_squared_error: 0.2125 - val_Jaccard_index: 0.1071 - val_Specificity: 0.9600 - val_Sensitivity: 1.2200 - val_precision: 0.1254 - val_recall: 0.5133 - val_f1score: 0.1987\n",
      "Epoch 17/50\n",
      " - 356s - loss: -1.5673e-01 - dice_coef: 0.1567 - acc: 0.6010 - mean_squared_error: 0.2449 - Jaccard_index: 0.0854 - Specificity: 0.9681 - Sensitivity: 1.2609 - precision: 0.0958 - recall: 0.5477 - f1score: 0.1616 - val_loss: -1.9122e-01 - val_dice_coef: 0.1912 - val_acc: 0.6119 - val_mean_squared_error: 0.2303 - val_Jaccard_index: 0.1067 - val_Specificity: 0.9610 - val_Sensitivity: 1.2403 - val_precision: 0.1233 - val_recall: 0.5479 - val_f1score: 0.1986\n",
      "Epoch 18/50\n",
      " - 355s - loss: -1.5749e-01 - dice_coef: 0.1575 - acc: 0.6005 - mean_squared_error: 0.2444 - Jaccard_index: 0.0859 - Specificity: 0.9680 - Sensitivity: 1.2596 - precision: 0.0966 - recall: 0.5478 - f1score: 0.1628 - val_loss: -1.9332e-01 - val_dice_coef: 0.1933 - val_acc: 0.6186 - val_mean_squared_error: 0.2237 - val_Jaccard_index: 0.1079 - val_Specificity: 0.9606 - val_Sensitivity: 1.2316 - val_precision: 0.1256 - val_recall: 0.5385 - val_f1score: 0.2009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      " - 356s - loss: -1.5754e-01 - dice_coef: 0.1575 - acc: 0.6029 - mean_squared_error: 0.2433 - Jaccard_index: 0.0859 - Specificity: 0.9680 - Sensitivity: 1.2576 - precision: 0.0968 - recall: 0.5448 - f1score: 0.1628 - val_loss: -1.9369e-01 - val_dice_coef: 0.1937 - val_acc: 0.6201 - val_mean_squared_error: 0.2225 - val_Jaccard_index: 0.1082 - val_Specificity: 0.9605 - val_Sensitivity: 1.2293 - val_precision: 0.1264 - val_recall: 0.5377 - val_f1score: 0.2016\n",
      "Epoch 20/50\n",
      " - 356s - loss: -1.5844e-01 - dice_coef: 0.1584 - acc: 0.6059 - mean_squared_error: 0.2423 - Jaccard_index: 0.0865 - Specificity: 0.9677 - Sensitivity: 1.2553 - precision: 0.0977 - recall: 0.5431 - f1score: 0.1639 - val_loss: -1.9222e-01 - val_dice_coef: 0.1922 - val_acc: 0.6094 - val_mean_squared_error: 0.2344 - val_Jaccard_index: 0.1073 - val_Specificity: 0.9610 - val_Sensitivity: 1.2420 - val_precision: 0.1241 - val_recall: 0.5561 - val_f1score: 0.2004\n",
      "Epoch 21/50\n",
      " - 356s - loss: -1.5742e-01 - dice_coef: 0.1574 - acc: 0.6035 - mean_squared_error: 0.2435 - Jaccard_index: 0.0859 - Specificity: 0.9678 - Sensitivity: 1.2558 - precision: 0.0968 - recall: 0.5421 - f1score: 0.1628 - val_loss: -1.9363e-01 - val_dice_coef: 0.1936 - val_acc: 0.6125 - val_mean_squared_error: 0.2318 - val_Jaccard_index: 0.1082 - val_Specificity: 0.9609 - val_Sensitivity: 1.2385 - val_precision: 0.1251 - val_recall: 0.5531 - val_f1score: 0.2015\n",
      "Epoch 22/50\n",
      " - 355s - loss: -1.5850e-01 - dice_coef: 0.1585 - acc: 0.6106 - mean_squared_error: 0.2379 - Jaccard_index: 0.0865 - Specificity: 0.9676 - Sensitivity: 1.2489 - precision: 0.0979 - recall: 0.5331 - f1score: 0.1637 - val_loss: -1.9634e-01 - val_dice_coef: 0.1963 - val_acc: 0.6367 - val_mean_squared_error: 0.2071 - val_Jaccard_index: 0.1099 - val_Specificity: 0.9598 - val_Sensitivity: 1.2089 - val_precision: 0.1305 - val_recall: 0.5092 - val_f1score: 0.2045\n",
      "Epoch 23/50\n",
      " - 355s - loss: -1.5819e-01 - dice_coef: 0.1582 - acc: 0.6144 - mean_squared_error: 0.2327 - Jaccard_index: 0.0864 - Specificity: 0.9673 - Sensitivity: 1.2426 - precision: 0.0982 - recall: 0.5216 - f1score: 0.1635 - val_loss: -1.9655e-01 - val_dice_coef: 0.1966 - val_acc: 0.6391 - val_mean_squared_error: 0.2056 - val_Jaccard_index: 0.1100 - val_Specificity: 0.9597 - val_Sensitivity: 1.2070 - val_precision: 0.1303 - val_recall: 0.5083 - val_f1score: 0.2046\n",
      "Epoch 24/50\n",
      " - 355s - loss: -1.5905e-01 - dice_coef: 0.1590 - acc: 0.6306 - mean_squared_error: 0.2169 - Jaccard_index: 0.0868 - Specificity: 0.9667 - Sensitivity: 1.2251 - precision: 0.0993 - recall: 0.4942 - f1score: 0.1635 - val_loss: -2.0195e-01 - val_dice_coef: 0.2019 - val_acc: 0.6548 - val_mean_squared_error: 0.1894 - val_Jaccard_index: 0.1135 - val_Specificity: 0.9589 - val_Sensitivity: 1.1881 - val_precision: 0.1377 - val_recall: 0.4862 - val_f1score: 0.2107\n",
      "Epoch 25/50\n",
      " - 356s - loss: -1.6067e-01 - dice_coef: 0.1607 - acc: 0.6495 - mean_squared_error: 0.1960 - Jaccard_index: 0.0879 - Specificity: 0.9658 - Sensitivity: 1.2017 - precision: 0.1023 - recall: 0.4582 - f1score: 0.1649 - val_loss: -2.0144e-01 - val_dice_coef: 0.2014 - val_acc: 0.6489 - val_mean_squared_error: 0.1963 - val_Jaccard_index: 0.1131 - val_Specificity: 0.9594 - val_Sensitivity: 1.1971 - val_precision: 0.1351 - val_recall: 0.5043 - val_f1score: 0.2099\n",
      "Epoch 26/50\n",
      " - 355s - loss: -1.6379e-01 - dice_coef: 0.1638 - acc: 0.6644 - mean_squared_error: 0.1795 - Jaccard_index: 0.0898 - Specificity: 0.9653 - Sensitivity: 1.1836 - precision: 0.1062 - recall: 0.4349 - f1score: 0.1680 - val_loss: -2.0869e-01 - val_dice_coef: 0.2087 - val_acc: 0.6895 - val_mean_squared_error: 0.1558 - val_Jaccard_index: 0.1180 - val_Specificity: 0.9575 - val_Sensitivity: 1.1479 - val_precision: 0.1493 - val_recall: 0.4251 - val_f1score: 0.2164\n",
      "Epoch 27/50\n",
      " - 356s - loss: -1.6584e-01 - dice_coef: 0.1658 - acc: 0.6712 - mean_squared_error: 0.1733 - Jaccard_index: 0.0910 - Specificity: 0.9652 - Sensitivity: 1.1767 - precision: 0.1085 - recall: 0.4273 - f1score: 0.1701 - val_loss: -2.1293e-01 - val_dice_coef: 0.2129 - val_acc: 0.6909 - val_mean_squared_error: 0.1557 - val_Jaccard_index: 0.1205 - val_Specificity: 0.9576 - val_Sensitivity: 1.1482 - val_precision: 0.1524 - val_recall: 0.4363 - val_f1score: 0.2212\n",
      "Epoch 28/50\n",
      " - 356s - loss: -1.6741e-01 - dice_coef: 0.1674 - acc: 0.6735 - mean_squared_error: 0.1713 - Jaccard_index: 0.0920 - Specificity: 0.9651 - Sensitivity: 1.1745 - precision: 0.1102 - recall: 0.4260 - f1score: 0.1721 - val_loss: -2.1551e-01 - val_dice_coef: 0.2155 - val_acc: 0.6987 - val_mean_squared_error: 0.1480 - val_Jaccard_index: 0.1222 - val_Specificity: 0.9572 - val_Sensitivity: 1.1376 - val_precision: 0.1574 - val_recall: 0.4181 - val_f1score: 0.2234\n",
      "Epoch 29/50\n",
      " - 355s - loss: -1.6830e-01 - dice_coef: 0.1683 - acc: 0.6745 - mean_squared_error: 0.1708 - Jaccard_index: 0.0925 - Specificity: 0.9653 - Sensitivity: 1.1738 - precision: 0.1108 - recall: 0.4292 - f1score: 0.1732 - val_loss: -2.1477e-01 - val_dice_coef: 0.2148 - val_acc: 0.6809 - val_mean_squared_error: 0.1654 - val_Jaccard_index: 0.1218 - val_Specificity: 0.9585 - val_Sensitivity: 1.1607 - val_precision: 0.1524 - val_recall: 0.4682 - val_f1score: 0.2254\n",
      "Epoch 30/50\n",
      " - 355s - loss: -1.7037e-01 - dice_coef: 0.1704 - acc: 0.6737 - mean_squared_error: 0.1701 - Jaccard_index: 0.0938 - Specificity: 0.9652 - Sensitivity: 1.1731 - precision: 0.1125 - recall: 0.4322 - f1score: 0.1755 - val_loss: -2.1876e-01 - val_dice_coef: 0.2188 - val_acc: 0.6907 - val_mean_squared_error: 0.1563 - val_Jaccard_index: 0.1243 - val_Specificity: 0.9580 - val_Sensitivity: 1.1484 - val_precision: 0.1575 - val_recall: 0.4516 - val_f1score: 0.2289\n",
      "Epoch 31/50\n",
      " - 355s - loss: -1.7004e-01 - dice_coef: 0.1700 - acc: 0.6727 - mean_squared_error: 0.1731 - Jaccard_index: 0.0936 - Specificity: 0.9653 - Sensitivity: 1.1759 - precision: 0.1120 - recall: 0.4361 - f1score: 0.1753 - val_loss: -2.1867e-01 - val_dice_coef: 0.2187 - val_acc: 0.6818 - val_mean_squared_error: 0.1652 - val_Jaccard_index: 0.1242 - val_Specificity: 0.9585 - val_Sensitivity: 1.1596 - val_precision: 0.1569 - val_recall: 0.4752 - val_f1score: 0.2304\n",
      "Epoch 32/50\n",
      " - 354s - loss: -1.7090e-01 - dice_coef: 0.1709 - acc: 0.6722 - mean_squared_error: 0.1728 - Jaccard_index: 0.0941 - Specificity: 0.9654 - Sensitivity: 1.1753 - precision: 0.1128 - recall: 0.4381 - f1score: 0.1763 - val_loss: -2.1896e-01 - val_dice_coef: 0.2190 - val_acc: 0.6766 - val_mean_squared_error: 0.1694 - val_Jaccard_index: 0.1244 - val_Specificity: 0.9589 - val_Sensitivity: 1.1651 - val_precision: 0.1556 - val_recall: 0.4884 - val_f1score: 0.2313\n",
      "Epoch 33/50\n",
      " - 355s - loss: -1.7219e-01 - dice_coef: 0.1722 - acc: 0.6730 - mean_squared_error: 0.1736 - Jaccard_index: 0.0949 - Specificity: 0.9654 - Sensitivity: 1.1758 - precision: 0.1139 - recall: 0.4418 - f1score: 0.1779 - val_loss: -2.1910e-01 - val_dice_coef: 0.2191 - val_acc: 0.6801 - val_mean_squared_error: 0.1679 - val_Jaccard_index: 0.1247 - val_Specificity: 0.9589 - val_Sensitivity: 1.1624 - val_precision: 0.1566 - val_recall: 0.4830 - val_f1score: 0.2318\n",
      "Epoch 34/50\n",
      " - 355s - loss: -1.7113e-01 - dice_coef: 0.1711 - acc: 0.6725 - mean_squared_error: 0.1747 - Jaccard_index: 0.0942 - Specificity: 0.9656 - Sensitivity: 1.1768 - precision: 0.1128 - recall: 0.4433 - f1score: 0.1766 - val_loss: -2.1937e-01 - val_dice_coef: 0.2194 - val_acc: 0.6730 - val_mean_squared_error: 0.1748 - val_Jaccard_index: 0.1247 - val_Specificity: 0.9593 - val_Sensitivity: 1.1708 - val_precision: 0.1550 - val_recall: 0.5031 - val_f1score: 0.2325\n",
      "Epoch 35/50\n",
      " - 356s - loss: -1.7288e-01 - dice_coef: 0.1729 - acc: 0.6712 - mean_squared_error: 0.1751 - Jaccard_index: 0.0952 - Specificity: 0.9655 - Sensitivity: 1.1765 - precision: 0.1141 - recall: 0.4474 - f1score: 0.1789 - val_loss: -2.2109e-01 - val_dice_coef: 0.2211 - val_acc: 0.6824 - val_mean_squared_error: 0.1652 - val_Jaccard_index: 0.1258 - val_Specificity: 0.9586 - val_Sensitivity: 1.1576 - val_precision: 0.1587 - val_recall: 0.4814 - val_f1score: 0.2337\n",
      "Epoch 36/50\n",
      " - 357s - loss: -1.7275e-01 - dice_coef: 0.1727 - acc: 0.6703 - mean_squared_error: 0.1769 - Jaccard_index: 0.0952 - Specificity: 0.9655 - Sensitivity: 1.1781 - precision: 0.1140 - recall: 0.4490 - f1score: 0.1786 - val_loss: -2.1999e-01 - val_dice_coef: 0.2200 - val_acc: 0.6699 - val_mean_squared_error: 0.1789 - val_Jaccard_index: 0.1250 - val_Specificity: 0.9594 - val_Sensitivity: 1.1747 - val_precision: 0.1551 - val_recall: 0.5113 - val_f1score: 0.2332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50\n",
      " - 356s - loss: -1.7265e-01 - dice_coef: 0.1727 - acc: 0.6701 - mean_squared_error: 0.1771 - Jaccard_index: 0.0951 - Specificity: 0.9657 - Sensitivity: 1.1779 - precision: 0.1141 - recall: 0.4501 - f1score: 0.1789 - val_loss: -2.2209e-01 - val_dice_coef: 0.2221 - val_acc: 0.6995 - val_mean_squared_error: 0.1503 - val_Jaccard_index: 0.1267 - val_Specificity: 0.9574 - val_Sensitivity: 1.1365 - val_precision: 0.1634 - val_recall: 0.4367 - val_f1score: 0.2326\n",
      "Epoch 38/50\n",
      " - 356s - loss: -1.7230e-01 - dice_coef: 0.1723 - acc: 0.6690 - mean_squared_error: 0.1790 - Jaccard_index: 0.0949 - Specificity: 0.9655 - Sensitivity: 1.1794 - precision: 0.1136 - recall: 0.4514 - f1score: 0.1785 - val_loss: -2.2295e-01 - val_dice_coef: 0.2230 - val_acc: 0.6787 - val_mean_squared_error: 0.1708 - val_Jaccard_index: 0.1270 - val_Specificity: 0.9589 - val_Sensitivity: 1.1634 - val_precision: 0.1591 - val_recall: 0.4950 - val_f1score: 0.2361\n",
      "Epoch 39/50\n",
      " - 355s - loss: -1.7240e-01 - dice_coef: 0.1724 - acc: 0.6678 - mean_squared_error: 0.1799 - Jaccard_index: 0.0949 - Specificity: 0.9656 - Sensitivity: 1.1799 - precision: 0.1134 - recall: 0.4551 - f1score: 0.1786 - val_loss: -2.2311e-01 - val_dice_coef: 0.2231 - val_acc: 0.6792 - val_mean_squared_error: 0.1698 - val_Jaccard_index: 0.1270 - val_Specificity: 0.9587 - val_Sensitivity: 1.1612 - val_precision: 0.1595 - val_recall: 0.4907 - val_f1score: 0.2360\n",
      "Epoch 40/50\n",
      " - 356s - loss: -1.7365e-01 - dice_coef: 0.1737 - acc: 0.6708 - mean_squared_error: 0.1788 - Jaccard_index: 0.0957 - Specificity: 0.9655 - Sensitivity: 1.1783 - precision: 0.1148 - recall: 0.4542 - f1score: 0.1800 - val_loss: -2.2321e-01 - val_dice_coef: 0.2232 - val_acc: 0.6816 - val_mean_squared_error: 0.1686 - val_Jaccard_index: 0.1271 - val_Specificity: 0.9587 - val_Sensitivity: 1.1595 - val_precision: 0.1595 - val_recall: 0.4891 - val_f1score: 0.2364\n",
      "Epoch 41/50\n",
      " - 357s - loss: -1.7378e-01 - dice_coef: 0.1738 - acc: 0.6680 - mean_squared_error: 0.1807 - Jaccard_index: 0.0958 - Specificity: 0.9655 - Sensitivity: 1.1798 - precision: 0.1146 - recall: 0.4587 - f1score: 0.1802 - val_loss: -2.2141e-01 - val_dice_coef: 0.2214 - val_acc: 0.6843 - val_mean_squared_error: 0.1656 - val_Jaccard_index: 0.1261 - val_Specificity: 0.9585 - val_Sensitivity: 1.1548 - val_precision: 0.1588 - val_recall: 0.4767 - val_f1score: 0.2336\n",
      "Epoch 42/50\n",
      " - 355s - loss: -1.7241e-01 - dice_coef: 0.1724 - acc: 0.6689 - mean_squared_error: 0.1800 - Jaccard_index: 0.0950 - Specificity: 0.9657 - Sensitivity: 1.1787 - precision: 0.1138 - recall: 0.4545 - f1score: 0.1788 - val_loss: -2.2458e-01 - val_dice_coef: 0.2246 - val_acc: 0.6837 - val_mean_squared_error: 0.1668 - val_Jaccard_index: 0.1280 - val_Specificity: 0.9584 - val_Sensitivity: 1.1559 - val_precision: 0.1615 - val_recall: 0.4840 - val_f1score: 0.2374\n",
      "Epoch 43/50\n",
      " - 355s - loss: -1.7450e-01 - dice_coef: 0.1745 - acc: 0.6695 - mean_squared_error: 0.1805 - Jaccard_index: 0.0963 - Specificity: 0.9656 - Sensitivity: 1.1786 - precision: 0.1152 - recall: 0.4577 - f1score: 0.1810 - val_loss: -2.2144e-01 - val_dice_coef: 0.2214 - val_acc: 0.6717 - val_mean_squared_error: 0.1787 - val_Jaccard_index: 0.1260 - val_Specificity: 0.9593 - val_Sensitivity: 1.1709 - val_precision: 0.1566 - val_recall: 0.5100 - val_f1score: 0.2349\n",
      "Epoch 44/50\n",
      " - 356s - loss: -1.7271e-01 - dice_coef: 0.1727 - acc: 0.6678 - mean_squared_error: 0.1823 - Jaccard_index: 0.0952 - Specificity: 0.9656 - Sensitivity: 1.1800 - precision: 0.1140 - recall: 0.4566 - f1score: 0.1792 - val_loss: -2.2105e-01 - val_dice_coef: 0.2210 - val_acc: 0.6654 - val_mean_squared_error: 0.1862 - val_Jaccard_index: 0.1256 - val_Specificity: 0.9598 - val_Sensitivity: 1.1801 - val_precision: 0.1546 - val_recall: 0.5291 - val_f1score: 0.2348\n",
      "Epoch 45/50\n",
      " - 355s - loss: -1.7466e-01 - dice_coef: 0.1747 - acc: 0.6699 - mean_squared_error: 0.1804 - Jaccard_index: 0.0963 - Specificity: 0.9655 - Sensitivity: 1.1776 - precision: 0.1155 - recall: 0.4567 - f1score: 0.1813 - val_loss: -2.2557e-01 - val_dice_coef: 0.2256 - val_acc: 0.6850 - val_mean_squared_error: 0.1644 - val_Jaccard_index: 0.1289 - val_Specificity: 0.9581 - val_Sensitivity: 1.1512 - val_precision: 0.1638 - val_recall: 0.4754 - val_f1score: 0.2381\n",
      "Epoch 46/50\n",
      " - 357s - loss: -1.7376e-01 - dice_coef: 0.1738 - acc: 0.6694 - mean_squared_error: 0.1816 - Jaccard_index: 0.0958 - Specificity: 0.9656 - Sensitivity: 1.1785 - precision: 0.1148 - recall: 0.4574 - f1score: 0.1804 - val_loss: -2.2452e-01 - val_dice_coef: 0.2245 - val_acc: 0.6799 - val_mean_squared_error: 0.1730 - val_Jaccard_index: 0.1281 - val_Specificity: 0.9589 - val_Sensitivity: 1.1622 - val_precision: 0.1608 - val_recall: 0.4982 - val_f1score: 0.2378\n",
      "Epoch 47/50\n",
      " - 357s - loss: -1.7458e-01 - dice_coef: 0.1746 - acc: 0.6693 - mean_squared_error: 0.1810 - Jaccard_index: 0.0963 - Specificity: 0.9654 - Sensitivity: 1.1773 - precision: 0.1156 - recall: 0.4563 - f1score: 0.1813 - val_loss: -2.2501e-01 - val_dice_coef: 0.2250 - val_acc: 0.6885 - val_mean_squared_error: 0.1624 - val_Jaccard_index: 0.1283 - val_Specificity: 0.9580 - val_Sensitivity: 1.1478 - val_precision: 0.1632 - val_recall: 0.4695 - val_f1score: 0.2372\n",
      "Epoch 48/50\n",
      " - 355s - loss: -1.7449e-01 - dice_coef: 0.1745 - acc: 0.6690 - mean_squared_error: 0.1825 - Jaccard_index: 0.0963 - Specificity: 0.9655 - Sensitivity: 1.1787 - precision: 0.1153 - recall: 0.4597 - f1score: 0.1811 - val_loss: -2.2375e-01 - val_dice_coef: 0.2237 - val_acc: 0.6832 - val_mean_squared_error: 0.1691 - val_Jaccard_index: 0.1277 - val_Specificity: 0.9586 - val_Sensitivity: 1.1562 - val_precision: 0.1613 - val_recall: 0.4845 - val_f1score: 0.2367\n",
      "Epoch 49/50\n",
      " - 356s - loss: -1.7386e-01 - dice_coef: 0.1739 - acc: 0.6675 - mean_squared_error: 0.1838 - Jaccard_index: 0.0959 - Specificity: 0.9656 - Sensitivity: 1.1798 - precision: 0.1146 - recall: 0.4604 - f1score: 0.1806 - val_loss: -2.2434e-01 - val_dice_coef: 0.2243 - val_acc: 0.6873 - val_mean_squared_error: 0.1646 - val_Jaccard_index: 0.1280 - val_Specificity: 0.9582 - val_Sensitivity: 1.1498 - val_precision: 0.1623 - val_recall: 0.4732 - val_f1score: 0.2363\n",
      "Epoch 50/50\n",
      " - 356s - loss: -1.7482e-01 - dice_coef: 0.1748 - acc: 0.6692 - mean_squared_error: 0.1827 - Jaccard_index: 0.0965 - Specificity: 0.9654 - Sensitivity: 1.1780 - precision: 0.1158 - recall: 0.4586 - f1score: 0.1816 - val_loss: -2.2149e-01 - val_dice_coef: 0.2215 - val_acc: 0.6688 - val_mean_squared_error: 0.1847 - val_Jaccard_index: 0.1259 - val_Specificity: 0.9596 - val_Sensitivity: 1.1755 - val_precision: 0.1555 - val_recall: 0.5230 - val_f1score: 0.2351\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=nb_train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose = 2,\n",
    "                    validation_data = validation_generator,\n",
    "                    validation_steps = nb_validation_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate_generator(validation_generator, steps=50)\n",
    "\n",
    "print ('Validation Score: ', score[0])\n",
    "print ('Validation Accuracy: ',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict_generator(test_generator, verbose=1, steps=nb_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = model.evaluate_generator(test_generator, steps=50)\n",
    "\n",
    "print(model.metrics_names)\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = np.array(history.history['Jaccard_index'])\n",
    "val_coef = np.array(history.history['val_Jaccard_index'])\n",
    "print(\"Training co-effiency    : {};\\nValidation co-effiency : {}\".format(coef[coef==max(coef)][0], val_coef[np.argmax(coef)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "\n",
    "def labelVisualize(num_class,color_dict,img):\n",
    "    img = img[:,:,0] if len(img.shape) == 3 else img\n",
    "    img_out = np.zeros(img.shape + (3,))\n",
    "    for i in range(num_class):\n",
    "        img_out[img == i,:] = color_dict[i]\n",
    "    return img_out / 255\n",
    "\n",
    "def saveResult(save_path,npyfile,flag_multi_class = False,num_class = 2):\n",
    "    for i,item in enumerate(npyfile):\n",
    "        img = labelVisualize(num_class,COLOR_DICT,item) if flag_multi_class else item[:,:,0]\n",
    "        io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
    "\n",
    "os.mkdir('05.U-Net2_results_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveResult('05.U-Net2_results_dir',prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeData(img,mask):\n",
    "    mean = np.mean(img)\n",
    "    std = np.std(img)\n",
    "    img -= mean\n",
    "    img /= std\n",
    "    mask = mask /255\n",
    "    mask[mask > 0.5] = 1\n",
    "    mask[mask <= 0.5] = 0\n",
    "    return (img,mask)\n",
    "\n",
    "test_data_dir= \"data_augmented/cvc300_test/images/\"\n",
    "test_data_mask_dir = \"data_augmented/cvc300_test/masks/\"\n",
    "test_data_pred_dir = \"05.U-Net2_results_dir\"\n",
    "img_rows, img_cols = 256, 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image as image_utils\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img\n",
    "\n",
    "file_names = next(os.walk(test_data_dir))[2]\n",
    "scores = []\n",
    "for file in file_names:\n",
    "    grey_img = load_img(os.path.join(test_data_dir,file), target_size=(img_rows, img_cols), grayscale=False)\n",
    "    mask_img = load_img(os.path.join(test_data_mask_dir,file), target_size=(img_rows, img_cols), grayscale=True)\n",
    "    img = img_to_array(grey_img)\n",
    "    img_mask = img_to_array(mask_img)\n",
    "    \n",
    "    img, img_mask = normalizeData(img, img_mask)\n",
    "    img = np.reshape(img,(1,)+img.shape)\n",
    "    \n",
    "    pred = model.predict([img])\n",
    "    sess = tf.Session()\n",
    "    score = sess.run(Jaccard_index(img_mask, pred))\n",
    "    print(\"{} -- jaccard index: {}\".format(file,score))\n",
    "    scores.append([file,score])\n",
    "\n",
    "    result_img = array_to_img(pred[0] * 255 )\n",
    "    result_img.save(os.path.join(test_data_pred_dir, file.split('.')[0] + '_predict.jpg'))\n",
    "\n",
    "with open(\"unet_test_result.csv\", 'w') as f:\n",
    "    f.write(\"filename, jaccard_index\\n\")\n",
    "    for i in range(len(scores)):\n",
    "        #print(scores[i])\n",
    "        f.write(\"{},{}\\n\".format(scores[i][0], scores[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img=mpimg.imread('05.U-Net2_results_dir/102_predict.png')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(prediction[1]), cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(prediction[1]), cmap = \"gray\", vmin = 0.0, vmax= 0.09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ =  np.squeeze(np.multiply(prediction[1], 255))\n",
    "print(results_)\n",
    "\n",
    "plt.imshow(results_, cmap = \"gray\", vmin = 0.0, vmax= 0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img=mpimg.imread('05.U-Net2_results_dir/35_predict.png')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['dice_coef'])\n",
    "plt.plot(history.history['val_dice_coef'])\n",
    "plt.title('model dice_coeff')\n",
    "plt.ylabel('dice_coef')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
