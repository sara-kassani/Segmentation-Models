{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 1515442187683927380, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 9214062756\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 18283777205103728145\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras import layers, metrics, models, optimizers\n",
    "from keras.optimizers import Adam, RMSprop,SGD\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, concatenate, Flatten, Dense, Activation, Dropout, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Version 2.2.4\n",
      "tensorflow Version 1.9.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Keras Version\", keras.__version__)\n",
    "print(\"tensorflow Version\", tf.__version__)\n",
    "# print(\"dim_ordering:\", K.image_dim_ordering())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "img_rows, img_cols = 512, 512\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "epochs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data_augmented/cvc300_train/'\n",
    "validation_dir = 'data_augmented/cvc300_validation/'\n",
    "test_dir = 'data_augmented/cvc300_test/'\n",
    "\n",
    "image_folder = 'images'\n",
    "masks_folder = 'masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://github.com/ykamikawa/PSPNet/blob/master/PSPNet.py\n",
    "(512, 512, 3)\n",
    "\"\"\"\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Reshape, Permute, Dense, Activation\n",
    "from keras.layers import AveragePooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Lambda, Conv2DTranspose\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import multiply, add, concatenate\n",
    "from keras.engine.topology import Layer\n",
    "from keras.engine import InputSpec\n",
    "\n",
    "\n",
    "def PSPNet50(img_size, n_labels=1, output_stride=16, num_blocks=4,\n",
    "             levels=[6,3,2,1], use_se=True, output_mode=\"sigmoid\",\n",
    "             upsample_type='deconv'):\n",
    "    input_shape = (img_size, img_size, 3)\n",
    "\n",
    "    img_input = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2), padding='same')(img_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, strides=(1, 1), use_se=use_se)\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, use_se=use_se)\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, use_se=use_se)\n",
    "\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, use_se=use_se)\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, use_se=use_se)\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, use_se=use_se)\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, use_se=use_se)\n",
    "\n",
    "    if output_stride == 8:\n",
    "        rate_scale = 2\n",
    "    elif output_stride == 16:\n",
    "        rate_scale = 1\n",
    "\n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, dilation_rate=1*rate_scale,\n",
    "                   multigrid=[1,1,1], use_se=use_se)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4,\n",
    "                       dilation_rate=1*rate_scale, multigrid=[1, 1, 1],\n",
    "                       use_se=use_se)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4,\n",
    "                       dilation_rate=1*rate_scale, multigrid=[1, 1, 1],\n",
    "                       use_se=use_se)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4,\n",
    "                       dilation_rate=1*rate_scale, multigrid=[1, 1, 1],\n",
    "                       use_se=use_se)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4,\n",
    "                       dilation_rate=1*rate_scale, multigrid=[1, 1, 1],\n",
    "                       use_se=use_se)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4,\n",
    "                       dilation_rate=1*rate_scale, multigrid=[1, 1, 1],\n",
    "                       use_se=use_se)\n",
    "\n",
    "    init_rate = 2\n",
    "    for block in range(4, num_blocks+1):\n",
    "        x = conv_block(x, 3, [512, 512, 2048], stage=5,\n",
    "                       dilation_rate=init_rate*rate_scale,\n",
    "                       multigrid=[1, 1, 1], use_se=use_se)\n",
    "        x = identity_block(x, 3, [512, 512, 2048], stage=5,\n",
    "                           dilation_rate=init_rate*rate_scale,\n",
    "                           multigrid=[1, 1, 1], use_se=use_se)\n",
    "        x = identity_block(x, 3, [512, 512, 2048], stage=5,\n",
    "                           dilation_rate=init_rate*rate_scale,\n",
    "                           multigrid=[1, 1, 1], use_se=use_se)\n",
    "        init_rate *= 2\n",
    "\n",
    "    x = pyramid_pooling_module(x, 512, input_shape, output_stride, levels)\n",
    "\n",
    "    if upsample_type == 'duc':\n",
    "        x = duc(x, factor=output_stride,\n",
    "                output_shape=(input_shape[0], input_shape[1], n_labels))\n",
    "        out = Conv2D(n_labels, (1, 1), padding='same',\n",
    "                     kernel_initializer=\"he_normal\")(x)\n",
    "\n",
    "    elif upsample_type == 'bilinear':\n",
    "        x = Conv2D(n_labels, (1, 1), padding='same',\n",
    "                   kernel_initializer=\"he_normal\")(x)\n",
    "        out = BilinearUpSampling2D((n_labels, input_shape[0], input_shape[1]),\n",
    "                                   factor=output_stride)(x)\n",
    "\n",
    "    elif upsample_type == 'deconv':\n",
    "        out = Conv2DTranspose(n_labels, (output_stride*2, output_stride*2),\n",
    "                              strides=(output_stride, output_stride),\n",
    "                              padding='same',\n",
    "                              kernel_initializer='he_normal',\n",
    "                              use_bias=False)(x)\n",
    "    out = Activation(output_mode)(out)\n",
    "\n",
    "    model = Model(inputs=img_input, outputs=out)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, strides=(2, 2),\n",
    "               dilation_rate=1, multigrid=[1,2,1], use_se=True):\n",
    "    filters1, filters2, filters3 = filters\n",
    "\n",
    "    if dilation_rate > 1:\n",
    "        strides = (1, 1)\n",
    "    else:\n",
    "        multigrid = [1, 1, 1]\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), strides=strides,\n",
    "               dilation_rate=dilation_rate*multigrid[0])(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, padding='same',\n",
    "               dilation_rate=dilation_rate*multigrid[1])(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1),\n",
    "               dilation_rate=dilation_rate*multigrid[2])(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    shortcut = Conv2D(filters3, (1, 1), strides=strides)(input_tensor)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    if use_se and stage < 5:\n",
    "        se = _squeeze_excite_block(x, filters3, k=1)\n",
    "        x = multiply([x, se])\n",
    "    x = add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def _squeeze_excite_block(init, filters, k=1):\n",
    "    se_shape = (1, 1, filters * k)\n",
    "\n",
    "    se = GlobalAveragePooling2D()(init)\n",
    "    se = Dense((filters * k) // 16, activation='relu',\n",
    "               kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = Dense(filters * k, activation='sigmoid',\n",
    "               kernel_initializer='he_normal', use_bias=False)(se)\n",
    "\n",
    "    return se\n",
    "\n",
    "\n",
    "def identity_block(input_tensor, kernel_size, filters, stage, dilation_rate=1,\n",
    "                   multigrid=[1, 2, 1], use_se=True):\n",
    "    filters1, filters2, filters3 = filters\n",
    "\n",
    "    if dilation_rate < 2:\n",
    "        multigrid = [1, 1, 1]\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1),\n",
    "               dilation_rate=dilation_rate*multigrid[0])(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, padding='same',\n",
    "               dilation_rate=dilation_rate*multigrid[1])(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1),\n",
    "               dilation_rate=dilation_rate*multigrid[2])(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # stage 5 after\n",
    "    if use_se and stage < 5:\n",
    "        se = _squeeze_excite_block(x, filters3, k=1)\n",
    "        x = multiply([x, se])\n",
    "    x = add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def pyramid_pooling_module(x, num_filters, input_shape, output_stride, levels):\n",
    "    pyramid_pooling_blocks = [x]\n",
    "    for level in levels:\n",
    "        pyramid_pooling_blocks.append(interp_block(x, num_filters, input_shape,\n",
    "                                                   output_stride, level))\n",
    "\n",
    "    y = concatenate(pyramid_pooling_blocks)\n",
    "    y = Conv2D(num_filters, (3, 3), padding='same',\n",
    "               kernel_initializer=\"he_normal\")(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "def interp_block(x, num_filters, input_shape, output_stride, level):\n",
    "    feature_map_shape = (input_shape[0]/output_stride,\n",
    "                         input_shape[1]/output_stride)\n",
    "\n",
    "    if output_stride == 16:\n",
    "        scale = 5\n",
    "    elif output_stride == 8:\n",
    "        scale = 10\n",
    "\n",
    "    kernel = (level*scale, level*scale)\n",
    "    strides = (level*scale, level*scale)\n",
    "    global_feat = AveragePooling2D(kernel, strides=strides)(x)\n",
    "    global_feat = Conv2D(num_filters, (1, 1), padding='same',\n",
    "                         kernel_initializer=\"he_normal\")(global_feat)\n",
    "    global_feat = BatchNormalization()(global_feat)\n",
    "    global_feat = Lambda(Interp, arguments={'shape': feature_map_shape})(global_feat)\n",
    "\n",
    "    return global_feat\n",
    "\n",
    "\n",
    "def duc(x, factor=8, output_shape=(512,512,1)):\n",
    "    H,W,c,r = output_shape[0],output_shape[1],output_shape[2],factor\n",
    "    h = H/r\n",
    "    w = W/r\n",
    "    x = Conv2D(c*r*r,\n",
    "            (3, 3),\n",
    "            padding='same',\n",
    "            name='conv_duc_%s'%factor)(x)\n",
    "    x = BatchNormalization(name='bn_duc_%s'%factor)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Permute((3,1,2))(x)\n",
    "    x = Reshape((c,r,r,h,w))(x)\n",
    "    x = Permute((1,4,2,5,3))(x)\n",
    "    x = Reshape((c,H,W))(x)\n",
    "    x = Permute((2,3,1))(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "class BilinearUpSampling2D(Layer):\n",
    "    def __init__(self, target_shape=None, factor=None, data_format=None,\n",
    "                 **kwargs):\n",
    "        if data_format is None:\n",
    "            data_format = K.image_data_format()\n",
    "        assert data_format in {\n",
    "            'channels_last', 'channels_first'}\n",
    "\n",
    "        self.data_format = data_format\n",
    "        self.input_spec = [InputSpec(ndim=4)]\n",
    "        self.target_shape = target_shape\n",
    "        self.factor = factor\n",
    "        if self.data_format == 'channels_first':\n",
    "            self.target_size = (target_shape[2], target_shape[3])\n",
    "        elif self.data_format == 'channels_last':\n",
    "            self.target_size = (target_shape[1], target_shape[2])\n",
    "        super(BilinearUpSampling2D, self).__init__(**kwargs)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.data_format == 'channels_last':\n",
    "            return (input_shape[0], self.target_size[0],\n",
    "                    self.target_size[1], input_shape[3])\n",
    "        else:\n",
    "            return (input_shape[0], input_shape[1],\n",
    "                    self.target_size[0], self.target_size[1])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return K.resize_images(inputs, self.factor, self.factor, self.data_format)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'target_shape': self.target_shape,\n",
    "                  'data_format': self.data_format}\n",
    "        base_config = super(BilinearUpSampling2D, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "def Interp(x, shape):\n",
    "    from keras.backend import tf as ktf\n",
    "    new_height, new_width = shape\n",
    "    resized = ktf.image.resize_images(x, [int(new_height), int(new_width)], align_corners=True)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26112 images belonging to 1 classes.\n",
      "Found 26112 images belonging to 1 classes.\n",
      "Found 8704 images belonging to 1 classes.\n",
      "Found 8704 images belonging to 1 classes.\n",
      "Found 28 images belonging to 1 classes.\n",
      "Found 28 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "seed = 1142\n",
    "data_gen_args = dict(rescale=1. / 255, featurewise_center=True, featurewise_std_normalization=True)\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "masks_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "image_generator = image_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    classes = [image_folder],\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "mask_generator = masks_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    classes = [masks_folder],\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "validation_image_generator = image_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    classes = [image_folder],\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "validation_mask_generator = masks_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    classes = [masks_folder],\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "test_image_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    classes = [image_folder],\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "test_mask_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    classes = [masks_folder],\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = zip(image_generator, mask_generator)\n",
    "validation_generator = zip(validation_image_generator, validation_mask_generator)\n",
    "test_generator = zip(test_image_generator, test_mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_train_samples: 26112\n",
      "nb_validation_samples: 8704\n",
      "nb_test_samples: 28\n",
      "\n",
      "predict_size_train: 6528\n",
      "predict_size_validation: 2176\n",
      "predict_size_test: 7\n"
     ]
    }
   ],
   "source": [
    "nb_train_samples = len(image_generator.filenames)\n",
    "nb_validation_samples = len(validation_image_generator.filenames)\n",
    "nb_test_samples = len(test_image_generator.filenames)\n",
    "\n",
    "predict_size_train = int(math.ceil(nb_train_samples / batch_size))\n",
    "predict_size_validation = int(math.ceil(nb_validation_samples / batch_size))\n",
    "predict_size_test = int(math.ceil(nb_test_samples / batch_size))\n",
    "\n",
    "print(\"nb_train_samples:\", nb_train_samples)\n",
    "print(\"nb_validation_samples:\", nb_validation_samples)\n",
    "print(\"nb_test_samples:\", nb_test_samples)\n",
    "\n",
    "print(\"\\npredict_size_train:\", predict_size_train)\n",
    "print(\"predict_size_validation:\", predict_size_validation)\n",
    "print(\"predict_size_test:\", predict_size_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 1.\n",
    "from keras import backend as K\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def Specificity(y_true, y_pred):\n",
    "    true_negatives = K.abs(y_pred)- K.abs(y_true)\n",
    "    return ((true_negatives+smooth)/(y_pred+ smooth))\n",
    "\n",
    "def Sensitivity(y_true, y_pred):\n",
    "    y_true = K.flatten(y_true)\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    return ((y_pred+smooth)/ (y_true+smooth))\n",
    "\n",
    "def Jaccard_index(y_true,y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return ((intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + smooth))\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "    Only computes a batch-wise average of precision.\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "    Only computes a batch-wise average of recall.\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def f1score(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "        Only computes a batch-wise average of recall.\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "        Only computes a batch-wise average of precision.\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 512, 512, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 64) 9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256, 256, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 256, 256, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 127, 127, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 127, 127, 64) 4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 127, 127, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 127, 127, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 127, 127, 64) 36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 127, 127, 64) 256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 127, 127, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 127, 127, 256 16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 127, 127, 256 1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 256)          0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           4096        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          4096        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 127, 127, 256 16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 127, 127, 256 0           batch_normalization_4[0][0]      \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 127, 127, 256 1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 127, 127, 256 0           multiply_1[0][0]                 \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 127, 127, 256 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 127, 127, 64) 16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 127, 127, 64) 256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 127, 127, 64) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 127, 127, 64) 36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 127, 127, 64) 256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 127, 127, 64) 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 127, 127, 256 16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 127, 127, 256 1024        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 256)          0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 16)           4096        global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          4096        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 127, 127, 256 0           batch_normalization_8[0][0]      \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 127, 127, 256 0           multiply_2[0][0]                 \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 127, 127, 256 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 127, 127, 64) 16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 127, 127, 64) 256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 127, 127, 64) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 127, 127, 64) 36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 127, 127, 64) 256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 127, 127, 64) 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 127, 127, 256 16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 127, 127, 256 1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 256)          0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 16)           4096        global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 256)          4096        dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 127, 127, 256 0           batch_normalization_11[0][0]     \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 127, 127, 256 0           multiply_3[0][0]                 \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 127, 127, 256 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 128)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 64, 64, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 128)  512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 64, 64, 512)  2048        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 512)          0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 32)           16384       global_average_pooling2d_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 512)          16384       dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 64, 64, 512)  0           batch_normalization_14[0][0]     \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 64, 64, 512)  2048        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 64, 64, 512)  0           multiply_4[0][0]                 \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 64, 64, 128)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 64, 64, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 64, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 64, 64, 128)  512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 64, 64, 128)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 64, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 64, 64, 512)  2048        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_5 (Glo (None, 512)          0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 32)           16384       global_average_pooling2d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 512)          16384       dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 64, 64, 512)  0           batch_normalization_18[0][0]     \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 64, 64, 512)  0           multiply_5[0][0]                 \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 64, 64, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 64, 64, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 64, 64, 128)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 64, 64, 128)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 64, 64, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 64, 64, 128)  512         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 64, 64, 128)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 64, 64, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 64, 64, 512)  2048        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_6 (Glo (None, 512)          0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 32)           16384       global_average_pooling2d_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 512)          16384       dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 64, 64, 512)  0           batch_normalization_21[0][0]     \n",
      "                                                                 dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 64, 64, 512)  0           multiply_6[0][0]                 \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 64, 64, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 64, 64, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 64, 64, 128)  512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 64, 64, 128)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 64, 64, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 64, 64, 128)  512         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 64, 64, 128)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 64, 64, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 64, 64, 512)  2048        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_7 (Glo (None, 512)          0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 32)           16384       global_average_pooling2d_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 512)          16384       dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 64, 64, 512)  0           batch_normalization_24[0][0]     \n",
      "                                                                 dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 64, 64, 512)  0           multiply_7[0][0]                 \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 64, 64, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 32, 32, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 32, 32, 256)  1024        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 32, 32, 256)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 32, 32, 256)  1024        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 32, 32, 256)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 32, 32, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 32, 32, 1024) 4096        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_8 (Glo (None, 1024)         0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 64)           65536       global_average_pooling2d_8[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1024)         65536       dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 32, 32, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 32, 32, 1024) 0           batch_normalization_27[0][0]     \n",
      "                                                                 dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 32, 32, 1024) 4096        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 32, 32, 1024) 0           multiply_8[0][0]                 \n",
      "                                                                 batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 32, 32, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 32, 32, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 32, 32, 256)  1024        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 32, 32, 256)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 32, 32, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 32, 32, 256)  1024        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 32, 32, 256)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 32, 32, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 32, 32, 1024) 4096        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_9 (Glo (None, 1024)         0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 64)           65536       global_average_pooling2d_9[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1024)         65536       dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 32, 32, 1024) 0           batch_normalization_31[0][0]     \n",
      "                                                                 dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 32, 32, 1024) 0           multiply_9[0][0]                 \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 32, 32, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 32, 32, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 32, 32, 256)  1024        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 32, 32, 256)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 32, 32, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 32, 32, 256)  1024        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 32, 32, 256)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 32, 32, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 32, 32, 1024) 4096        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_10 (Gl (None, 1024)         0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 64)           65536       global_average_pooling2d_10[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 1024)         65536       dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 32, 32, 1024) 0           batch_normalization_34[0][0]     \n",
      "                                                                 dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 32, 32, 1024) 0           multiply_10[0][0]                \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 32, 32, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 32, 32, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 32, 32, 256)  1024        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 32, 32, 256)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 32, 32, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 32, 32, 256)  1024        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 32, 32, 256)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 32, 32, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 32, 32, 1024) 4096        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_11 (Gl (None, 1024)         0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 64)           65536       global_average_pooling2d_11[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 1024)         65536       dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 32, 32, 1024) 0           batch_normalization_37[0][0]     \n",
      "                                                                 dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 32, 32, 1024) 0           multiply_11[0][0]                \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 32, 32, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 32, 32, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 32, 32, 256)  1024        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 32, 32, 256)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 32, 32, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 32, 32, 256)  1024        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 32, 32, 256)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 32, 32, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 32, 32, 1024) 4096        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_12 (Gl (None, 1024)         0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 64)           65536       global_average_pooling2d_12[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 1024)         65536       dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_12 (Multiply)          (None, 32, 32, 1024) 0           batch_normalization_40[0][0]     \n",
      "                                                                 dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 32, 32, 1024) 0           multiply_12[0][0]                \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 32, 32, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 32, 32, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 32, 32, 256)  1024        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 32, 32, 256)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 32, 32, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 32, 32, 256)  1024        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 32, 32, 256)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 32, 32, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 32, 32, 1024) 4096        conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_13 (Gl (None, 1024)         0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 64)           65536       global_average_pooling2d_13[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 1024)         65536       dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_13 (Multiply)          (None, 32, 32, 1024) 0           batch_normalization_43[0][0]     \n",
      "                                                                 dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 32, 32, 1024) 0           multiply_13[0][0]                \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 32, 32, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 32, 32, 512)  524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 32, 32, 512)  2048        conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 32, 32, 512)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 32, 32, 512)  2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 32, 32, 512)  2048        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 32, 32, 512)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 32, 32, 2048) 1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 32, 32, 2048) 2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 32, 32, 2048) 8192        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 32, 32, 2048) 8192        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 32, 32, 2048) 0           batch_normalization_46[0][0]     \n",
      "                                                                 batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 32, 32, 2048) 0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 32, 32, 512)  1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 32, 32, 512)  2048        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 32, 32, 512)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 32, 32, 512)  2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 32, 32, 512)  2048        conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 32, 32, 512)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 32, 32, 2048) 1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 32, 32, 2048) 8192        conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 32, 32, 2048) 0           batch_normalization_50[0][0]     \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 32, 32, 2048) 0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 32, 32, 512)  1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 32, 32, 512)  2048        conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 32, 32, 512)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 32, 32, 512)  2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 32, 32, 512)  2048        conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 32, 32, 512)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 32, 32, 2048) 1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 32, 32, 2048) 8192        conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 32, 32, 2048) 0           batch_normalization_53[0][0]     \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 32, 32, 2048) 0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 2048)   0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 2, 2, 2048)   0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 3, 3, 2048)   0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 6, 6, 2048)   0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 1, 1, 512)    1049088     average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 2, 2, 512)    1049088     average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 3, 3, 512)    1049088     average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 6, 6, 512)    1049088     average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 1, 1, 512)    2048        conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 2, 2, 512)    2048        conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 3, 3, 512)    2048        conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 6, 6, 512)    2048        conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 32, 32, 512)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 32, 32, 512)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 32, 32, 512)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 32, 32, 512)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 4096) 0           activation_49[0][0]              \n",
      "                                                                 lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 32, 32, 512)  18874880    concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 32, 32, 512)  2048        conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 32, 32, 512)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 512, 512, 1)  524288      activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 512, 512, 1)  0           conv2d_transpose_1[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 48,135,552\n",
      "Trainable params: 48,077,312\n",
      "Non-trainable params: 58,240\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = PSPNet50(img_size = 512)\n",
    "model.summary()\n",
    "adam_opt = Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(optimizer= adam_opt, loss=dice_coef_loss, \n",
    "              metrics=[dice_coef, 'acc','mse', Jaccard_index, Specificity, Sensitivity, precision, recall, f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "6528/6528 [==============================] - 2465s 378ms/step - loss: -0.1536 - dice_coef: 0.1536 - acc: 0.6705 - mean_squared_error: 0.1830 - Jaccard_index: 0.0854 - Specificity: 0.9636 - Sensitivity: 1.1745 - precision: 0.1104 - recall: 0.4159 - f1score: nan - val_loss: -0.1864 - val_dice_coef: 0.1864 - val_acc: 0.7188 - val_mean_squared_error: 0.1460 - val_Jaccard_index: 0.1079 - val_Specificity: 0.9530 - val_Sensitivity: 1.1009 - val_precision: 0.1518 - val_recall: 0.3371 - val_f1score: nan\n",
      "Epoch 2/150\n",
      "6528/6528 [==============================] - 2451s 376ms/step - loss: -0.6688 - dice_coef: 0.6688 - acc: 0.8248 - mean_squared_error: 0.0230 - Jaccard_index: 0.5243 - Specificity: 0.9703 - Sensitivity: 1.0102 - precision: 0.7423 - recall: 0.7154 - f1score: nan - val_loss: -0.6782 - val_dice_coef: 0.6782 - val_acc: 0.8263 - val_mean_squared_error: 0.0210 - val_Jaccard_index: 0.5318 - val_Specificity: 0.9608 - val_Sensitivity: 0.9936 - val_precision: 0.8985 - val_recall: 0.6273 - val_f1score: 0.7192\n",
      "Epoch 3/150\n",
      "6528/6528 [==============================] - 2448s 375ms/step - loss: -0.8278 - dice_coef: 0.8278 - acc: 0.8362 - mean_squared_error: 0.0082 - Jaccard_index: 0.7108 - Specificity: 0.9738 - Sensitivity: 1.0034 - precision: 0.9105 - recall: 0.8785 - f1score: 0.8927 - val_loss: -0.7337 - val_dice_coef: 0.7337 - val_acc: 0.8257 - val_mean_squared_error: 0.0189 - val_Jaccard_index: 0.5975 - val_Specificity: 0.9638 - val_Sensitivity: 1.0006 - val_precision: 0.8674 - val_recall: 0.7545 - val_f1score: nan\n",
      "Epoch 4/150\n",
      "6528/6528 [==============================] - 2452s 376ms/step - loss: -0.8628 - dice_coef: 0.8628 - acc: 0.8378 - mean_squared_error: 0.0059 - Jaccard_index: 0.7623 - Specificity: 0.9747 - Sensitivity: 1.0032 - precision: 0.9422 - recall: 0.9229 - f1score: 0.9318 - val_loss: -0.7601 - val_dice_coef: 0.7601 - val_acc: 0.8269 - val_mean_squared_error: 0.0169 - val_Jaccard_index: 0.6301 - val_Specificity: 0.9646 - val_Sensitivity: 1.0006 - val_precision: 0.8886 - val_recall: 0.7880 - val_f1score: 0.8191\n",
      "Epoch 5/150\n",
      "6528/6528 [==============================] - 2452s 376ms/step - loss: -0.8771 - dice_coef: 0.8771 - acc: 0.8385 - mean_squared_error: 0.0049 - Jaccard_index: 0.7846 - Specificity: 0.9750 - Sensitivity: 1.0031 - precision: 0.9555 - recall: 0.9412 - f1score: 0.9479 - val_loss: -0.7570 - val_dice_coef: 0.7570 - val_acc: 0.8284 - val_mean_squared_error: 0.0167 - val_Jaccard_index: 0.6297 - val_Specificity: 0.9635 - val_Sensitivity: 0.9965 - val_precision: 0.9340 - val_recall: 0.7483 - val_f1score: 0.8119\n",
      "Epoch 6/150\n",
      "6528/6528 [==============================] - 2451s 375ms/step - loss: -0.8865 - dice_coef: 0.8865 - acc: 0.8389 - mean_squared_error: 0.0043 - Jaccard_index: 0.7994 - Specificity: 0.9752 - Sensitivity: 1.0030 - precision: 0.9643 - recall: 0.9533 - f1score: 0.9585 - val_loss: -0.7648 - val_dice_coef: 0.7648 - val_acc: 0.8285 - val_mean_squared_error: 0.0162 - val_Jaccard_index: 0.6384 - val_Specificity: 0.9638 - val_Sensitivity: 0.9968 - val_precision: 0.9332 - val_recall: 0.7596 - val_f1score: 0.8207\n",
      "Epoch 7/150\n",
      "6528/6528 [==============================] - 2451s 375ms/step - loss: -0.8932 - dice_coef: 0.8932 - acc: 0.8392 - mean_squared_error: 0.0038 - Jaccard_index: 0.8103 - Specificity: 0.9754 - Sensitivity: 1.0030 - precision: 0.9698 - recall: 0.9629 - f1score: 0.9662 - val_loss: -0.7558 - val_dice_coef: 0.7558 - val_acc: 0.8283 - val_mean_squared_error: 0.0171 - val_Jaccard_index: 0.6294 - val_Specificity: 0.9632 - val_Sensitivity: 0.9960 - val_precision: 0.9368 - val_recall: 0.7459 - val_f1score: 0.8113\n",
      "Epoch 8/150\n",
      "6528/6528 [==============================] - 2439s 374ms/step - loss: -0.8980 - dice_coef: 0.8980 - acc: 0.8394 - mean_squared_error: 0.0035 - Jaccard_index: 0.8180 - Specificity: 0.9755 - Sensitivity: 1.0030 - precision: 0.9739 - recall: 0.9683 - f1score: 0.9710 - val_loss: -0.7700 - val_dice_coef: 0.7700 - val_acc: 0.8286 - val_mean_squared_error: 0.0160 - val_Jaccard_index: 0.6452 - val_Specificity: 0.9640 - val_Sensitivity: 0.9972 - val_precision: 0.9343 - val_recall: 0.7696 - val_f1score: 0.8274\n",
      "Epoch 9/150\n",
      "6528/6528 [==============================] - 2439s 374ms/step - loss: -0.9000 - dice_coef: 0.9000 - acc: 0.8395 - mean_squared_error: 0.0033 - Jaccard_index: 0.8215 - Specificity: 0.9756 - Sensitivity: 1.0029 - precision: 0.9762 - recall: 0.9709 - f1score: 0.9735 - val_loss: -0.7757 - val_dice_coef: 0.7757 - val_acc: 0.8283 - val_mean_squared_error: 0.0160 - val_Jaccard_index: 0.6538 - val_Specificity: 0.9644 - val_Sensitivity: 0.9983 - val_precision: 0.9244 - val_recall: 0.7911 - val_f1score: 0.8355\n",
      "Epoch 10/150\n",
      "6528/6528 [==============================] - 2441s 374ms/step - loss: -0.9024 - dice_coef: 0.9024 - acc: 0.8396 - mean_squared_error: 0.0032 - Jaccard_index: 0.8254 - Specificity: 0.9756 - Sensitivity: 1.0029 - precision: 0.9789 - recall: 0.9741 - f1score: 0.9765 - val_loss: -0.7804 - val_dice_coef: 0.7804 - val_acc: 0.8285 - val_mean_squared_error: 0.0157 - val_Jaccard_index: 0.6596 - val_Specificity: 0.9645 - val_Sensitivity: 0.9982 - val_precision: 0.9283 - val_recall: 0.7964 - val_f1score: 0.8404\n",
      "Epoch 11/150\n",
      "6528/6528 [==============================] - 2441s 374ms/step - loss: -0.9042 - dice_coef: 0.9042 - acc: 0.8397 - mean_squared_error: 0.0030 - Jaccard_index: 0.8283 - Specificity: 0.9757 - Sensitivity: 1.0028 - precision: 0.9806 - recall: 0.9760 - f1score: 0.9782 - val_loss: -0.7707 - val_dice_coef: 0.7707 - val_acc: 0.8284 - val_mean_squared_error: 0.0165 - val_Jaccard_index: 0.6488 - val_Specificity: 0.9639 - val_Sensitivity: 0.9973 - val_precision: 0.9327 - val_recall: 0.7776 - val_f1score: 0.8289\n",
      "Epoch 12/150\n",
      "6528/6528 [==============================] - 2442s 374ms/step - loss: -0.9054 - dice_coef: 0.9054 - acc: 0.8398 - mean_squared_error: 0.0029 - Jaccard_index: 0.8305 - Specificity: 0.9757 - Sensitivity: 1.0028 - precision: 0.9821 - recall: 0.9779 - f1score: 0.9800 - val_loss: -0.7814 - val_dice_coef: 0.7814 - val_acc: 0.8288 - val_mean_squared_error: 0.0155 - val_Jaccard_index: 0.6593 - val_Specificity: 0.9643 - val_Sensitivity: 0.9976 - val_precision: 0.9367 - val_recall: 0.7880 - val_f1score: 0.8403\n",
      "Epoch 13/150\n",
      "6528/6528 [==============================] - 2439s 374ms/step - loss: -0.9064 - dice_coef: 0.9064 - acc: 0.8398 - mean_squared_error: 0.0029 - Jaccard_index: 0.8322 - Specificity: 0.9757 - Sensitivity: 1.0028 - precision: 0.9832 - recall: 0.9791 - f1score: 0.9811 - val_loss: -0.7769 - val_dice_coef: 0.7769 - val_acc: 0.8285 - val_mean_squared_error: 0.0161 - val_Jaccard_index: 0.6549 - val_Specificity: 0.9640 - val_Sensitivity: 0.9974 - val_precision: 0.9339 - val_recall: 0.7843 - val_f1score: 0.8356\n",
      "Epoch 14/150\n",
      "6528/6528 [==============================] - 2441s 374ms/step - loss: -0.9075 - dice_coef: 0.9075 - acc: 0.8399 - mean_squared_error: 0.0028 - Jaccard_index: 0.8340 - Specificity: 0.9757 - Sensitivity: 1.0028 - precision: 0.9843 - recall: 0.9804 - f1score: 0.9823 - val_loss: -0.7754 - val_dice_coef: 0.7754 - val_acc: 0.8285 - val_mean_squared_error: 0.0161 - val_Jaccard_index: 0.6531 - val_Specificity: 0.9641 - val_Sensitivity: 0.9974 - val_precision: 0.9347 - val_recall: 0.7827 - val_f1score: 0.8343\n",
      "Epoch 15/150\n",
      "6528/6528 [==============================] - 2442s 374ms/step - loss: -0.9084 - dice_coef: 0.9084 - acc: 0.8399 - mean_squared_error: 0.0027 - Jaccard_index: 0.8355 - Specificity: 0.9758 - Sensitivity: 1.0028 - precision: 0.9853 - recall: 0.9813 - f1score: 0.9833 - val_loss: -0.7791 - val_dice_coef: 0.7791 - val_acc: 0.8286 - val_mean_squared_error: 0.0158 - val_Jaccard_index: 0.6576 - val_Specificity: 0.9643 - val_Sensitivity: 0.9979 - val_precision: 0.9313 - val_recall: 0.7920 - val_f1score: 0.8389\n",
      "Epoch 16/150\n",
      "6528/6528 [==============================] - 2442s 374ms/step - loss: -0.9091 - dice_coef: 0.9091 - acc: 0.8400 - mean_squared_error: 0.0027 - Jaccard_index: 0.8367 - Specificity: 0.9758 - Sensitivity: 1.0028 - precision: 0.9860 - recall: 0.9823 - f1score: 0.9841 - val_loss: -0.7773 - val_dice_coef: 0.7773 - val_acc: 0.8286 - val_mean_squared_error: 0.0160 - val_Jaccard_index: 0.6562 - val_Specificity: 0.9641 - val_Sensitivity: 0.9974 - val_precision: 0.9353 - val_recall: 0.7863 - val_f1score: 0.8366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/150\n",
      "6528/6528 [==============================] - 2441s 374ms/step - loss: -0.9097 - dice_coef: 0.9097 - acc: 0.8400 - mean_squared_error: 0.0026 - Jaccard_index: 0.8377 - Specificity: 0.9758 - Sensitivity: 1.0027 - precision: 0.9867 - recall: 0.9829 - f1score: 0.9847 - val_loss: -0.7808 - val_dice_coef: 0.7808 - val_acc: 0.8284 - val_mean_squared_error: 0.0159 - val_Jaccard_index: 0.6604 - val_Specificity: 0.9645 - val_Sensitivity: 0.9983 - val_precision: 0.9274 - val_recall: 0.7985 - val_f1score: 0.8408\n",
      "Epoch 18/150\n",
      "6528/6528 [==============================] - 2439s 374ms/step - loss: -0.9101 - dice_coef: 0.9101 - acc: 0.8400 - mean_squared_error: 0.0026 - Jaccard_index: 0.8383 - Specificity: 0.9758 - Sensitivity: 1.0027 - precision: 0.9872 - recall: 0.9836 - f1score: 0.9854 - val_loss: -0.7796 - val_dice_coef: 0.7796 - val_acc: 0.8286 - val_mean_squared_error: 0.0158 - val_Jaccard_index: 0.6586 - val_Specificity: 0.9644 - val_Sensitivity: 0.9979 - val_precision: 0.9316 - val_recall: 0.7929 - val_f1score: 0.8389\n",
      "Epoch 19/150\n",
      "6528/6528 [==============================] - 2438s 373ms/step - loss: -0.9108 - dice_coef: 0.9108 - acc: 0.8400 - mean_squared_error: 0.0026 - Jaccard_index: 0.8395 - Specificity: 0.9758 - Sensitivity: 1.0027 - precision: 0.9877 - recall: 0.9842 - f1score: 0.9860 - val_loss: -0.7760 - val_dice_coef: 0.7760 - val_acc: 0.8288 - val_mean_squared_error: 0.0160 - val_Jaccard_index: 0.6548 - val_Specificity: 0.9639 - val_Sensitivity: 0.9966 - val_precision: 0.9438 - val_recall: 0.7763 - val_f1score: nan\n",
      "Epoch 20/150\n",
      "6528/6528 [==============================] - 2441s 374ms/step - loss: -0.9111 - dice_coef: 0.9111 - acc: 0.8401 - mean_squared_error: 0.0025 - Jaccard_index: 0.8401 - Specificity: 0.9758 - Sensitivity: 1.0027 - precision: 0.9880 - recall: 0.9845 - f1score: 0.9862 - val_loss: -0.7807 - val_dice_coef: 0.7807 - val_acc: 0.8288 - val_mean_squared_error: 0.0158 - val_Jaccard_index: 0.6611 - val_Specificity: 0.9642 - val_Sensitivity: 0.9974 - val_precision: 0.9387 - val_recall: 0.7904 - val_f1score: 0.8405\n",
      "Epoch 21/150\n",
      "6528/6528 [==============================] - 2441s 374ms/step - loss: -0.9115 - dice_coef: 0.9115 - acc: 0.8401 - mean_squared_error: 0.0025 - Jaccard_index: 0.8407 - Specificity: 0.9758 - Sensitivity: 1.0027 - precision: 0.9886 - recall: 0.9852 - f1score: 0.9869 - val_loss: -0.7736 - val_dice_coef: 0.7736 - val_acc: 0.8287 - val_mean_squared_error: 0.0161 - val_Jaccard_index: 0.6533 - val_Specificity: 0.9640 - val_Sensitivity: 0.9971 - val_precision: 0.9391 - val_recall: 0.7811 - val_f1score: 0.8332\n",
      "Epoch 22/150\n",
      "6528/6528 [==============================] - 2441s 374ms/step - loss: -0.9120 - dice_coef: 0.9120 - acc: 0.8401 - mean_squared_error: 0.0025 - Jaccard_index: 0.8416 - Specificity: 0.9758 - Sensitivity: 1.0027 - precision: 0.9890 - recall: 0.9856 - f1score: 0.9873 - val_loss: -0.7820 - val_dice_coef: 0.7820 - val_acc: 0.8287 - val_mean_squared_error: 0.0157 - val_Jaccard_index: 0.6621 - val_Specificity: 0.9644 - val_Sensitivity: 0.9979 - val_precision: 0.9335 - val_recall: 0.7964 - val_f1score: 0.8422\n",
      "Epoch 23/150\n",
      "6528/6528 [==============================] - 2439s 374ms/step - loss: -0.9120 - dice_coef: 0.9120 - acc: 0.8401 - mean_squared_error: 0.0024 - Jaccard_index: 0.8416 - Specificity: 0.9759 - Sensitivity: 1.0027 - precision: 0.9894 - recall: 0.9861 - f1score: 0.9877 - val_loss: -0.7778 - val_dice_coef: 0.7778 - val_acc: 0.8287 - val_mean_squared_error: 0.0160 - val_Jaccard_index: 0.6574 - val_Specificity: 0.9641 - val_Sensitivity: 0.9972 - val_precision: 0.9396 - val_recall: 0.7837 - val_f1score: 0.8359\n",
      "Epoch 24/150\n",
      "6528/6528 [==============================] - 2438s 373ms/step - loss: -0.9122 - dice_coef: 0.9122 - acc: 0.8401 - mean_squared_error: 0.0024 - Jaccard_index: 0.8420 - Specificity: 0.9758 - Sensitivity: 1.0027 - precision: 0.9897 - recall: 0.9861 - f1score: 0.9879 - val_loss: -0.7770 - val_dice_coef: 0.7770 - val_acc: 0.8287 - val_mean_squared_error: 0.0160 - val_Jaccard_index: 0.6582 - val_Specificity: 0.9641 - val_Sensitivity: 0.9972 - val_precision: 0.9400 - val_recall: 0.7859 - val_f1score: 0.8363\n",
      "Epoch 25/150\n",
      "6528/6528 [==============================] - 2442s 374ms/step - loss: -0.9129 - dice_coef: 0.9129 - acc: 0.8401 - mean_squared_error: 0.0024 - Jaccard_index: 0.8432 - Specificity: 0.9759 - Sensitivity: 1.0027 - precision: 0.9901 - recall: 0.9869 - f1score: 0.9884 - val_loss: -0.7759 - val_dice_coef: 0.7759 - val_acc: 0.8287 - val_mean_squared_error: 0.0161 - val_Jaccard_index: 0.6564 - val_Specificity: 0.9640 - val_Sensitivity: 0.9972 - val_precision: 0.9384 - val_recall: 0.7850 - val_f1score: 0.8350\n",
      "Epoch 26/150\n",
      "6528/6528 [==============================] - 2453s 376ms/step - loss: -0.9130 - dice_coef: 0.9130 - acc: 0.8402 - mean_squared_error: 0.0024 - Jaccard_index: 0.8434 - Specificity: 0.9759 - Sensitivity: 1.0027 - precision: 0.9903 - recall: 0.9871 - f1score: 0.9887 - val_loss: -0.7768 - val_dice_coef: 0.7768 - val_acc: 0.8287 - val_mean_squared_error: 0.0160 - val_Jaccard_index: 0.6559 - val_Specificity: 0.9641 - val_Sensitivity: 0.9973 - val_precision: 0.9381 - val_recall: 0.7848 - val_f1score: 0.8363\n",
      "Epoch 27/150\n",
      "6528/6528 [==============================] - 2455s 376ms/step - loss: -0.9133 - dice_coef: 0.9133 - acc: 0.8402 - mean_squared_error: 0.0024 - Jaccard_index: 0.8438 - Specificity: 0.9759 - Sensitivity: 1.0027 - precision: 0.9906 - recall: 0.9874 - f1score: 0.9890 - val_loss: -0.7778 - val_dice_coef: 0.7778 - val_acc: 0.8286 - val_mean_squared_error: 0.0160 - val_Jaccard_index: 0.6578 - val_Specificity: 0.9642 - val_Sensitivity: 0.9978 - val_precision: 0.9324 - val_recall: 0.7919 - val_f1score: 0.8376\n",
      "Epoch 28/150\n",
      "6528/6528 [==============================] - 2452s 376ms/step - loss: -0.9135 - dice_coef: 0.9135 - acc: 0.8402 - mean_squared_error: 0.0023 - Jaccard_index: 0.8441 - Specificity: 0.9759 - Sensitivity: 1.0027 - precision: 0.9909 - recall: 0.9878 - f1score: 0.9893 - val_loss: -0.7812 - val_dice_coef: 0.7812 - val_acc: 0.8286 - val_mean_squared_error: 0.0158 - val_Jaccard_index: 0.6619 - val_Specificity: 0.9643 - val_Sensitivity: 0.9979 - val_precision: 0.9344 - val_recall: 0.7961 - val_f1score: 0.8411\n",
      "Epoch 29/150\n",
      "6528/6528 [==============================] - 2454s 376ms/step - loss: -0.9137 - dice_coef: 0.9137 - acc: 0.8402 - mean_squared_error: 0.0023 - Jaccard_index: 0.8443 - Specificity: 0.9759 - Sensitivity: 1.0027 - precision: 0.9911 - recall: 0.9880 - f1score: 0.9896 - val_loss: -0.7787 - val_dice_coef: 0.7787 - val_acc: 0.8287 - val_mean_squared_error: 0.0160 - val_Jaccard_index: 0.6585 - val_Specificity: 0.9641 - val_Sensitivity: 0.9974 - val_precision: 0.9374 - val_recall: 0.7885 - val_f1score: 0.8385\n",
      "Epoch 30/150\n",
      "6528/6528 [==============================] - 2454s 376ms/step - loss: -0.9141 - dice_coef: 0.9141 - acc: 0.8402 - mean_squared_error: 0.0023 - Jaccard_index: 0.8451 - Specificity: 0.9759 - Sensitivity: 1.0027 - precision: 0.9915 - recall: 0.9882 - f1score: 0.9898 - val_loss: -0.7767 - val_dice_coef: 0.7767 - val_acc: 0.8286 - val_mean_squared_error: 0.0161 - val_Jaccard_index: 0.6566 - val_Specificity: 0.9641 - val_Sensitivity: 0.9973 - val_precision: 0.9378 - val_recall: 0.7863 - val_f1score: 0.8363\n",
      "Epoch 31/150\n",
      "6528/6528 [==============================] - 2455s 376ms/step - loss: -0.9143 - dice_coef: 0.9143 - acc: 0.8402 - mean_squared_error: 0.0023 - Jaccard_index: 0.8456 - Specificity: 0.9759 - Sensitivity: 1.0027 - precision: 0.9917 - recall: 0.9886 - f1score: 0.9901 - val_loss: -0.7788 - val_dice_coef: 0.7788 - val_acc: 0.8287 - val_mean_squared_error: 0.0159 - val_Jaccard_index: 0.6585 - val_Specificity: 0.9642 - val_Sensitivity: 0.9976 - val_precision: 0.9354 - val_recall: 0.7910 - val_f1score: 0.8390\n",
      "Epoch 32/150\n",
      "6528/6528 [==============================] - 2454s 376ms/step - loss: -0.9147 - dice_coef: 0.9147 - acc: 0.8402 - mean_squared_error: 0.0023 - Jaccard_index: 0.8461 - Specificity: 0.9759 - Sensitivity: 1.0027 - precision: 0.9920 - recall: 0.9889 - f1score: 0.9904 - val_loss: -0.7795 - val_dice_coef: 0.7795 - val_acc: 0.8288 - val_mean_squared_error: 0.0160 - val_Jaccard_index: 0.6599 - val_Specificity: 0.9641 - val_Sensitivity: 0.9972 - val_precision: 0.9405 - val_recall: 0.7891 - val_f1score: 0.8393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/150\n",
      "6528/6528 [==============================] - 2457s 376ms/step - loss: -0.9147 - dice_coef: 0.9147 - acc: 0.8402 - mean_squared_error: 0.0022 - Jaccard_index: 0.8461 - Specificity: 0.9759 - Sensitivity: 1.0027 - precision: 0.9922 - recall: 0.9892 - f1score: 0.9907 - val_loss: -0.7803 - val_dice_coef: 0.7803 - val_acc: 0.8287 - val_mean_squared_error: 0.0158 - val_Jaccard_index: 0.6595 - val_Specificity: 0.9643 - val_Sensitivity: 0.9977 - val_precision: 0.9362 - val_recall: 0.7908 - val_f1score: 0.8403\n",
      "Epoch 34/150\n",
      "6528/6528 [==============================] - 2461s 377ms/step - loss: -0.9151 - dice_coef: 0.9151 - acc: 0.8402 - mean_squared_error: 0.0022 - Jaccard_index: 0.8468 - Specificity: 0.9759 - Sensitivity: 1.0026 - precision: 0.9925 - recall: 0.9895 - f1score: 0.9909 - val_loss: -0.7858 - val_dice_coef: 0.7858 - val_acc: 0.8287 - val_mean_squared_error: 0.0154 - val_Jaccard_index: 0.6660 - val_Specificity: 0.9647 - val_Sensitivity: 0.9985 - val_precision: 0.9298 - val_recall: 0.8046 - val_f1score: 0.8460\n",
      "Epoch 35/150\n",
      "6528/6528 [==============================] - 2455s 376ms/step - loss: -0.9153 - dice_coef: 0.9153 - acc: 0.8402 - mean_squared_error: 0.0022 - Jaccard_index: 0.8472 - Specificity: 0.9759 - Sensitivity: 1.0026 - precision: 0.9926 - recall: 0.9897 - f1score: 0.9911 - val_loss: -0.7757 - val_dice_coef: 0.7757 - val_acc: 0.8287 - val_mean_squared_error: 0.0160 - val_Jaccard_index: 0.6553 - val_Specificity: 0.9641 - val_Sensitivity: 0.9972 - val_precision: 0.9387 - val_recall: 0.7831 - val_f1score: 0.8348\n",
      "Epoch 36/150\n",
      "6528/6528 [==============================] - 2455s 376ms/step - loss: -0.9152 - dice_coef: 0.9152 - acc: 0.8403 - mean_squared_error: 0.0022 - Jaccard_index: 0.8472 - Specificity: 0.9759 - Sensitivity: 1.0026 - precision: 0.9929 - recall: 0.9900 - f1score: 0.9914 - val_loss: -0.7811 - val_dice_coef: 0.7811 - val_acc: 0.8286 - val_mean_squared_error: 0.0157 - val_Jaccard_index: 0.6603 - val_Specificity: 0.9644 - val_Sensitivity: 0.9980 - val_precision: 0.9324 - val_recall: 0.7956 - val_f1score: 0.8414\n",
      "Epoch 37/150\n",
      "6528/6528 [==============================] - 2453s 376ms/step - loss: -0.9154 - dice_coef: 0.9154 - acc: 0.8403 - mean_squared_error: 0.0022 - Jaccard_index: 0.8474 - Specificity: 0.9759 - Sensitivity: 1.0026 - precision: 0.9930 - recall: 0.9902 - f1score: 0.9916 - val_loss: -0.7769 - val_dice_coef: 0.7769 - val_acc: 0.8287 - val_mean_squared_error: 0.0161 - val_Jaccard_index: 0.6569 - val_Specificity: 0.9640 - val_Sensitivity: 0.9971 - val_precision: 0.9395 - val_recall: 0.7835 - val_f1score: 0.8358\n",
      "Epoch 38/150\n",
      "6528/6528 [==============================] - 2453s 376ms/step - loss: -0.9155 - dice_coef: 0.9155 - acc: 0.8403 - mean_squared_error: 0.0022 - Jaccard_index: 0.8476 - Specificity: 0.9759 - Sensitivity: 1.0026 - precision: 0.9932 - recall: 0.9904 - f1score: 0.9918 - val_loss: -0.7799 - val_dice_coef: 0.7799 - val_acc: 0.8289 - val_mean_squared_error: 0.0157 - val_Jaccard_index: 0.6603 - val_Specificity: 0.9641 - val_Sensitivity: 0.9971 - val_precision: 0.9426 - val_recall: 0.7871 - val_f1score: 0.8394\n",
      "Epoch 39/150\n",
      "6528/6528 [==============================] - 2455s 376ms/step - loss: -0.9158 - dice_coef: 0.9158 - acc: 0.8403 - mean_squared_error: 0.0022 - Jaccard_index: 0.8481 - Specificity: 0.9759 - Sensitivity: 1.0026 - precision: 0.9935 - recall: 0.9907 - f1score: 0.9921 - val_loss: -0.7805 - val_dice_coef: 0.7805 - val_acc: 0.8288 - val_mean_squared_error: 0.0156 - val_Jaccard_index: 0.6602 - val_Specificity: 0.9643 - val_Sensitivity: 0.9977 - val_precision: 0.9360 - val_recall: 0.7908 - val_f1score: 0.8396\n",
      "Epoch 40/150\n",
      "6528/6528 [==============================] - 2457s 376ms/step - loss: -0.9160 - dice_coef: 0.9160 - acc: 0.8403 - mean_squared_error: 0.0021 - Jaccard_index: 0.8484 - Specificity: 0.9759 - Sensitivity: 1.0026 - precision: 0.9937 - recall: 0.9910 - f1score: 0.9923 - val_loss: -0.7812 - val_dice_coef: 0.7812 - val_acc: 0.8289 - val_mean_squared_error: 0.0156 - val_Jaccard_index: 0.6608 - val_Specificity: 0.9643 - val_Sensitivity: 0.9975 - val_precision: 0.9384 - val_recall: 0.7904 - val_f1score: 0.8407\n",
      "Epoch 41/150\n",
      "6528/6528 [==============================] - 2454s 376ms/step - loss: -0.9158 - dice_coef: 0.9158 - acc: 0.8403 - mean_squared_error: 0.0021 - Jaccard_index: 0.8482 - Specificity: 0.9759 - Sensitivity: 1.0026 - precision: 0.9938 - recall: 0.9912 - f1score: 0.9925 - val_loss: -0.7819 - val_dice_coef: 0.7819 - val_acc: 0.8286 - val_mean_squared_error: 0.0157 - val_Jaccard_index: 0.6612 - val_Specificity: 0.9644 - val_Sensitivity: 0.9980 - val_precision: 0.9317 - val_recall: 0.7961 - val_f1score: 0.8415\n",
      "Epoch 42/150\n",
      "6528/6528 [==============================] - 2449s 375ms/step - loss: -0.9163 - dice_coef: 0.9163 - acc: 0.8403 - mean_squared_error: 0.0021 - Jaccard_index: 0.8489 - Specificity: 0.9759 - Sensitivity: 1.0026 - precision: 0.9940 - recall: 0.9914 - f1score: 0.9927 - val_loss: -0.7698 - val_dice_coef: 0.7698 - val_acc: 0.8287 - val_mean_squared_error: 0.0164 - val_Jaccard_index: 0.6486 - val_Specificity: 0.9637 - val_Sensitivity: 0.9965 - val_precision: 0.9435 - val_recall: 0.7709 - val_f1score: 0.8284\n",
      "Epoch 43/150\n",
      "6528/6528 [==============================] - 2449s 375ms/step - loss: -0.9168 - dice_coef: 0.9168 - acc: 0.8403 - mean_squared_error: 0.0021 - Jaccard_index: 0.8499 - Specificity: 0.9759 - Sensitivity: 1.0026 - precision: 0.9942 - recall: 0.9916 - f1score: 0.9929 - val_loss: -0.7759 - val_dice_coef: 0.7759 - val_acc: 0.8288 - val_mean_squared_error: 0.0160 - val_Jaccard_index: 0.6560 - val_Specificity: 0.9640 - val_Sensitivity: 0.9969 - val_precision: 0.9408 - val_recall: 0.7818 - val_f1score: 0.8344\n",
      "Epoch 44/150\n",
      "6528/6528 [==============================] - 2449s 375ms/step - loss: -0.9163 - dice_coef: 0.9163 - acc: 0.8403 - mean_squared_error: 0.0021 - Jaccard_index: 0.8490 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9944 - recall: 0.9917 - f1score: 0.9930 - val_loss: -0.7763 - val_dice_coef: 0.7763 - val_acc: 0.8287 - val_mean_squared_error: 0.0160 - val_Jaccard_index: 0.6568 - val_Specificity: 0.9641 - val_Sensitivity: 0.9972 - val_precision: 0.9391 - val_recall: 0.7851 - val_f1score: 0.8357\n",
      "Epoch 45/150\n",
      "6528/6528 [==============================] - 2450s 375ms/step - loss: -0.9164 - dice_coef: 0.9164 - acc: 0.8403 - mean_squared_error: 0.0021 - Jaccard_index: 0.8492 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9945 - recall: 0.9919 - f1score: 0.9932 - val_loss: -0.7735 - val_dice_coef: 0.7735 - val_acc: 0.8287 - val_mean_squared_error: 0.0161 - val_Jaccard_index: 0.6536 - val_Specificity: 0.9639 - val_Sensitivity: 0.9969 - val_precision: 0.9421 - val_recall: 0.7791 - val_f1score: 0.8325\n",
      "Epoch 46/150\n",
      "6528/6528 [==============================] - 2447s 375ms/step - loss: -0.9171 - dice_coef: 0.9171 - acc: 0.8403 - mean_squared_error: 0.0021 - Jaccard_index: 0.8503 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9947 - recall: 0.9921 - f1score: 0.9934 - val_loss: -0.7715 - val_dice_coef: 0.7715 - val_acc: 0.8286 - val_mean_squared_error: 0.0163 - val_Jaccard_index: 0.6503 - val_Specificity: 0.9639 - val_Sensitivity: 0.9969 - val_precision: 0.9390 - val_recall: 0.7766 - val_f1score: 0.8304\n",
      "Epoch 47/150\n",
      "6528/6528 [==============================] - 2449s 375ms/step - loss: -0.9170 - dice_coef: 0.9170 - acc: 0.8403 - mean_squared_error: 0.0021 - Jaccard_index: 0.8502 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9947 - recall: 0.9921 - f1score: 0.9934 - val_loss: -0.7780 - val_dice_coef: 0.7780 - val_acc: 0.8286 - val_mean_squared_error: 0.0161 - val_Jaccard_index: 0.6588 - val_Specificity: 0.9642 - val_Sensitivity: 0.9976 - val_precision: 0.9349 - val_recall: 0.7925 - val_f1score: 0.8380\n",
      "Epoch 48/150\n",
      "6528/6528 [==============================] - 2448s 375ms/step - loss: -0.9169 - dice_coef: 0.9169 - acc: 0.8403 - mean_squared_error: 0.0021 - Jaccard_index: 0.8501 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9950 - recall: 0.9924 - f1score: 0.9937 - val_loss: -0.7820 - val_dice_coef: 0.7820 - val_acc: 0.8287 - val_mean_squared_error: 0.0157 - val_Jaccard_index: 0.6624 - val_Specificity: 0.9643 - val_Sensitivity: 0.9978 - val_precision: 0.9345 - val_recall: 0.7965 - val_f1score: 0.8421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/150\n",
      "6528/6528 [==============================] - 2449s 375ms/step - loss: -0.9172 - dice_coef: 0.9172 - acc: 0.8403 - mean_squared_error: 0.0021 - Jaccard_index: 0.8506 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9951 - recall: 0.9926 - f1score: 0.9938 - val_loss: -0.7723 - val_dice_coef: 0.7723 - val_acc: 0.8286 - val_mean_squared_error: 0.0163 - val_Jaccard_index: 0.6514 - val_Specificity: 0.9639 - val_Sensitivity: 0.9969 - val_precision: 0.9401 - val_recall: 0.7781 - val_f1score: 0.8314\n",
      "Epoch 50/150\n",
      "6528/6528 [==============================] - 2448s 375ms/step - loss: -0.9175 - dice_coef: 0.9175 - acc: 0.8403 - mean_squared_error: 0.0020 - Jaccard_index: 0.8509 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9953 - recall: 0.9927 - f1score: 0.9940 - val_loss: -0.7762 - val_dice_coef: 0.7762 - val_acc: 0.8286 - val_mean_squared_error: 0.0160 - val_Jaccard_index: 0.6560 - val_Specificity: 0.9641 - val_Sensitivity: 0.9974 - val_precision: 0.9368 - val_recall: 0.7876 - val_f1score: 0.8364\n",
      "Epoch 51/150\n",
      "6528/6528 [==============================] - 2450s 375ms/step - loss: -0.9176 - dice_coef: 0.9176 - acc: 0.8404 - mean_squared_error: 0.0020 - Jaccard_index: 0.8511 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9954 - recall: 0.9930 - f1score: 0.9942 - val_loss: -0.7748 - val_dice_coef: 0.7748 - val_acc: 0.8287 - val_mean_squared_error: 0.0162 - val_Jaccard_index: 0.6538 - val_Specificity: 0.9639 - val_Sensitivity: 0.9968 - val_precision: 0.9416 - val_recall: 0.7793 - val_f1score: 0.8338\n",
      "Epoch 52/150\n",
      "6528/6528 [==============================] - 2452s 376ms/step - loss: -0.9179 - dice_coef: 0.9179 - acc: 0.8404 - mean_squared_error: 0.0020 - Jaccard_index: 0.8517 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9956 - recall: 0.9932 - f1score: 0.9944 - val_loss: -0.7748 - val_dice_coef: 0.7748 - val_acc: 0.8286 - val_mean_squared_error: 0.0161 - val_Jaccard_index: 0.6546 - val_Specificity: 0.9640 - val_Sensitivity: 0.9973 - val_precision: 0.9379 - val_recall: 0.7833 - val_f1score: 0.8341\n",
      "Epoch 53/150\n",
      "6528/6528 [==============================] - 2450s 375ms/step - loss: -0.9178 - dice_coef: 0.9178 - acc: 0.8404 - mean_squared_error: 0.0020 - Jaccard_index: 0.8516 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9957 - recall: 0.9934 - f1score: 0.9945 - val_loss: -0.7807 - val_dice_coef: 0.7807 - val_acc: 0.8287 - val_mean_squared_error: 0.0158 - val_Jaccard_index: 0.6618 - val_Specificity: 0.9643 - val_Sensitivity: 0.9978 - val_precision: 0.9356 - val_recall: 0.7941 - val_f1score: 0.8401\n",
      "Epoch 54/150\n",
      "6528/6528 [==============================] - 2451s 376ms/step - loss: -0.9178 - dice_coef: 0.9178 - acc: 0.8404 - mean_squared_error: 0.0020 - Jaccard_index: 0.8515 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9959 - recall: 0.9935 - f1score: 0.9947 - val_loss: -0.7714 - val_dice_coef: 0.7714 - val_acc: 0.8287 - val_mean_squared_error: 0.0163 - val_Jaccard_index: 0.6498 - val_Specificity: 0.9637 - val_Sensitivity: 0.9966 - val_precision: 0.9421 - val_recall: 0.7741 - val_f1score: 0.8305\n",
      "Epoch 55/150\n",
      "6528/6528 [==============================] - 2451s 375ms/step - loss: -0.9183 - dice_coef: 0.9183 - acc: 0.8404 - mean_squared_error: 0.0020 - Jaccard_index: 0.8524 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9960 - recall: 0.9936 - f1score: 0.9948 - val_loss: -0.7736 - val_dice_coef: 0.7736 - val_acc: 0.8287 - val_mean_squared_error: 0.0161 - val_Jaccard_index: 0.6525 - val_Specificity: 0.9640 - val_Sensitivity: 0.9970 - val_precision: 0.9392 - val_recall: 0.7796 - val_f1score: 0.8328\n",
      "Epoch 56/150\n",
      "6528/6528 [==============================] - 2451s 375ms/step - loss: -0.9183 - dice_coef: 0.9183 - acc: 0.8404 - mean_squared_error: 0.0020 - Jaccard_index: 0.8524 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9961 - recall: 0.9938 - f1score: 0.9949 - val_loss: -0.7745 - val_dice_coef: 0.7745 - val_acc: 0.8287 - val_mean_squared_error: 0.0162 - val_Jaccard_index: 0.6536 - val_Specificity: 0.9638 - val_Sensitivity: 0.9967 - val_precision: 0.9437 - val_recall: 0.7773 - val_f1score: 0.8332\n",
      "Epoch 57/150\n",
      "6528/6528 [==============================] - 2451s 375ms/step - loss: -0.9183 - dice_coef: 0.9183 - acc: 0.8404 - mean_squared_error: 0.0020 - Jaccard_index: 0.8524 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9962 - recall: 0.9938 - f1score: 0.9950 - val_loss: -0.7709 - val_dice_coef: 0.7709 - val_acc: 0.8286 - val_mean_squared_error: 0.0162 - val_Jaccard_index: 0.6500 - val_Specificity: 0.9639 - val_Sensitivity: 0.9970 - val_precision: 0.9393 - val_recall: 0.7765 - val_f1score: 0.8302\n",
      "Epoch 58/150\n",
      "6528/6528 [==============================] - 2449s 375ms/step - loss: -0.9185 - dice_coef: 0.9185 - acc: 0.8404 - mean_squared_error: 0.0020 - Jaccard_index: 0.8526 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9963 - recall: 0.9941 - f1score: 0.9952 - val_loss: -0.7763 - val_dice_coef: 0.7763 - val_acc: 0.8287 - val_mean_squared_error: 0.0161 - val_Jaccard_index: 0.6560 - val_Specificity: 0.9641 - val_Sensitivity: 0.9973 - val_precision: 0.9381 - val_recall: 0.7855 - val_f1score: 0.8360\n",
      "Epoch 59/150\n",
      "6528/6528 [==============================] - 2450s 375ms/step - loss: -0.9185 - dice_coef: 0.9185 - acc: 0.8404 - mean_squared_error: 0.0020 - Jaccard_index: 0.8528 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9964 - recall: 0.9942 - f1score: 0.9953 - val_loss: -0.7771 - val_dice_coef: 0.7771 - val_acc: 0.8287 - val_mean_squared_error: 0.0159 - val_Jaccard_index: 0.6571 - val_Specificity: 0.9642 - val_Sensitivity: 0.9975 - val_precision: 0.9366 - val_recall: 0.7879 - val_f1score: 0.8369\n",
      "Epoch 60/150\n",
      "6528/6528 [==============================] - 2450s 375ms/step - loss: -0.9189 - dice_coef: 0.9189 - acc: 0.8404 - mean_squared_error: 0.0020 - Jaccard_index: 0.8533 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9965 - recall: 0.9942 - f1score: 0.9953 - val_loss: -0.7821 - val_dice_coef: 0.7821 - val_acc: 0.8287 - val_mean_squared_error: 0.0157 - val_Jaccard_index: 0.6631 - val_Specificity: 0.9643 - val_Sensitivity: 0.9977 - val_precision: 0.9354 - val_recall: 0.7955 - val_f1score: 0.8417\n",
      "Epoch 61/150\n",
      "6528/6528 [==============================] - 2466s 378ms/step - loss: -0.9185 - dice_coef: 0.9185 - acc: 0.8404 - mean_squared_error: 0.0020 - Jaccard_index: 0.8527 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9966 - recall: 0.9944 - f1score: 0.9955 - val_loss: -0.7767 - val_dice_coef: 0.7767 - val_acc: 0.8286 - val_mean_squared_error: 0.0160 - val_Jaccard_index: 0.6568 - val_Specificity: 0.9642 - val_Sensitivity: 0.9976 - val_precision: 0.9339 - val_recall: 0.7887 - val_f1score: 0.8364\n",
      "Epoch 62/150\n",
      "6528/6528 [==============================] - 2465s 378ms/step - loss: -0.9186 - dice_coef: 0.9186 - acc: 0.8404 - mean_squared_error: 0.0020 - Jaccard_index: 0.8529 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9966 - recall: 0.9945 - f1score: 0.9956 - val_loss: -0.7752 - val_dice_coef: 0.7752 - val_acc: 0.8286 - val_mean_squared_error: 0.0162 - val_Jaccard_index: 0.6550 - val_Specificity: 0.9640 - val_Sensitivity: 0.9971 - val_precision: 0.9382 - val_recall: 0.7841 - val_f1score: 0.8348\n",
      "Epoch 63/150\n",
      "6528/6528 [==============================] - 2465s 378ms/step - loss: -0.9191 - dice_coef: 0.9191 - acc: 0.8404 - mean_squared_error: 0.0020 - Jaccard_index: 0.8537 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9967 - recall: 0.9946 - f1score: 0.9956 - val_loss: -0.7838 - val_dice_coef: 0.7838 - val_acc: 0.8288 - val_mean_squared_error: 0.0155 - val_Jaccard_index: 0.6635 - val_Specificity: 0.9645 - val_Sensitivity: 0.9979 - val_precision: 0.9364 - val_recall: 0.7963 - val_f1score: 0.8439\n",
      "Epoch 64/150\n",
      "6528/6528 [==============================] - 2464s 377ms/step - loss: -0.9187 - dice_coef: 0.9187 - acc: 0.8404 - mean_squared_error: 0.0020 - Jaccard_index: 0.8531 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9968 - recall: 0.9947 - f1score: 0.9957 - val_loss: -0.7764 - val_dice_coef: 0.7764 - val_acc: 0.8287 - val_mean_squared_error: 0.0161 - val_Jaccard_index: 0.6561 - val_Specificity: 0.9640 - val_Sensitivity: 0.9972 - val_precision: 0.9382 - val_recall: 0.7834 - val_f1score: 0.8352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/150\n",
      "6528/6528 [==============================] - 2464s 377ms/step - loss: -0.9191 - dice_coef: 0.9191 - acc: 0.8404 - mean_squared_error: 0.0020 - Jaccard_index: 0.8538 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9969 - recall: 0.9947 - f1score: 0.9958 - val_loss: -0.7805 - val_dice_coef: 0.7805 - val_acc: 0.8286 - val_mean_squared_error: 0.0159 - val_Jaccard_index: 0.6609 - val_Specificity: 0.9643 - val_Sensitivity: 0.9978 - val_precision: 0.9338 - val_recall: 0.7950 - val_f1score: 0.8403\n",
      "Epoch 66/150\n",
      "6528/6528 [==============================] - 2464s 377ms/step - loss: -0.9189 - dice_coef: 0.9189 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8535 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9969 - recall: 0.9948 - f1score: 0.9959 - val_loss: -0.7825 - val_dice_coef: 0.7825 - val_acc: 0.8286 - val_mean_squared_error: 0.0158 - val_Jaccard_index: 0.6639 - val_Specificity: 0.9645 - val_Sensitivity: 0.9981 - val_precision: 0.9320 - val_recall: 0.8002 - val_f1score: 0.8426\n",
      "Epoch 67/150\n",
      "6528/6528 [==============================] - 2463s 377ms/step - loss: -0.9190 - dice_coef: 0.9190 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8536 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9970 - recall: 0.9949 - f1score: 0.9960 - val_loss: -0.7744 - val_dice_coef: 0.7744 - val_acc: 0.8287 - val_mean_squared_error: 0.0161 - val_Jaccard_index: 0.6537 - val_Specificity: 0.9639 - val_Sensitivity: 0.9970 - val_precision: 0.9404 - val_recall: 0.7788 - val_f1score: 0.8325\n",
      "Epoch 68/150\n",
      "6528/6528 [==============================] - 2465s 378ms/step - loss: -0.9192 - dice_coef: 0.9192 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8539 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9971 - recall: 0.9950 - f1score: 0.9960 - val_loss: -0.7730 - val_dice_coef: 0.7730 - val_acc: 0.8287 - val_mean_squared_error: 0.0161 - val_Jaccard_index: 0.6515 - val_Specificity: 0.9640 - val_Sensitivity: 0.9971 - val_precision: 0.9379 - val_recall: 0.7802 - val_f1score: 0.8327\n",
      "Epoch 69/150\n",
      "6528/6528 [==============================] - 2466s 378ms/step - loss: -0.9193 - dice_coef: 0.9193 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8540 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9972 - recall: 0.9951 - f1score: 0.9961 - val_loss: -0.7742 - val_dice_coef: 0.7742 - val_acc: 0.8287 - val_mean_squared_error: 0.0161 - val_Jaccard_index: 0.6547 - val_Specificity: 0.9640 - val_Sensitivity: 0.9972 - val_precision: 0.9376 - val_recall: 0.7828 - val_f1score: 0.8334\n",
      "Epoch 70/150\n",
      "6528/6528 [==============================] - 2460s 377ms/step - loss: -0.9190 - dice_coef: 0.9190 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8537 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9972 - recall: 0.9951 - f1score: 0.9961 - val_loss: -0.7739 - val_dice_coef: 0.7739 - val_acc: 0.8286 - val_mean_squared_error: 0.0161 - val_Jaccard_index: 0.6536 - val_Specificity: 0.9640 - val_Sensitivity: 0.9973 - val_precision: 0.9365 - val_recall: 0.7825 - val_f1score: 0.8330\n",
      "Epoch 71/150\n",
      "6528/6528 [==============================] - 2464s 377ms/step - loss: -0.9194 - dice_coef: 0.9194 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8544 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9973 - recall: 0.9952 - f1score: 0.9962 - val_loss: -0.7782 - val_dice_coef: 0.7782 - val_acc: 0.8287 - val_mean_squared_error: 0.0159 - val_Jaccard_index: 0.6587 - val_Specificity: 0.9642 - val_Sensitivity: 0.9974 - val_precision: 0.9365 - val_recall: 0.7874 - val_f1score: 0.8370\n",
      "Epoch 72/150\n",
      "6528/6528 [==============================] - 2465s 378ms/step - loss: -0.9195 - dice_coef: 0.9195 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8544 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9973 - recall: 0.9952 - f1score: 0.9962 - val_loss: -0.7796 - val_dice_coef: 0.7796 - val_acc: 0.8287 - val_mean_squared_error: 0.0158 - val_Jaccard_index: 0.6591 - val_Specificity: 0.9643 - val_Sensitivity: 0.9976 - val_precision: 0.9358 - val_recall: 0.7907 - val_f1score: 0.8391\n",
      "Epoch 73/150\n",
      "6528/6528 [==============================] - 2465s 378ms/step - loss: -0.9192 - dice_coef: 0.9192 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8538 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9973 - recall: 0.9952 - f1score: 0.9963 - val_loss: -0.7788 - val_dice_coef: 0.7788 - val_acc: 0.8287 - val_mean_squared_error: 0.0159 - val_Jaccard_index: 0.6597 - val_Specificity: 0.9642 - val_Sensitivity: 0.9975 - val_precision: 0.9355 - val_recall: 0.7910 - val_f1score: 0.8381\n",
      "Epoch 74/150\n",
      "6528/6528 [==============================] - 2466s 378ms/step - loss: -0.9193 - dice_coef: 0.9193 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8541 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9974 - recall: 0.9953 - f1score: 0.9963 - val_loss: -0.7774 - val_dice_coef: 0.7774 - val_acc: 0.8287 - val_mean_squared_error: 0.0159 - val_Jaccard_index: 0.6581 - val_Specificity: 0.9642 - val_Sensitivity: 0.9974 - val_precision: 0.9374 - val_recall: 0.7882 - val_f1score: 0.8370\n",
      "Epoch 75/150\n",
      "6528/6528 [==============================] - 2466s 378ms/step - loss: -0.9196 - dice_coef: 0.9196 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8546 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9974 - recall: 0.9954 - f1score: 0.9964 - val_loss: -0.7733 - val_dice_coef: 0.7733 - val_acc: 0.8286 - val_mean_squared_error: 0.0162 - val_Jaccard_index: 0.6518 - val_Specificity: 0.9639 - val_Sensitivity: 0.9969 - val_precision: 0.9397 - val_recall: 0.7775 - val_f1score: 0.8318\n",
      "Epoch 76/150\n",
      "6528/6528 [==============================] - 2467s 378ms/step - loss: -0.9194 - dice_coef: 0.9194 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8543 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9974 - recall: 0.9955 - f1score: 0.9964 - val_loss: -0.7666 - val_dice_coef: 0.7666 - val_acc: 0.8286 - val_mean_squared_error: 0.0166 - val_Jaccard_index: 0.6449 - val_Specificity: 0.9636 - val_Sensitivity: 0.9963 - val_precision: 0.9426 - val_recall: 0.7662 - val_f1score: 0.8247\n",
      "Epoch 77/150\n",
      "6528/6528 [==============================] - 2465s 378ms/step - loss: -0.9196 - dice_coef: 0.9196 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8546 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9975 - recall: 0.9955 - f1score: 0.9965 - val_loss: -0.7773 - val_dice_coef: 0.7773 - val_acc: 0.8287 - val_mean_squared_error: 0.0160 - val_Jaccard_index: 0.6568 - val_Specificity: 0.9641 - val_Sensitivity: 0.9973 - val_precision: 0.9384 - val_recall: 0.7857 - val_f1score: 0.8366\n",
      "Epoch 78/150\n",
      "6528/6528 [==============================] - 2452s 376ms/step - loss: -0.9196 - dice_coef: 0.9196 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8547 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9975 - recall: 0.9955 - f1score: 0.9965 - val_loss: -0.7688 - val_dice_coef: 0.7688 - val_acc: 0.8287 - val_mean_squared_error: 0.0164 - val_Jaccard_index: 0.6478 - val_Specificity: 0.9637 - val_Sensitivity: 0.9965 - val_precision: 0.9426 - val_recall: 0.7705 - val_f1score: 0.8274\n",
      "Epoch 79/150\n",
      "6528/6528 [==============================] - 2454s 376ms/step - loss: -0.9195 - dice_coef: 0.9195 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8545 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9976 - recall: 0.9956 - f1score: 0.9965 - val_loss: -0.7740 - val_dice_coef: 0.7740 - val_acc: 0.8286 - val_mean_squared_error: 0.0161 - val_Jaccard_index: 0.6533 - val_Specificity: 0.9640 - val_Sensitivity: 0.9972 - val_precision: 0.9372 - val_recall: 0.7820 - val_f1score: 0.8330\n",
      "Epoch 80/150\n",
      "6528/6528 [==============================] - 2452s 376ms/step - loss: -0.9196 - dice_coef: 0.9196 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8547 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9976 - recall: 0.9955 - f1score: 0.9965 - val_loss: -0.7804 - val_dice_coef: 0.7804 - val_acc: 0.8287 - val_mean_squared_error: 0.0157 - val_Jaccard_index: 0.6615 - val_Specificity: 0.9644 - val_Sensitivity: 0.9979 - val_precision: 0.9336 - val_recall: 0.7954 - val_f1score: 0.8405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/150\n",
      "6528/6528 [==============================] - 2452s 376ms/step - loss: -0.9200 - dice_coef: 0.9200 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8553 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9976 - recall: 0.9957 - f1score: 0.9967 - val_loss: -0.7794 - val_dice_coef: 0.7794 - val_acc: 0.8287 - val_mean_squared_error: 0.0159 - val_Jaccard_index: 0.6605 - val_Specificity: 0.9642 - val_Sensitivity: 0.9975 - val_precision: 0.9359 - val_recall: 0.7910 - val_f1score: 0.8385\n",
      "Epoch 82/150\n",
      "6528/6528 [==============================] - 2452s 376ms/step - loss: -0.9197 - dice_coef: 0.9197 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8548 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9977 - recall: 0.9958 - f1score: 0.9967 - val_loss: -0.7789 - val_dice_coef: 0.7789 - val_acc: 0.8287 - val_mean_squared_error: 0.0159 - val_Jaccard_index: 0.6582 - val_Specificity: 0.9641 - val_Sensitivity: 0.9972 - val_precision: 0.9398 - val_recall: 0.7847 - val_f1score: 0.8374\n",
      "Epoch 83/150\n",
      "6528/6528 [==============================] - 2451s 376ms/step - loss: -0.9197 - dice_coef: 0.9197 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8549 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9976 - recall: 0.9957 - f1score: 0.9966 - val_loss: -0.7782 - val_dice_coef: 0.7782 - val_acc: 0.8286 - val_mean_squared_error: 0.0160 - val_Jaccard_index: 0.6582 - val_Specificity: 0.9642 - val_Sensitivity: 0.9975 - val_precision: 0.9351 - val_recall: 0.7893 - val_f1score: 0.8370\n",
      "Epoch 84/150\n",
      "6528/6528 [==============================] - 2451s 375ms/step - loss: -0.9195 - dice_coef: 0.9195 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8545 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9977 - recall: 0.9957 - f1score: 0.9966 - val_loss: -0.7764 - val_dice_coef: 0.7764 - val_acc: 0.8287 - val_mean_squared_error: 0.0159 - val_Jaccard_index: 0.6564 - val_Specificity: 0.9641 - val_Sensitivity: 0.9972 - val_precision: 0.9397 - val_recall: 0.7856 - val_f1score: 0.8365\n",
      "Epoch 85/150\n",
      "6528/6528 [==============================] - 2454s 376ms/step - loss: -0.9198 - dice_coef: 0.9198 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8550 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9977 - recall: 0.9958 - f1score: 0.9968 - val_loss: -0.7731 - val_dice_coef: 0.7731 - val_acc: 0.8287 - val_mean_squared_error: 0.0162 - val_Jaccard_index: 0.6531 - val_Specificity: 0.9639 - val_Sensitivity: 0.9969 - val_precision: 0.9411 - val_recall: 0.7780 - val_f1score: 0.8320\n",
      "Epoch 86/150\n",
      "6528/6528 [==============================] - 2453s 376ms/step - loss: -0.9197 - dice_coef: 0.9197 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8548 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9976 - recall: 0.9956 - f1score: 0.9966 - val_loss: -0.7730 - val_dice_coef: 0.7730 - val_acc: 0.8286 - val_mean_squared_error: 0.0163 - val_Jaccard_index: 0.6537 - val_Specificity: 0.9639 - val_Sensitivity: 0.9970 - val_precision: 0.9396 - val_recall: 0.7804 - val_f1score: 0.8319\n",
      "Epoch 87/150\n",
      "6528/6528 [==============================] - 2450s 375ms/step - loss: -0.9196 - dice_coef: 0.9196 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8547 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9978 - recall: 0.9959 - f1score: 0.9968 - val_loss: -0.7743 - val_dice_coef: 0.7743 - val_acc: 0.8287 - val_mean_squared_error: 0.0161 - val_Jaccard_index: 0.6551 - val_Specificity: 0.9640 - val_Sensitivity: 0.9970 - val_precision: 0.9413 - val_recall: 0.7811 - val_f1score: 0.8334\n",
      "Epoch 88/150\n",
      "6528/6528 [==============================] - 2455s 376ms/step - loss: -0.9189 - dice_coef: 0.9189 - acc: 0.8404 - mean_squared_error: 0.0020 - Jaccard_index: 0.8536 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9969 - recall: 0.9950 - f1score: 0.9959 - val_loss: -0.7775 - val_dice_coef: 0.7775 - val_acc: 0.8288 - val_mean_squared_error: 0.0160 - val_Jaccard_index: 0.6577 - val_Specificity: 0.9640 - val_Sensitivity: 0.9970 - val_precision: 0.9417 - val_recall: 0.7836 - val_f1score: 0.8366\n",
      "Epoch 89/150\n",
      "6528/6528 [==============================] - 2454s 376ms/step - loss: -0.9203 - dice_coef: 0.9203 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8557 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9979 - recall: 0.9960 - f1score: 0.9969 - val_loss: -0.7752 - val_dice_coef: 0.7752 - val_acc: 0.8288 - val_mean_squared_error: 0.0161 - val_Jaccard_index: 0.6550 - val_Specificity: 0.9639 - val_Sensitivity: 0.9968 - val_precision: 0.9425 - val_recall: 0.7785 - val_f1score: 0.8337\n",
      "Epoch 90/150\n",
      "6528/6528 [==============================] - 2454s 376ms/step - loss: -0.9197 - dice_coef: 0.9197 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8549 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9979 - recall: 0.9960 - f1score: 0.9969 - val_loss: -0.7790 - val_dice_coef: 0.7790 - val_acc: 0.8287 - val_mean_squared_error: 0.0160 - val_Jaccard_index: 0.6594 - val_Specificity: 0.9642 - val_Sensitivity: 0.9975 - val_precision: 0.9365 - val_recall: 0.7898 - val_f1score: 0.8383\n",
      "Epoch 91/150\n",
      "6528/6528 [==============================] - 2454s 376ms/step - loss: -0.9197 - dice_coef: 0.9197 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8549 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9978 - recall: 0.9960 - f1score: 0.9969 - val_loss: -0.7771 - val_dice_coef: 0.7771 - val_acc: 0.8287 - val_mean_squared_error: 0.0160 - val_Jaccard_index: 0.6575 - val_Specificity: 0.9641 - val_Sensitivity: 0.9972 - val_precision: 0.9384 - val_recall: 0.7851 - val_f1score: 0.8359\n",
      "Epoch 92/150\n",
      "6528/6528 [==============================] - 2454s 376ms/step - loss: -0.9201 - dice_coef: 0.9201 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8554 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9978 - recall: 0.9960 - f1score: 0.9969 - val_loss: -0.7738 - val_dice_coef: 0.7738 - val_acc: 0.8286 - val_mean_squared_error: 0.0162 - val_Jaccard_index: 0.6532 - val_Specificity: 0.9640 - val_Sensitivity: 0.9972 - val_precision: 0.9381 - val_recall: 0.7817 - val_f1score: 0.8327\n",
      "Epoch 93/150\n",
      "6528/6528 [==============================] - 2452s 376ms/step - loss: -0.9199 - dice_coef: 0.9199 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8552 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9979 - recall: 0.9960 - f1score: 0.9969 - val_loss: -0.7742 - val_dice_coef: 0.7742 - val_acc: 0.8287 - val_mean_squared_error: 0.0162 - val_Jaccard_index: 0.6535 - val_Specificity: 0.9639 - val_Sensitivity: 0.9969 - val_precision: 0.9406 - val_recall: 0.7790 - val_f1score: 0.8331\n",
      "Epoch 94/150\n",
      "6528/6528 [==============================] - 2453s 376ms/step - loss: -0.9199 - dice_coef: 0.9199 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8553 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9979 - recall: 0.9961 - f1score: 0.9970 - val_loss: -0.7826 - val_dice_coef: 0.7826 - val_acc: 0.8288 - val_mean_squared_error: 0.0156 - val_Jaccard_index: 0.6635 - val_Specificity: 0.9644 - val_Sensitivity: 0.9978 - val_precision: 0.9361 - val_recall: 0.7958 - val_f1score: 0.8425\n",
      "Epoch 95/150\n",
      "6528/6528 [==============================] - 2460s 377ms/step - loss: -0.9201 - dice_coef: 0.9201 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8555 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9978 - recall: 0.9960 - f1score: 0.9969 - val_loss: -0.7761 - val_dice_coef: 0.7761 - val_acc: 0.8288 - val_mean_squared_error: 0.0160 - val_Jaccard_index: 0.6566 - val_Specificity: 0.9640 - val_Sensitivity: 0.9971 - val_precision: 0.9403 - val_recall: 0.7842 - val_f1score: 0.8357\n",
      "Epoch 96/150\n",
      "6528/6528 [==============================] - 2457s 376ms/step - loss: -0.9201 - dice_coef: 0.9201 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8555 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9979 - recall: 0.9960 - f1score: 0.9969 - val_loss: -0.7721 - val_dice_coef: 0.7721 - val_acc: 0.8286 - val_mean_squared_error: 0.0164 - val_Jaccard_index: 0.6514 - val_Specificity: 0.9638 - val_Sensitivity: 0.9969 - val_precision: 0.9393 - val_recall: 0.7780 - val_f1score: 0.8312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/150\n",
      "6528/6528 [==============================] - 2457s 376ms/step - loss: -0.9198 - dice_coef: 0.9198 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8550 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9980 - recall: 0.9961 - f1score: 0.9970 - val_loss: -0.7761 - val_dice_coef: 0.7761 - val_acc: 0.8287 - val_mean_squared_error: 0.0161 - val_Jaccard_index: 0.6560 - val_Specificity: 0.9640 - val_Sensitivity: 0.9972 - val_precision: 0.9388 - val_recall: 0.7846 - val_f1score: 0.8355\n",
      "Epoch 98/150\n",
      "6528/6528 [==============================] - 2465s 378ms/step - loss: -0.9201 - dice_coef: 0.9201 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8554 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9980 - recall: 0.9961 - f1score: 0.9970 - val_loss: -0.7727 - val_dice_coef: 0.7727 - val_acc: 0.8286 - val_mean_squared_error: 0.0164 - val_Jaccard_index: 0.6522 - val_Specificity: 0.9639 - val_Sensitivity: 0.9970 - val_precision: 0.9387 - val_recall: 0.7788 - val_f1score: 0.8315\n",
      "Epoch 99/150\n",
      "6528/6528 [==============================] - 2466s 378ms/step - loss: -0.9199 - dice_coef: 0.9199 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8552 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9979 - recall: 0.9961 - f1score: 0.9970 - val_loss: -0.7810 - val_dice_coef: 0.7810 - val_acc: 0.8288 - val_mean_squared_error: 0.0157 - val_Jaccard_index: 0.6616 - val_Specificity: 0.9643 - val_Sensitivity: 0.9976 - val_precision: 0.9372 - val_recall: 0.7918 - val_f1score: 0.8401\n",
      "Epoch 100/150\n",
      "6528/6528 [==============================] - 2459s 377ms/step - loss: -0.9199 - dice_coef: 0.9199 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8551 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9979 - recall: 0.9962 - f1score: 0.9970 - val_loss: -0.7817 - val_dice_coef: 0.7817 - val_acc: 0.8288 - val_mean_squared_error: 0.0157 - val_Jaccard_index: 0.6619 - val_Specificity: 0.9643 - val_Sensitivity: 0.9977 - val_precision: 0.9359 - val_recall: 0.7938 - val_f1score: 0.8413\n",
      "Epoch 101/150\n",
      "6528/6528 [==============================] - 2457s 376ms/step - loss: -0.9199 - dice_coef: 0.9199 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8553 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9979 - recall: 0.9962 - f1score: 0.9971 - val_loss: -0.7787 - val_dice_coef: 0.7787 - val_acc: 0.8287 - val_mean_squared_error: 0.0160 - val_Jaccard_index: 0.6588 - val_Specificity: 0.9640 - val_Sensitivity: 0.9972 - val_precision: 0.9405 - val_recall: 0.7864 - val_f1score: 0.8380\n",
      "Epoch 102/150\n",
      "6528/6528 [==============================] - 2455s 376ms/step - loss: -0.9202 - dice_coef: 0.9202 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8557 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9980 - recall: 0.9962 - f1score: 0.9971 - val_loss: -0.7780 - val_dice_coef: 0.7780 - val_acc: 0.8287 - val_mean_squared_error: 0.0160 - val_Jaccard_index: 0.6579 - val_Specificity: 0.9641 - val_Sensitivity: 0.9974 - val_precision: 0.9365 - val_recall: 0.7890 - val_f1score: 0.8377\n",
      "Epoch 103/150\n",
      "6528/6528 [==============================] - 2456s 376ms/step - loss: -0.9199 - dice_coef: 0.9199 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8552 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9979 - recall: 0.9962 - f1score: 0.9970 - val_loss: -0.7761 - val_dice_coef: 0.7761 - val_acc: 0.8287 - val_mean_squared_error: 0.0162 - val_Jaccard_index: 0.6563 - val_Specificity: 0.9640 - val_Sensitivity: 0.9971 - val_precision: 0.9392 - val_recall: 0.7845 - val_f1score: 0.8355\n",
      "Epoch 104/150\n",
      "6528/6528 [==============================] - 2455s 376ms/step - loss: -0.9199 - dice_coef: 0.9199 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8551 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9980 - recall: 0.9962 - f1score: 0.9971 - val_loss: -0.7784 - val_dice_coef: 0.7784 - val_acc: 0.8286 - val_mean_squared_error: 0.0160 - val_Jaccard_index: 0.6592 - val_Specificity: 0.9642 - val_Sensitivity: 0.9977 - val_precision: 0.9346 - val_recall: 0.7924 - val_f1score: 0.8381\n",
      "Epoch 105/150\n",
      "6528/6528 [==============================] - 2459s 377ms/step - loss: -0.9199 - dice_coef: 0.9199 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8551 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9980 - recall: 0.9962 - f1score: 0.9971 - val_loss: -0.7798 - val_dice_coef: 0.7798 - val_acc: 0.8287 - val_mean_squared_error: 0.0159 - val_Jaccard_index: 0.6597 - val_Specificity: 0.9642 - val_Sensitivity: 0.9976 - val_precision: 0.9356 - val_recall: 0.7920 - val_f1score: 0.8394\n",
      "Epoch 106/150\n",
      "6528/6528 [==============================] - 2456s 376ms/step - loss: -0.9201 - dice_coef: 0.9201 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8555 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9981 - recall: 0.9963 - f1score: 0.9972 - val_loss: -0.7657 - val_dice_coef: 0.7657 - val_acc: 0.8286 - val_mean_squared_error: 0.0166 - val_Jaccard_index: 0.6443 - val_Specificity: 0.9636 - val_Sensitivity: 0.9966 - val_precision: 0.9401 - val_recall: 0.7678 - val_f1score: 0.8242\n",
      "Epoch 107/150\n",
      "6528/6528 [==============================] - 2458s 377ms/step - loss: -0.9201 - dice_coef: 0.9201 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8554 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9981 - recall: 0.9963 - f1score: 0.9972 - val_loss: -0.7709 - val_dice_coef: 0.7709 - val_acc: 0.8286 - val_mean_squared_error: 0.0165 - val_Jaccard_index: 0.6495 - val_Specificity: 0.9637 - val_Sensitivity: 0.9966 - val_precision: 0.9427 - val_recall: 0.7731 - val_f1score: 0.8298\n",
      "Epoch 108/150\n",
      "6528/6528 [==============================] - 2458s 376ms/step - loss: -0.9203 - dice_coef: 0.9203 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8558 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9981 - recall: 0.9963 - f1score: 0.9972 - val_loss: -0.7782 - val_dice_coef: 0.7782 - val_acc: 0.8287 - val_mean_squared_error: 0.0159 - val_Jaccard_index: 0.6592 - val_Specificity: 0.9642 - val_Sensitivity: 0.9975 - val_precision: 0.9371 - val_recall: 0.7899 - val_f1score: 0.8379\n",
      "Epoch 109/150\n",
      "6528/6528 [==============================] - 2457s 376ms/step - loss: -0.9201 - dice_coef: 0.9201 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8555 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9980 - recall: 0.9963 - f1score: 0.9971 - val_loss: -0.7788 - val_dice_coef: 0.7788 - val_acc: 0.8287 - val_mean_squared_error: 0.0160 - val_Jaccard_index: 0.6587 - val_Specificity: 0.9642 - val_Sensitivity: 0.9975 - val_precision: 0.9373 - val_recall: 0.7896 - val_f1score: 0.8387\n",
      "Epoch 110/150\n",
      "6528/6528 [==============================] - 2468s 378ms/step - loss: -0.9204 - dice_coef: 0.9204 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8559 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9981 - recall: 0.9964 - f1score: 0.9972 - val_loss: -0.7736 - val_dice_coef: 0.7736 - val_acc: 0.8286 - val_mean_squared_error: 0.0162 - val_Jaccard_index: 0.6528 - val_Specificity: 0.9640 - val_Sensitivity: 0.9971 - val_precision: 0.9386 - val_recall: 0.7810 - val_f1score: 0.8326\n",
      "Epoch 111/150\n",
      "6528/6528 [==============================] - 2468s 378ms/step - loss: -0.9201 - dice_coef: 0.9201 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8555 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9981 - recall: 0.9964 - f1score: 0.9973 - val_loss: -0.7726 - val_dice_coef: 0.7726 - val_acc: 0.8286 - val_mean_squared_error: 0.0163 - val_Jaccard_index: 0.6518 - val_Specificity: 0.9639 - val_Sensitivity: 0.9970 - val_precision: 0.9389 - val_recall: 0.7792 - val_f1score: 0.8322\n",
      "Epoch 112/150\n",
      "6528/6528 [==============================] - 2465s 378ms/step - loss: -0.9201 - dice_coef: 0.9201 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8555 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9982 - recall: 0.9964 - f1score: 0.9973 - val_loss: -0.7743 - val_dice_coef: 0.7743 - val_acc: 0.8286 - val_mean_squared_error: 0.0163 - val_Jaccard_index: 0.6541 - val_Specificity: 0.9639 - val_Sensitivity: 0.9969 - val_precision: 0.9395 - val_recall: 0.7808 - val_f1score: 0.8332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/150\n",
      "6528/6528 [==============================] - 2459s 377ms/step - loss: -0.9204 - dice_coef: 0.9204 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8560 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9982 - recall: 0.9964 - f1score: 0.9973 - val_loss: -0.7632 - val_dice_coef: 0.7632 - val_acc: 0.8284 - val_mean_squared_error: 0.0170 - val_Jaccard_index: 0.6406 - val_Specificity: 0.9634 - val_Sensitivity: 0.9962 - val_precision: 0.9416 - val_recall: 0.7620 - val_f1score: 0.8215\n",
      "Epoch 114/150\n",
      "6528/6528 [==============================] - 2454s 376ms/step - loss: -0.9203 - dice_coef: 0.9203 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8558 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9981 - recall: 0.9964 - f1score: 0.9973 - val_loss: -0.7790 - val_dice_coef: 0.7790 - val_acc: 0.8288 - val_mean_squared_error: 0.0158 - val_Jaccard_index: 0.6597 - val_Specificity: 0.9642 - val_Sensitivity: 0.9973 - val_precision: 0.9397 - val_recall: 0.7878 - val_f1score: 0.8386\n",
      "Epoch 115/150\n",
      "6528/6528 [==============================] - 2458s 376ms/step - loss: -0.9202 - dice_coef: 0.9202 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8557 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9982 - recall: 0.9964 - f1score: 0.9973 - val_loss: -0.7713 - val_dice_coef: 0.7713 - val_acc: 0.8286 - val_mean_squared_error: 0.0162 - val_Jaccard_index: 0.6501 - val_Specificity: 0.9639 - val_Sensitivity: 0.9970 - val_precision: 0.9396 - val_recall: 0.7756 - val_f1score: 0.8297\n",
      "Epoch 116/150\n",
      "6528/6528 [==============================] - 2457s 376ms/step - loss: -0.9201 - dice_coef: 0.9201 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8555 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9982 - recall: 0.9964 - f1score: 0.9973 - val_loss: -0.7801 - val_dice_coef: 0.7801 - val_acc: 0.8287 - val_mean_squared_error: 0.0159 - val_Jaccard_index: 0.6597 - val_Specificity: 0.9643 - val_Sensitivity: 0.9977 - val_precision: 0.9359 - val_recall: 0.7924 - val_f1score: 0.8404\n",
      "Epoch 117/150\n",
      "6528/6528 [==============================] - 2458s 376ms/step - loss: -0.9205 - dice_coef: 0.9205 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8562 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9982 - recall: 0.9966 - f1score: 0.9974 - val_loss: -0.7756 - val_dice_coef: 0.7756 - val_acc: 0.8287 - val_mean_squared_error: 0.0160 - val_Jaccard_index: 0.6567 - val_Specificity: 0.9641 - val_Sensitivity: 0.9974 - val_precision: 0.9371 - val_recall: 0.7863 - val_f1score: 0.8350\n",
      "Epoch 118/150\n",
      "6528/6528 [==============================] - 2460s 377ms/step - loss: -0.9202 - dice_coef: 0.9202 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8557 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9981 - recall: 0.9965 - f1score: 0.9973 - val_loss: -0.7771 - val_dice_coef: 0.7771 - val_acc: 0.8287 - val_mean_squared_error: 0.0160 - val_Jaccard_index: 0.6567 - val_Specificity: 0.9641 - val_Sensitivity: 0.9973 - val_precision: 0.9387 - val_recall: 0.7853 - val_f1score: 0.8364\n",
      "Epoch 119/150\n",
      "6528/6528 [==============================] - 2455s 376ms/step - loss: -0.9202 - dice_coef: 0.9202 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8557 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9981 - recall: 0.9965 - f1score: 0.9973 - val_loss: -0.7751 - val_dice_coef: 0.7751 - val_acc: 0.8286 - val_mean_squared_error: 0.0162 - val_Jaccard_index: 0.6550 - val_Specificity: 0.9640 - val_Sensitivity: 0.9971 - val_precision: 0.9387 - val_recall: 0.7837 - val_f1score: 0.8347\n",
      "Epoch 120/150\n",
      "6528/6528 [==============================] - 2454s 376ms/step - loss: -0.9204 - dice_coef: 0.9204 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8560 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9982 - recall: 0.9966 - f1score: 0.9974 - val_loss: -0.7685 - val_dice_coef: 0.7685 - val_acc: 0.8286 - val_mean_squared_error: 0.0165 - val_Jaccard_index: 0.6479 - val_Specificity: 0.9637 - val_Sensitivity: 0.9967 - val_precision: 0.9409 - val_recall: 0.7727 - val_f1score: 0.8279\n",
      "Epoch 121/150\n",
      "6528/6528 [==============================] - 2452s 376ms/step - loss: -0.9201 - dice_coef: 0.9201 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8556 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9982 - recall: 0.9966 - f1score: 0.9974 - val_loss: -0.7790 - val_dice_coef: 0.7790 - val_acc: 0.8286 - val_mean_squared_error: 0.0159 - val_Jaccard_index: 0.6594 - val_Specificity: 0.9643 - val_Sensitivity: 0.9978 - val_precision: 0.9330 - val_recall: 0.7926 - val_f1score: 0.8383\n",
      "Epoch 122/150\n",
      "6528/6528 [==============================] - 2456s 376ms/step - loss: -0.9204 - dice_coef: 0.9204 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8561 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9982 - recall: 0.9966 - f1score: 0.9974 - val_loss: -0.7736 - val_dice_coef: 0.7736 - val_acc: 0.8287 - val_mean_squared_error: 0.0162 - val_Jaccard_index: 0.6532 - val_Specificity: 0.9639 - val_Sensitivity: 0.9969 - val_precision: 0.9418 - val_recall: 0.7770 - val_f1score: 0.8320\n",
      "Epoch 123/150\n",
      "6528/6528 [==============================] - 2456s 376ms/step - loss: -0.9202 - dice_coef: 0.9202 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8557 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9982 - recall: 0.9965 - f1score: 0.9974 - val_loss: -0.7751 - val_dice_coef: 0.7751 - val_acc: 0.8285 - val_mean_squared_error: 0.0163 - val_Jaccard_index: 0.6543 - val_Specificity: 0.9640 - val_Sensitivity: 0.9974 - val_precision: 0.9351 - val_recall: 0.7857 - val_f1score: 0.8352\n",
      "Epoch 124/150\n",
      "6528/6528 [==============================] - 2456s 376ms/step - loss: -0.9205 - dice_coef: 0.9205 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8561 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9983 - recall: 0.9965 - f1score: 0.9974 - val_loss: -0.7741 - val_dice_coef: 0.7741 - val_acc: 0.8287 - val_mean_squared_error: 0.0163 - val_Jaccard_index: 0.6529 - val_Specificity: 0.9638 - val_Sensitivity: 0.9968 - val_precision: 0.9423 - val_recall: 0.7768 - val_f1score: 0.8329\n",
      "Epoch 125/150\n",
      "6528/6528 [==============================] - 2456s 376ms/step - loss: -0.9202 - dice_coef: 0.9202 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8557 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9982 - recall: 0.9966 - f1score: 0.9974 - val_loss: -0.7716 - val_dice_coef: 0.7716 - val_acc: 0.8287 - val_mean_squared_error: 0.0163 - val_Jaccard_index: 0.6511 - val_Specificity: 0.9639 - val_Sensitivity: 0.9969 - val_precision: 0.9403 - val_recall: 0.7766 - val_f1score: 0.8305\n",
      "Epoch 126/150\n",
      "6528/6528 [==============================] - 2454s 376ms/step - loss: -0.9203 - dice_coef: 0.9203 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8559 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9982 - recall: 0.9967 - f1score: 0.9974 - val_loss: -0.7768 - val_dice_coef: 0.7768 - val_acc: 0.8286 - val_mean_squared_error: 0.0160 - val_Jaccard_index: 0.6569 - val_Specificity: 0.9642 - val_Sensitivity: 0.9976 - val_precision: 0.9346 - val_recall: 0.7891 - val_f1score: 0.8367\n",
      "Epoch 127/150\n",
      "6528/6528 [==============================] - 2453s 376ms/step - loss: -0.9204 - dice_coef: 0.9204 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8560 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9983 - recall: 0.9967 - f1score: 0.9975 - val_loss: -0.7705 - val_dice_coef: 0.7705 - val_acc: 0.8286 - val_mean_squared_error: 0.0164 - val_Jaccard_index: 0.6506 - val_Specificity: 0.9638 - val_Sensitivity: 0.9968 - val_precision: 0.9401 - val_recall: 0.7764 - val_f1score: 0.8299\n",
      "Epoch 128/150\n",
      "6528/6528 [==============================] - 2453s 376ms/step - loss: -0.9205 - dice_coef: 0.9205 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8563 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9983 - recall: 0.9966 - f1score: 0.9974 - val_loss: -0.7728 - val_dice_coef: 0.7728 - val_acc: 0.8286 - val_mean_squared_error: 0.0164 - val_Jaccard_index: 0.6516 - val_Specificity: 0.9638 - val_Sensitivity: 0.9968 - val_precision: 0.9392 - val_recall: 0.7764 - val_f1score: 0.8312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129/150\n",
      "6528/6528 [==============================] - 2457s 376ms/step - loss: -0.9204 - dice_coef: 0.9204 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8560 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9983 - recall: 0.9966 - f1score: 0.9974 - val_loss: -0.7786 - val_dice_coef: 0.7786 - val_acc: 0.8287 - val_mean_squared_error: 0.0159 - val_Jaccard_index: 0.6584 - val_Specificity: 0.9642 - val_Sensitivity: 0.9976 - val_precision: 0.9356 - val_recall: 0.7884 - val_f1score: 0.8377\n",
      "Epoch 130/150\n",
      "6528/6528 [==============================] - 2457s 376ms/step - loss: -0.9200 - dice_coef: 0.9200 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8553 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9980 - recall: 0.9962 - f1score: 0.9971 - val_loss: -0.7694 - val_dice_coef: 0.7694 - val_acc: 0.8286 - val_mean_squared_error: 0.0164 - val_Jaccard_index: 0.6511 - val_Specificity: 0.9639 - val_Sensitivity: 0.9971 - val_precision: 0.9372 - val_recall: 0.7785 - val_f1score: 0.8287\n",
      "Epoch 131/150\n",
      "6528/6528 [==============================] - 2459s 377ms/step - loss: -0.9205 - dice_coef: 0.9205 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8561 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9983 - recall: 0.9967 - f1score: 0.9975 - val_loss: -0.7737 - val_dice_coef: 0.7737 - val_acc: 0.8286 - val_mean_squared_error: 0.0163 - val_Jaccard_index: 0.6538 - val_Specificity: 0.9640 - val_Sensitivity: 0.9973 - val_precision: 0.9376 - val_recall: 0.7831 - val_f1score: 0.8331\n",
      "Epoch 132/150\n",
      "6528/6528 [==============================] - 2456s 376ms/step - loss: -0.9201 - dice_coef: 0.9201 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8556 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9982 - recall: 0.9967 - f1score: 0.9974 - val_loss: -0.7694 - val_dice_coef: 0.7694 - val_acc: 0.8285 - val_mean_squared_error: 0.0166 - val_Jaccard_index: 0.6477 - val_Specificity: 0.9637 - val_Sensitivity: 0.9967 - val_precision: 0.9399 - val_recall: 0.7721 - val_f1score: 0.8280\n",
      "Epoch 133/150\n",
      "6528/6528 [==============================] - 2457s 376ms/step - loss: -0.9204 - dice_coef: 0.9204 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8560 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9982 - recall: 0.9967 - f1score: 0.9975 - val_loss: -0.7734 - val_dice_coef: 0.7734 - val_acc: 0.8286 - val_mean_squared_error: 0.0164 - val_Jaccard_index: 0.6523 - val_Specificity: 0.9638 - val_Sensitivity: 0.9969 - val_precision: 0.9403 - val_recall: 0.7790 - val_f1score: 0.8325\n",
      "Epoch 134/150\n",
      "6528/6528 [==============================] - 2452s 376ms/step - loss: -0.9205 - dice_coef: 0.9205 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8561 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9984 - recall: 0.9968 - f1score: 0.9976 - val_loss: -0.7751 - val_dice_coef: 0.7751 - val_acc: 0.8287 - val_mean_squared_error: 0.0161 - val_Jaccard_index: 0.6547 - val_Specificity: 0.9639 - val_Sensitivity: 0.9970 - val_precision: 0.9404 - val_recall: 0.7794 - val_f1score: 0.8332\n",
      "Epoch 135/150\n",
      "6528/6528 [==============================] - 2456s 376ms/step - loss: -0.9204 - dice_coef: 0.9204 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8560 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9983 - recall: 0.9967 - f1score: 0.9975 - val_loss: -0.7701 - val_dice_coef: 0.7701 - val_acc: 0.8286 - val_mean_squared_error: 0.0164 - val_Jaccard_index: 0.6485 - val_Specificity: 0.9638 - val_Sensitivity: 0.9968 - val_precision: 0.9408 - val_recall: 0.7737 - val_f1score: 0.8292\n",
      "Epoch 136/150\n",
      "6528/6528 [==============================] - 2458s 376ms/step - loss: -0.9200 - dice_coef: 0.9200 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8554 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9983 - recall: 0.9967 - f1score: 0.9975 - val_loss: -0.7668 - val_dice_coef: 0.7668 - val_acc: 0.8285 - val_mean_squared_error: 0.0166 - val_Jaccard_index: 0.6452 - val_Specificity: 0.9636 - val_Sensitivity: 0.9965 - val_precision: 0.9410 - val_recall: 0.7672 - val_f1score: 0.8248\n",
      "Epoch 137/150\n",
      "6528/6528 [==============================] - 2455s 376ms/step - loss: -0.9204 - dice_coef: 0.9204 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8561 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9983 - recall: 0.9967 - f1score: 0.9975 - val_loss: -0.7740 - val_dice_coef: 0.7740 - val_acc: 0.8287 - val_mean_squared_error: 0.0162 - val_Jaccard_index: 0.6528 - val_Specificity: 0.9639 - val_Sensitivity: 0.9970 - val_precision: 0.9393 - val_recall: 0.7794 - val_f1score: 0.8330\n",
      "Epoch 138/150\n",
      "6528/6528 [==============================] - 2454s 376ms/step - loss: -0.9207 - dice_coef: 0.9207 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8565 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9983 - recall: 0.9968 - f1score: 0.9975 - val_loss: -0.7756 - val_dice_coef: 0.7756 - val_acc: 0.8287 - val_mean_squared_error: 0.0162 - val_Jaccard_index: 0.6554 - val_Specificity: 0.9640 - val_Sensitivity: 0.9971 - val_precision: 0.9400 - val_recall: 0.7832 - val_f1score: 0.8348\n",
      "Epoch 139/150\n",
      "6528/6528 [==============================] - 2459s 377ms/step - loss: -0.9202 - dice_coef: 0.9202 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8557 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9983 - recall: 0.9968 - f1score: 0.9975 - val_loss: -0.7711 - val_dice_coef: 0.7711 - val_acc: 0.8286 - val_mean_squared_error: 0.0164 - val_Jaccard_index: 0.6493 - val_Specificity: 0.9638 - val_Sensitivity: 0.9968 - val_precision: 0.9392 - val_recall: 0.7745 - val_f1score: 0.8295\n",
      "Epoch 140/150\n",
      "6528/6528 [==============================] - 2460s 377ms/step - loss: -0.9204 - dice_coef: 0.9204 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8560 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9983 - recall: 0.9968 - f1score: 0.9975 - val_loss: -0.7724 - val_dice_coef: 0.7724 - val_acc: 0.8286 - val_mean_squared_error: 0.0165 - val_Jaccard_index: 0.6509 - val_Specificity: 0.9638 - val_Sensitivity: 0.9968 - val_precision: 0.9404 - val_recall: 0.7760 - val_f1score: 0.8312\n",
      "Epoch 141/150\n",
      "6528/6528 [==============================] - 2457s 376ms/step - loss: -0.9207 - dice_coef: 0.9207 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8565 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9983 - recall: 0.9968 - f1score: 0.9976 - val_loss: -0.7747 - val_dice_coef: 0.7747 - val_acc: 0.8286 - val_mean_squared_error: 0.0162 - val_Jaccard_index: 0.6540 - val_Specificity: 0.9641 - val_Sensitivity: 0.9974 - val_precision: 0.9353 - val_recall: 0.7845 - val_f1score: 0.8341\n",
      "Epoch 142/150\n",
      "6528/6528 [==============================] - 2455s 376ms/step - loss: -0.9205 - dice_coef: 0.9205 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8562 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9983 - recall: 0.9968 - f1score: 0.9976 - val_loss: -0.7728 - val_dice_coef: 0.7728 - val_acc: 0.8285 - val_mean_squared_error: 0.0163 - val_Jaccard_index: 0.6507 - val_Specificity: 0.9640 - val_Sensitivity: 0.9974 - val_precision: 0.9327 - val_recall: 0.7815 - val_f1score: 0.8319\n",
      "Epoch 143/150\n",
      "6528/6528 [==============================] - 2455s 376ms/step - loss: -0.9202 - dice_coef: 0.9202 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8556 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9984 - recall: 0.9968 - f1score: 0.9976 - val_loss: -0.7752 - val_dice_coef: 0.7752 - val_acc: 0.8287 - val_mean_squared_error: 0.0162 - val_Jaccard_index: 0.6554 - val_Specificity: 0.9640 - val_Sensitivity: 0.9971 - val_precision: 0.9396 - val_recall: 0.7831 - val_f1score: 0.8344\n",
      "Epoch 144/150\n",
      "6528/6528 [==============================] - 2453s 376ms/step - loss: -0.9207 - dice_coef: 0.9207 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8565 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9983 - recall: 0.9968 - f1score: 0.9976 - val_loss: -0.7662 - val_dice_coef: 0.7662 - val_acc: 0.8284 - val_mean_squared_error: 0.0169 - val_Jaccard_index: 0.6451 - val_Specificity: 0.9635 - val_Sensitivity: 0.9965 - val_precision: 0.9407 - val_recall: 0.7690 - val_f1score: 0.8253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/150\n",
      "6528/6528 [==============================] - 2459s 377ms/step - loss: -0.9204 - dice_coef: 0.9204 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8561 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9984 - recall: 0.9970 - f1score: 0.9977 - val_loss: -0.7761 - val_dice_coef: 0.7761 - val_acc: 0.8287 - val_mean_squared_error: 0.0161 - val_Jaccard_index: 0.6555 - val_Specificity: 0.9640 - val_Sensitivity: 0.9971 - val_precision: 0.9406 - val_recall: 0.7826 - val_f1score: 0.8356\n",
      "Epoch 146/150\n",
      "6528/6528 [==============================] - 2454s 376ms/step - loss: -0.9207 - dice_coef: 0.9207 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8565 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9984 - recall: 0.9969 - f1score: 0.9976 - val_loss: -0.7663 - val_dice_coef: 0.7663 - val_acc: 0.8286 - val_mean_squared_error: 0.0168 - val_Jaccard_index: 0.6447 - val_Specificity: 0.9635 - val_Sensitivity: 0.9963 - val_precision: 0.9430 - val_recall: 0.7649 - val_f1score: 0.8242\n",
      "Epoch 147/150\n",
      "6528/6528 [==============================] - 2458s 377ms/step - loss: -0.9205 - dice_coef: 0.9205 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8562 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9983 - recall: 0.9969 - f1score: 0.9976 - val_loss: -0.7747 - val_dice_coef: 0.7747 - val_acc: 0.8286 - val_mean_squared_error: 0.0162 - val_Jaccard_index: 0.6551 - val_Specificity: 0.9641 - val_Sensitivity: 0.9974 - val_precision: 0.9344 - val_recall: 0.7847 - val_f1score: 0.8339\n",
      "Epoch 148/150\n",
      "6528/6528 [==============================] - 2455s 376ms/step - loss: -0.9206 - dice_coef: 0.9206 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8563 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9984 - recall: 0.9969 - f1score: 0.9976 - val_loss: -0.7630 - val_dice_coef: 0.7630 - val_acc: 0.8284 - val_mean_squared_error: 0.0170 - val_Jaccard_index: 0.6397 - val_Specificity: 0.9634 - val_Sensitivity: 0.9962 - val_precision: 0.9410 - val_recall: 0.7590 - val_f1score: 0.8202\n",
      "Epoch 149/150\n",
      "6528/6528 [==============================] - 2456s 376ms/step - loss: -0.9202 - dice_coef: 0.9202 - acc: 0.8404 - mean_squared_error: 0.0019 - Jaccard_index: 0.8557 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9981 - recall: 0.9965 - f1score: 0.9973 - val_loss: -0.7724 - val_dice_coef: 0.7724 - val_acc: 0.8286 - val_mean_squared_error: 0.0165 - val_Jaccard_index: 0.6527 - val_Specificity: 0.9639 - val_Sensitivity: 0.9972 - val_precision: 0.9365 - val_recall: 0.7826 - val_f1score: 0.8322\n",
      "Epoch 150/150\n",
      "6528/6528 [==============================] - 2466s 378ms/step - loss: -0.9207 - dice_coef: 0.9207 - acc: 0.8405 - mean_squared_error: 0.0019 - Jaccard_index: 0.8564 - Specificity: 0.9760 - Sensitivity: 1.0026 - precision: 0.9986 - recall: 0.9970 - f1score: 0.9978 - val_loss: -0.7685 - val_dice_coef: 0.7685 - val_acc: 0.8286 - val_mean_squared_error: 0.0166 - val_Jaccard_index: 0.6483 - val_Specificity: 0.9638 - val_Sensitivity: 0.9968 - val_precision: 0.9387 - val_recall: 0.7741 - val_f1score: 0.8275\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=nb_train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = validation_generator,\n",
    "                    validation_steps = nb_validation_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Score:  -0.7667666560411454\n",
      "Validation Accuracy:  0.7667666560411454\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate_generator(validation_generator, steps=50)\n",
    "\n",
    "print ('Validation Score: ', score[0])\n",
    "print ('Validation Accuracy: ',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 4s 140ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict_generator(test_generator, verbose=1, steps=nb_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 512, 512, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'dice_coef', 'acc', 'mean_squared_error', 'Jaccard_index', 'Specificity', 'Sensitivity', 'precision', 'recall', 'f1score']\n",
      "[-0.8470228499174118, 0.8470228499174118, 0.9867490959167481, 0.01302079098764807, 0.7624162492156029, 0.9700357627868652, 0.9969150114059449, 0.9335356044769287, 0.8065314799547195, 0.8471782588958741]\n"
     ]
    }
   ],
   "source": [
    "test_results = model.evaluate_generator(test_generator, steps=50)\n",
    "\n",
    "print(model.metrics_names)\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training co-effiency    : 0.8565467512052433;\n",
      "Validation co-effiency : 0.6450701266559704\n"
     ]
    }
   ],
   "source": [
    "coef = np.array(history.history['Jaccard_index'])\n",
    "val_coef = np.array(history.history['val_Jaccard_index'])\n",
    "print(\"Training co-effiency    : {};\\nValidation co-effiency : {}\".format(coef[coef==max(coef)][0], val_coef[np.argmax(coef)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "\n",
    "def labelVisualize(num_class,color_dict,img):\n",
    "    img = img[:,:,0] if len(img.shape) == 3 else img\n",
    "    img_out = np.zeros(img.shape + (3,))\n",
    "    for i in range(num_class):\n",
    "        img_out[img == i,:] = color_dict[i]\n",
    "    return img_out / 255\n",
    "\n",
    "def saveResult(save_path,npyfile,flag_multi_class = False,num_class = 2):\n",
    "    for i,item in enumerate(npyfile):\n",
    "        img = labelVisualize(num_class,COLOR_DICT,item) if flag_multi_class else item[:,:,0]\n",
    "        io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
    "\n",
    "os.mkdir('10.PSPNet50_results_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveResult('10.PSPNet50_results_dir',prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeData(img,mask):\n",
    "    mean = np.mean(img)\n",
    "    std = np.std(img)\n",
    "    img -= mean\n",
    "    img /= std\n",
    "    mask = mask /255\n",
    "    mask[mask > 0.5] = 1\n",
    "    mask[mask <= 0.5] = 0\n",
    "    return (img,mask)\n",
    "\n",
    "test_data_dir= \"data_augmented/cvc300_test/images/\"\n",
    "test_data_mask_dir = \"data_augmented/cvc300_test/masks/\"\n",
    "test_data_pred_dir = \"10.PSPNet50_results_dir\"\n",
    "img_rows, img_cols = 256, 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_1 to have shape (512, 512, 3) but got array with shape (256, 256, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-a5558b271cfa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mJaccard_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1147\u001b[0m                              'argument.')\n\u001b[0;32m   1148\u001b[0m         \u001b[1;31m# Validate user data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    136\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected input_1 to have shape (512, 512, 3) but got array with shape (256, 256, 3)"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image as image_utils\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img\n",
    "\n",
    "file_names = next(os.walk(test_data_dir))[2]\n",
    "scores = []\n",
    "for file in file_names:\n",
    "    grey_img = load_img(os.path.join(test_data_dir,file), target_size=(img_rows, img_cols), grayscale=False)\n",
    "    mask_img = load_img(os.path.join(test_data_mask_dir,file), target_size=(img_rows, img_cols), grayscale=True)\n",
    "    img = img_to_array(grey_img)\n",
    "    img_mask = img_to_array(mask_img)\n",
    "    \n",
    "    img, img_mask = normalizeData(img, img_mask)\n",
    "    img = np.reshape(img,(1,)+img.shape)\n",
    "    \n",
    "    pred = model.predict([img])\n",
    "    sess = tf.Session()\n",
    "    score = sess.run(Jaccard_index(img_mask, pred))\n",
    "    print(\"{} -- jaccard index: {}\".format(file,score))\n",
    "    scores.append([file,score])\n",
    "\n",
    "    result_img = array_to_img(pred[0] * 255 )\n",
    "    result_img.save(os.path.join(test_data_pred_dir, file.split('.')[0] + '_predict.jpg'))\n",
    "\n",
    "with open(\"unet_test_result.csv\", 'w') as f:\n",
    "    f.write(\"filename, jaccard_index\\n\")\n",
    "    for i in range(len(scores)):\n",
    "        #print(scores[i])\n",
    "        f.write(\"{},{}\\n\".format(scores[i][0], scores[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img=mpimg.imread('10.PSPNet50_results_dir/102_predict.png')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2e0a68a1ac8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAEyNJREFUeJzt3X2MVfWdx/H3h2EGFORJhBqggpVYTK1oSaVhs6m0Guu2YBOb0tYtaTA0+5C06SZd3E027f617h+1adKHJWuzdG192FYjUXarUdv9pwWH8iiIgGFhgpEQnqqjjMz97h/3N/YyZ2TuzNx7zrl3Pq/k5p7zO2fu+V649zO/8zsPo4jAzKzWhKILMLPycTCYWYaDwcwyHAxmluFgMLMMB4OZZTQlGCTdKemApEOSNjRjG2bWPGr0eQySOoBXgduBHuAl4EsRsa+hGzKzpmlGj+HjwKGIeC0i+oBHgdVN2I6ZNcnEJrzmPOBYzXwPcOulfkCST780a76TEXFVPSs2Ixg0RFvmiy9pPbC+Cds3s6H9X70rNiMYeoAFNfPzgeODV4qIjcBGcI/BrGyaMcbwErBY0iJJXcAaYHMTtmNmTdLwHkNEXJD0t8CvgQ7gpxHxcqO3Y2bN0/DDlaMqwrsSZnnYHhHL6lnRZz6aWYaDwcwyHAxmluFgMLMMB4OZZTgYzCzDwWBmGQ4GM8twMJhZhoPBzDIcDGaW4WAwswwHg5llOBjMLMPBYGYZDgYzy3AwmFmGg8HMMhwMZpbhYDCzDAeDmWU4GMwsw8FgZhkOBjPLcDCYWYaDwcwyHAxmluFgMLMMB4OZZTgYzCzDwWBmGQ4GM8twMJhZhoPBzDKGDQZJP5V0QtLemrZZkp6TdDA9z0ztkvQDSYck7ZZ0SzOLN7PmqKfH8B/AnYPaNgDPR8Ri4Pk0D/AZYHF6rAd+3JgyzSxPwwZDRPwvcGpQ82pgU5reBNxd0/6zqPo9MEPS1Y0q1szyMdoxhrkR8TpAep6T2ucBx2rW60ltGZLWS+qW1D3KGsysSSY2+PU0RFsMtWJEbAQ2Akgach0zK8ZoewxvDOwipOcTqb0HWFCz3nzg+OjLM7MijDYYNgNr0/Ra4Kma9q+moxPLgbMDuxxm1kIi4pIP4BHgdeBdqj2CdcCVVI9GHEzPs9K6An4IHAb2AMuGe/30c+GHH340/dFdz/cxIlD6YhbKYwxmudgeEcvqWdFnPppZhoPBzDIcDGaW4WAwswwHg5llOBhsXJsyZQqSeOaZZ5g3bx5S9eTdr3/96+zbtw+A/v7+IkssRr3HNZv5oPjju36Mw8ePfvSjiOoHMM6dOxe1KpVKDNbd3f3edNG1j/JR93kMjb5WwqyUJkyYwKRJk+jt7aW/v5+Ojg4A3n333YFfThcZ6DnU+tjHPgbAyZMnmTp1Km+++WZziy6QdyWs7a1YsYLOzk56e3sB3gsFgM7OzhG/3uzZszlz5gyVSoX+/n6mT5/OHXfc0bB6y8BnPlpb+/CHP8z+/ftz2dZQvYyS8ZmPZkBuoQAQEbz11lu5ba+ZHAzWti5cuJD7Ni+//PIhxyxajYPB2lJ3d/dFYwl5q1QqhW5/rBwM1pYGjiAURRIXLlzg1VdfLbSO0XIwWFuZNm1aqbryixcv5qabbiq6jBFzMFhb2bVrV9ElZOzcuZPu7ta657EPV1pbKcPn+f2U4HCmD1fa+LN9+/aiS7ikMofWYO4xWFvo7Oykr6+v6DLqUmDPwT0GG18mTZpUdAl1K8Mv4+E4GKwttNoFTefPny+6hEtyMFhb6OrqKrqEESl7vQ4Ga3kdHR2l/w08lDLvUjgYrOUtX7686BJGrazh4GCwlrdz586iSxiTMp785MOV1vLK8BkeqwkTJuTxPny40saHEpxN2BCVSqVU78XBYC3t7bffLrqEhnEwmDXAwA1e20WZblPvYLCWtX79+qJLaLgtW7YUXQLgwUdrYWX47DbDl7/8ZR555JFmvHTdg48OBmtZZfjsNsuNN97I3r17G/2yDgZrb2UbxW+GJry/xh2ulLRA0ouS9kt6WdI3UvssSc9JOpieZ6Z2SfqBpEOSdku6ZWzvxSxr+vTpRZfQ1uoZfLwA/F1ELAGWA38j6QZgA/B8RCwGnk/zAJ8BFqfHeuDHDa/axr2DBw8WXULTFXmq97DBEBGvR8Qf0vQfgf3APGA1sCmttgm4O02vBn6W/vbn74EZkq5ueOU2rs2cObPoEprud7/7XWHbHtHhSkkLgZuBrcDciHgdquEBzEmrzQOO1fxYT2oza5iyX7bc6ur+a9eSpgK/Ar4ZEecuMTAy1ILM4KKk9VR3NcxGpN0HHcugrh6DpE6qofDziHgiNb8xsIuQnk+k9h5gQc2PzweOD37NiNgYEcvqHSU1G/DEE08Mv1KbKOqoYT1HJQQ8BOyPiO/VLNoMrE3Ta4Gnatq/mo5OLAfODuxymDXCvffeW3QJba+eXYkVwF8CeyQNXPj+D8C/AI9LWgccBb6Qlm0B7gIOAb3A1xpasY17v/3tb4suIVezZs3i1KlTuW7TJzhZS3n22We5/fbbiy4jVw0cU/GZj9aeyvB5zVsRweCrK81KrohDsw4Gs5I7fPhw7tt0MJiV3C235H+5kYPBrOROnDgx/EoN5mAwswwHg5llOBisZUyePLnoEsYNB4O1jHfeeafoEgqT9wCkg8Faxng747HWjh07ct2ez3y0llKGz2sRGnT2o898tPZz3333FV1CYfbs2ZPr9txjsJbR1dXF+fPniy6jEL29vUyZMmWsL+Meg7WfXbt2FV1CYfK+K7aDwVrGRz7ykaJLKMyECfl+VR0M1jLK9Edf87Zt27Zct+dgsJaR9wBcmdxwww25bs/BYC3jxhtvLLqEwjz22GO5bs9HJaxlXH/99bzyyitFl1GISqVCR0fHWF/Gt3az9lSGz2tRGnCSkw9XWvtZtWpV0SUU5u233851e+4xWMuYMGHCuD0y8aEPfYjXXnttrC/jHoO1n0qlUnQJhdmzZw9Tp07NbXsOBmsZs2fPLrqEwjzzzDO89dZbuW3PwWDWAtauXZvrwKuDwVrGmTNnii6hMDNnzsx1ew4GaxkXLlwouoTcLVmyBMj/tnY+KmEtpQyf1yL4Ri1mdpFHH3009206GKyl7N27t+gScrdmzRo+97nP5bpN70pYS5HEBz7wAY4fP150KbnyroTZJUQEW7ZsKbqM3D377LO5bs89BmtJZfjc5sk9BjPLmDhxYq7bGzYYJE2WtE3SLkkvS/pual8kaaukg5Iek9SV2iel+UNp+cLmvgUbjz74wQ8WXUKu8j6Ho54ew3lgZUTcBCwF7pS0HHgAeDAiFgOngXVp/XXA6Yi4DngwrWfWUMeOHaO3t7foMpquqF2mYYMhqt5Ms53pEcBK4JepfRNwd5peneZJyz+lBu0gmdWaMmUKfX19RZfRVJ///OcL2W5dYwySOiTtBE4AzwGHgTMRMdC/6QHmpel5wDGAtPwscOUQr7leUrek7rG9BRvPurq6ii6hqZ588slGDTyOSF3BEBH9EbEUmA98HFgy1Grpeah3kekPRcTGiFhW7yip2VAWLVpUdAlNJSn3PzYDIzwqERFngN8Ay4EZkgaGSucDA2ec9AALANLy6cCpRhRrNtiRI0dyH7HP29mzZ3PfZj1HJa6SNCNNXwZ8GtgPvAjck1ZbCzyVpjenedLyF2K8HXS2XPX39zfiDsqlNGfOnEK2O+wJTpI+SnUwsYNqkDweEf8s6VrgUWAWsAO4NyLOS5oM/CdwM9WewpqIuOTN6nyCkzVCX18fnZ2dRZfRUA0eX6j7BKdh+2ARsZvql3xw+2tUxxsGt78DfKGejZs1UldXF5VKpZDBumZ4+OGHC9u2T4m2tlOGz3QjRESj/5itT4m28atdegxFvg8Hg7WldggHB4NZE7RDOBTFwWBtzeEwOg4Ga3vXXHNN0SWMWNGB5mCwtnf06NHCv2gj8eabbw6/UpM5GGzcWLBgQdEl1OWKK64ougQHg40fPT09pe85lKG3AA4GG4fKHA5l6C2Ag8HGqTJedFWmwHIw2LhUqVTYvHlz0WWUloPBxq3Vq1dz9OjRosvgvvvuK1VvAXwRlRlvvPFGYfc9gFx3IXwRlVm95s6dy+OPP577dpcsWdLoqycbppxVmeXsi1/8IpKQxIEDBwA4efIkQFPGIvr6+njllVdKe2MZB4PZINdffz0RwezZswFYtWpVw7fxwAPVP7dS1tvfe4zBbBBJ9Pb2Mnny5CGXRwSSOHXqFLNmzRr1NgrgMQaz0YoILrvsMm6++eaLzkSsVCrAn77UM2fOvOjndu/enXmtvr4+tm7diiRuu+02Dh8+XLojEENxMJi9j507dzJjxgwkvXcL93379nHq1Ckuv/xyTp8+DcC2bduoVCpMmTKFqVOnIonjx4/zne98h87OTlauXAnA0qVLue666wp7PyPhXQmzEejo6KC/v/+its7OTm699VZ6eno4cuQI06ZN49y5cwVVeEl170o4GMzGD48xmNnoORjMLMPBYGYZDgYzy3AwmFmGg8HMMhwMZpbhYDCzDAeDmWU4GMwsw8FgZhl1B4OkDkk7JD2d5hdJ2irpoKTHJHWl9klp/lBavrA5pZtZs4ykx/ANYH/N/APAgxGxGDgNrEvt64DTEXEd8GBaz8xaSF3BIGk+8BfAv6d5ASuBX6ZVNgF3p+nVaZ60/FNqhTtTmNl76u0xfB/4NlBJ81cCZyLiQprvAeal6XnAMYC0/Gxa/yKS1kvqltQ9ytrNrEmGDQZJnwVORMT22uYhVo06lv2pIWJjRCyr9/pwM8vPxDrWWQGsknQXMBmYRrUHMUPSxNQrmA8cT+v3AAuAHkkTgenAqYZXbmZNM2yPISLuj4j5EbEQWAO8EBFfAV4E7kmrrQWeStOb0zxp+QtRhttEmVndxnIew98D35J0iOoYwkOp/SHgytT+LWDD2Eo0s7z5no9m44fv+Whmo+dgMLMMB4OZZTgYzCzDwWBmGQ4GM8twMJhZhoPBzDIcDGaW4WAwswwHg5llOBjMLMPBYGYZDgYzy3AwmFmGg8HMMhwMZpbhYDCzDAeDmWU4GMwsw8FgZhkOBjPLcDCYWYaDwcwyHAxmluFgMLMMB4OZZTgYzCzDwWBmGQ4GM8twMJhZhoPBzDIcDGaW4WAws4y6gkHSEUl7JO2U1J3aZkl6TtLB9DwztUvSDyQdkrRb0i3NfANm1ngj6THcFhFLI2JZmt8APB8Ri4Hn0zzAZ4DF6bEe+HGjijWzfIxlV2I1sClNbwLurmn/WVT9Hpgh6eoxbMfMclZvMATwrKTtktantrkR8TpAep6T2ucBx2p+tie1XUTSekndA7smZlYeE+tcb0VEHJc0B3hO0iuXWFdDtEWmIWIjsBFAUma5mRWnrh5DRBxPzyeAJ4GPA28M7CKk5xNp9R5gQc2PzweON6pgM2u+YYNB0hRJVwxMA3cAe4HNwNq02lrgqTS9GfhqOjqxHDg7sMthZq2hnl2JucCTkgbW/0VE/I+kl4DHJa0DjgJfSOtvAe4CDgG9wNcaXrWZNZUiit+9l/RH4EDRddRpNnCy6CLq0Cp1QuvU2ip1wtC1XhMRV9Xzw/UOPjbbgZrzI0pNUncr1NoqdULr1NoqdcLYa/Up0WaW4WAws4yyBMPGogsYgVaptVXqhNaptVXqhDHWWorBRzMrl7L0GMysRAoPBkl3SjqQLtPeMPxPNLWWn0o6IWlvTVspLy+XtEDSi5L2S3pZ0jfKWK+kyZK2SdqV6vxual8kaWuq8zFJXal9Upo/lJYvzKPOmno7JO2Q9HTJ62zurRAiorAH0AEcBq4FuoBdwA0F1vPnwC3A3pq2fwU2pOkNwANp+i7gv6leG7Ic2JpzrVcDt6TpK4BXgRvKVm/a3tQ03QlsTdt/HFiT2n8C/FWa/mvgJ2l6DfBYzv+u3wJ+ATyd5sta5xFg9qC2hv3f5/ZG3ufNfQL4dc38/cD9Bde0cFAwHACuTtNXUz3nAuDfgC8NtV5BdT8F3F7meoHLgT8At1I9+Wbi4M8B8GvgE2l6YlpPOdU3n+q9RVYCT6cvUunqTNscKhga9n9f9K5EXZdoF2xMl5fnIXVjb6b627h09abu+U6qF9o9R7WXeCYiLgxRy3t1puVngSvzqBP4PvBtoJLmryxpndCEWyHUKvrMx7ou0S6pUtQuaSrwK+CbEXEuXdMy5KpDtOVSb0T0A0slzaB6de6SS9RSSJ2SPguciIjtkj5ZRy1F//83/FYItYruMbTCJdqlvbxcUifVUPh5RDyRmktbb0ScAX5DdT93hqSBX0y1tbxXZ1o+HTiVQ3krgFWSjgCPUt2d+H4J6wSafyuEooPhJWBxGvntojqIs7ngmgYr5eXlqnYNHgL2R8T3ylqvpKtSTwFJlwGfBvYDLwL3vE+dA/XfA7wQace4mSLi/oiYHxELqX4OX4iIr5StTsjpVgh5Dj69zyDKXVRH1A8D/1hwLY8ArwPvUk3ZdVT3G58HDqbnWWldAT9Mde8BluVc659R7Q7uBnamx11lqxf4KLAj1bkX+KfUfi2wjerl+f8FTErtk9P8obT82gI+B5/kT0clSldnqmlXerw88L1p5P+9z3w0s4yidyXMrIQcDGaW4WAwswwHg5llOBjMLMPBYGYZDgYzy3AwmFnG/wPpMZmpWuARpwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.squeeze(prediction[1]), cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2e0a69f7780>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.squeeze(prediction[1]), cmap = \"gray\", vmin = 0.0, vmax= 0.09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.0519516e-06 8.0069021e-06 9.0966259e-06 ... 4.7527188e-05\n",
      "  2.0820278e-05 2.8622560e-05]\n",
      " [9.1147535e-07 1.0588739e-06 1.2355899e-06 ... 2.4217632e-05\n",
      "  2.3047971e-05 2.8903612e-05]\n",
      " [3.1463267e-05 2.2419010e-06 6.7238539e-06 ... 4.0554856e-05\n",
      "  9.2272503e-06 1.2011006e-05]\n",
      " ...\n",
      " [1.7847022e-05 1.7158633e-05 2.2093938e-05 ... 7.9565376e-07\n",
      "  2.8412649e-06 9.8073606e-06]\n",
      " [5.2593441e-06 1.1322943e-05 2.4530634e-06 ... 6.1780759e-07\n",
      "  3.2421085e-05 2.5181284e-06]\n",
      " [9.9023391e-06 2.5835839e-06 6.6012517e-06 ... 2.9803075e-06\n",
      "  7.0778777e-05 1.7472203e-06]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_ =  np.squeeze(np.multiply(prediction[1], 255))\n",
    "print(results_)\n",
    "\n",
    "plt.imshow(results_, cmap = \"gray\", vmin = 0.0, vmax= 0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img=mpimg.imread('05.U-Net2_results_dir/35_predict.png')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Specificity', 'loss', 'val_loss', 'val_f1score', 'val_acc', 'val_recall', 'f1score', 'val_Specificity', 'val_dice_coef', 'precision', 'Sensitivity', 'val_precision', 'acc', 'dice_coef', 'recall', 'Jaccard_index', 'mean_squared_error', 'val_Jaccard_index', 'val_mean_squared_error', 'val_Sensitivity'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['dice_coef'])\n",
    "plt.plot(history.history['val_dice_coef'])\n",
    "plt.title('model dice_coeff')\n",
    "plt.ylabel('dice_coef')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
