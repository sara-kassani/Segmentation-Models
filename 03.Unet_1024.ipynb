{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 6743576785865329468, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 9234857329\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 5558866097463813574\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras import layers, metrics, models, optimizers\n",
    "from keras.optimizers import Adam, RMSprop,SGD\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input,UpSampling2D, concatenate, Flatten, Dense, Activation, Dropout, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Version 2.1.6\n",
      "tensorflow Version 1.10.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Keras Version\", keras.__version__)\n",
    "print(\"tensorflow Version\", tf.__version__)\n",
    "# print(\"dim_ordering:\", K.image_dim_ordering())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "img_rows, img_cols =1024, 1024\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "epochs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/cvc300_train/'\n",
    "validation_dir = 'data/cvc300_validation/'\n",
    "test_dir = 'data/cvc300_test/'\n",
    "\n",
    "image_folder = 'images'\n",
    "masks_folder = 'masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 204 images belonging to 1 classes.\n",
      "Found 204 images belonging to 1 classes.\n",
      "Found 68 images belonging to 1 classes.\n",
      "Found 68 images belonging to 1 classes.\n",
      "Found 28 images belonging to 1 classes.\n",
      "Found 28 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "seed = 1142\n",
    "data_gen_args = dict(rescale=1. / 255, featurewise_center=True, featurewise_std_normalization=True)\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "masks_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "image_generator = image_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    classes = [image_folder],\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "mask_generator = masks_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    classes = [masks_folder],\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "validation_image_generator = image_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    classes = [image_folder],\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "validation_mask_generator = masks_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    classes = [masks_folder],\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "test_image_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    classes = [image_folder],\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "test_mask_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    classes = [masks_folder],\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = zip(image_generator, mask_generator)\n",
    "validation_generator = zip(validation_image_generator, validation_mask_generator)\n",
    "test_generator = zip(test_image_generator, test_mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_train_samples: 204\n",
      "nb_validation_samples: 68\n",
      "nb_test_samples: 28\n",
      "\n",
      "predict_size_train: 102\n",
      "predict_size_validation: 34\n",
      "predict_size_test: 14\n"
     ]
    }
   ],
   "source": [
    "nb_train_samples = len(image_generator.filenames)\n",
    "nb_validation_samples = len(validation_image_generator.filenames)\n",
    "nb_test_samples = len(test_image_generator.filenames)\n",
    "\n",
    "predict_size_train = int(math.ceil(nb_train_samples / batch_size))\n",
    "predict_size_validation = int(math.ceil(nb_validation_samples / batch_size))\n",
    "predict_size_test = int(math.ceil(nb_test_samples / batch_size))\n",
    "\n",
    "print(\"nb_train_samples:\", nb_train_samples)\n",
    "print(\"nb_validation_samples:\", nb_validation_samples)\n",
    "print(\"nb_test_samples:\", nb_test_samples)\n",
    "\n",
    "print(\"\\npredict_size_train:\", predict_size_train)\n",
    "print(\"predict_size_validation:\", predict_size_validation)\n",
    "print(\"predict_size_test:\", predict_size_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet_1024(input_shape=(img_rows, img_cols, 3),num_classes=1):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # 1024\n",
    "\n",
    "    down0b = Conv2D(8, (3, 3), padding='same')(inputs)\n",
    "    down0b = BatchNormalization()(down0b)\n",
    "    down0b = Activation('relu')(down0b)\n",
    "    down0b = Conv2D(8, (3, 3), padding='same')(down0b)\n",
    "    down0b = BatchNormalization()(down0b)\n",
    "    down0b = Activation('relu')(down0b)\n",
    "    down0b_pool = MaxPooling2D((2, 2), strides=(2, 2))(down0b)\n",
    "    # 512\n",
    "\n",
    "    down0a = Conv2D(16, (3, 3), padding='same')(down0b_pool)\n",
    "    down0a = BatchNormalization()(down0a)\n",
    "    down0a = Activation('relu')(down0a)\n",
    "    down0a = Conv2D(16, (3, 3), padding='same')(down0a)\n",
    "    down0a = BatchNormalization()(down0a)\n",
    "    down0a = Activation('relu')(down0a)\n",
    "    down0a_pool = MaxPooling2D((2, 2), strides=(2, 2))(down0a)\n",
    "    # 256\n",
    "\n",
    "    down0 = Conv2D(32, (3, 3), padding='same')(down0a_pool)\n",
    "    down0 = BatchNormalization()(down0)\n",
    "    down0 = Activation('relu')(down0)\n",
    "    down0 = Conv2D(32, (3, 3), padding='same')(down0)\n",
    "    down0 = BatchNormalization()(down0)\n",
    "    down0 = Activation('relu')(down0)\n",
    "    down0_pool = MaxPooling2D((2, 2), strides=(2, 2))(down0)\n",
    "    # 128\n",
    "\n",
    "    down1 = Conv2D(64, (3, 3), padding='same')(down0_pool)\n",
    "    down1 = BatchNormalization()(down1)\n",
    "    down1 = Activation('relu')(down1)\n",
    "    down1 = Conv2D(64, (3, 3), padding='same')(down1)\n",
    "    down1 = BatchNormalization()(down1)\n",
    "    down1 = Activation('relu')(down1)\n",
    "    down1_pool = MaxPooling2D((2, 2), strides=(2, 2))(down1)\n",
    "    # 64\n",
    "\n",
    "    down2 = Conv2D(128, (3, 3), padding='same')(down1_pool)\n",
    "    down2 = BatchNormalization()(down2)\n",
    "    down2 = Activation('relu')(down2)\n",
    "    down2 = Conv2D(128, (3, 3), padding='same')(down2)\n",
    "    down2 = BatchNormalization()(down2)\n",
    "    down2 = Activation('relu')(down2)\n",
    "    down2_pool = MaxPooling2D((2, 2), strides=(2, 2))(down2)\n",
    "    # 32\n",
    "\n",
    "    down3 = Conv2D(256, (3, 3), padding='same')(down2_pool)\n",
    "    down3 = BatchNormalization()(down3)\n",
    "    down3 = Activation('relu')(down3)\n",
    "    down3 = Conv2D(256, (3, 3), padding='same')(down3)\n",
    "    down3 = BatchNormalization()(down3)\n",
    "    down3 = Activation('relu')(down3)\n",
    "    down3_pool = MaxPooling2D((2, 2), strides=(2, 2))(down3)\n",
    "    # 16\n",
    "\n",
    "    down4 = Conv2D(512, (3, 3), padding='same')(down3_pool)\n",
    "    down4 = BatchNormalization()(down4)\n",
    "    down4 = Activation('relu')(down4)\n",
    "    down4 = Conv2D(512, (3, 3), padding='same')(down4)\n",
    "    down4 = BatchNormalization()(down4)\n",
    "    down4 = Activation('relu')(down4)\n",
    "    down4_pool = MaxPooling2D((2, 2), strides=(2, 2))(down4)\n",
    "    # 8\n",
    "\n",
    "    center = Conv2D(1024, (3, 3), padding='same')(down4_pool)\n",
    "    center = BatchNormalization()(center)\n",
    "    center = Activation('relu')(center)\n",
    "    center = Conv2D(1024, (3, 3), padding='same')(center)\n",
    "    center = BatchNormalization()(center)\n",
    "    center = Activation('relu')(center)\n",
    "    # center\n",
    "\n",
    "    up4 = UpSampling2D((2, 2))(center)\n",
    "    up4 = concatenate([down4, up4], axis=3)\n",
    "    up4 = Conv2D(512, (3, 3), padding='same')(up4)\n",
    "    up4 = BatchNormalization()(up4)\n",
    "    up4 = Activation('relu')(up4)\n",
    "    up4 = Conv2D(512, (3, 3), padding='same')(up4)\n",
    "    up4 = BatchNormalization()(up4)\n",
    "    up4 = Activation('relu')(up4)\n",
    "    up4 = Conv2D(512, (3, 3), padding='same')(up4)\n",
    "    up4 = BatchNormalization()(up4)\n",
    "    up4 = Activation('relu')(up4)\n",
    "    # 16\n",
    "\n",
    "    up3 = UpSampling2D((2, 2))(up4)\n",
    "    up3 = concatenate([down3, up3], axis=3)\n",
    "    up3 = Conv2D(256, (3, 3), padding='same')(up3)\n",
    "    up3 = BatchNormalization()(up3)\n",
    "    up3 = Activation('relu')(up3)\n",
    "    up3 = Conv2D(256, (3, 3), padding='same')(up3)\n",
    "    up3 = BatchNormalization()(up3)\n",
    "    up3 = Activation('relu')(up3)\n",
    "    up3 = Conv2D(256, (3, 3), padding='same')(up3)\n",
    "    up3 = BatchNormalization()(up3)\n",
    "    up3 = Activation('relu')(up3)\n",
    "    # 32\n",
    "\n",
    "    up2 = UpSampling2D((2, 2))(up3)\n",
    "    up2 = concatenate([down2, up2], axis=3)\n",
    "    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n",
    "    up2 = BatchNormalization()(up2)\n",
    "    up2 = Activation('relu')(up2)\n",
    "    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n",
    "    up2 = BatchNormalization()(up2)\n",
    "    up2 = Activation('relu')(up2)\n",
    "    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n",
    "    up2 = BatchNormalization()(up2)\n",
    "    up2 = Activation('relu')(up2)\n",
    "    # 64\n",
    "\n",
    "    up1 = UpSampling2D((2, 2))(up2)\n",
    "    up1 = concatenate([down1, up1], axis=3)\n",
    "    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n",
    "    up1 = BatchNormalization()(up1)\n",
    "    up1 = Activation('relu')(up1)\n",
    "    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n",
    "    up1 = BatchNormalization()(up1)\n",
    "    up1 = Activation('relu')(up1)\n",
    "    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n",
    "    up1 = BatchNormalization()(up1)\n",
    "    up1 = Activation('relu')(up1)\n",
    "    # 128\n",
    "\n",
    "    up0 = UpSampling2D((2, 2))(up1)\n",
    "    up0 = concatenate([down0, up0], axis=3)\n",
    "    up0 = Conv2D(32, (3, 3), padding='same')(up0)\n",
    "    up0 = BatchNormalization()(up0)\n",
    "    up0 = Activation('relu')(up0)\n",
    "    up0 = Conv2D(32, (3, 3), padding='same')(up0)\n",
    "    up0 = BatchNormalization()(up0)\n",
    "    up0 = Activation('relu')(up0)\n",
    "    up0 = Conv2D(32, (3, 3), padding='same')(up0)\n",
    "    up0 = BatchNormalization()(up0)\n",
    "    up0 = Activation('relu')(up0)\n",
    "    # 256\n",
    "\n",
    "    up0a = UpSampling2D((2, 2))(up0)\n",
    "    up0a = concatenate([down0a, up0a], axis=3)\n",
    "    up0a = Conv2D(16, (3, 3), padding='same')(up0a)\n",
    "    up0a = BatchNormalization()(up0a)\n",
    "    up0a = Activation('relu')(up0a)\n",
    "    up0a = Conv2D(16, (3, 3), padding='same')(up0a)\n",
    "    up0a = BatchNormalization()(up0a)\n",
    "    up0a = Activation('relu')(up0a)\n",
    "    up0a = Conv2D(16, (3, 3), padding='same')(up0a)\n",
    "    up0a = BatchNormalization()(up0a)\n",
    "    up0a = Activation('relu')(up0a)\n",
    "    # 512\n",
    "\n",
    "    up0b = UpSampling2D((2, 2))(up0a)\n",
    "    up0b = concatenate([down0b, up0b], axis=3)\n",
    "    up0b = Conv2D(8, (3, 3), padding='same')(up0b)\n",
    "    up0b = BatchNormalization()(up0b)\n",
    "    up0b = Activation('relu')(up0b)\n",
    "    up0b = Conv2D(8, (3, 3), padding='same')(up0b)\n",
    "    up0b = BatchNormalization()(up0b)\n",
    "    up0b = Activation('relu')(up0b)\n",
    "    up0b = Conv2D(8, (3, 3), padding='same')(up0b)\n",
    "    up0b = BatchNormalization()(up0b)\n",
    "    up0b = Activation('relu')(up0b)\n",
    "    # 1024\n",
    "\n",
    "    classify = Conv2D(num_classes, (1, 1), activation='sigmoid')(up0b)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=classify)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 1.\n",
    "from keras import backend as K\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def Specificity(y_true, y_pred):\n",
    "    true_negatives = K.abs(y_pred)- K.abs(y_true)\n",
    "    return ((true_negatives+smooth)/(y_pred+ smooth))\n",
    "\n",
    "def Sensitivity(y_true, y_pred):\n",
    "    y_true = K.flatten(y_true)\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    return ((y_pred+smooth)/ (y_true+smooth))\n",
    "\n",
    "def Jaccard_index(y_true,y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return ((intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + smooth))\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "    Only computes a batch-wise average of precision.\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "    Only computes a batch-wise average of recall.\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def f1score(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "        Only computes a batch-wise average of recall.\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "        Only computes a batch-wise average of precision.\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1024, 1024, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 1024, 1024, 8 224         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1024, 1024, 8 32          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1024, 1024, 8 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 1024, 1024, 8 584         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1024, 1024, 8 32          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1024, 1024, 8 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 512, 512, 8)  0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 512, 512, 16) 1168        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 512, 512, 16) 64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 512, 512, 16) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 512, 512, 16) 2320        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 512, 512, 16) 64          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 512, 512, 16) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 256, 256, 16) 0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 256, 256, 32) 4640        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 256, 256, 32) 128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 256, 256, 32) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 256, 256, 32) 9248        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 256, 256, 32) 128         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 256, 256, 32) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 128, 128, 32) 0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 128, 128, 64) 18496       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 128, 128, 64) 256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 128, 128, 64) 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 128, 128, 64) 36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 128, 128, 64) 256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 128, 128, 64) 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 64, 64, 64)   0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 64, 64, 128)  73856       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 64, 64, 128)  512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 64, 64, 128)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 128)  147584      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64, 64, 128)  512         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64, 64, 128)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 32, 32, 128)  0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 256)  295168      max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 256)  1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 256)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 256)  590080      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 256)  1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 256)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 16, 16, 256)  0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 512)  1180160     max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 512)  2048        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 512)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 512)  2359808     activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 512)  2048        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 512)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 512)    0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 8, 8, 1024)   4719616     max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 8, 8, 1024)   4096        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8, 8, 1024)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 8, 8, 1024)   9438208     activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 8, 1024)   4096        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 1024)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 1024) 0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16, 16, 1536) 0           activation_14[0][0]              \n",
      "                                                                 up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 512)  7078400     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 512)  2048        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 512)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 512)  2359808     activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 512)  2048        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 512)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 512)  2359808     activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 512)  2048        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 512)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 512)  0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 768)  0           activation_12[0][0]              \n",
      "                                                                 up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 32, 256)  1769728     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 256)  1024        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 32, 32, 256)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 256)  590080      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 256)  1024        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 32, 256)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 256)  590080      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 32, 32, 256)  1024        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 32, 32, 256)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 256)  0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64, 64, 384)  0           activation_10[0][0]              \n",
      "                                                                 up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 64, 64, 128)  442496      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 64, 64, 128)  512         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 64, 64, 128)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 64, 64, 128)  147584      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 64, 64, 128)  512         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 64, 64, 128)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 64, 64, 128)  147584      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 64, 64, 128)  512         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 64, 64, 128)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 128, 128, 128 0           activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 128, 128, 192 0           activation_8[0][0]               \n",
      "                                                                 up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 128, 128, 64) 110656      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 128, 128, 64) 256         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 128, 128, 64) 0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 128, 128, 64) 36928       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 128, 128, 64) 256         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 128, 128, 64) 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 128, 128, 64) 36928       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 128, 128, 64) 256         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 128, 128, 64) 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 256, 256, 64) 0           activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 256, 256, 96) 0           activation_6[0][0]               \n",
      "                                                                 up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 256, 256, 32) 27680       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 256, 256, 32) 128         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 256, 256, 32) 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 256, 256, 32) 9248        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 256, 256, 32) 128         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 256, 256, 32) 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 256, 256, 32) 9248        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 256, 256, 32) 128         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 256, 256, 32) 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 512, 512, 32) 0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 512, 512, 48) 0           activation_4[0][0]               \n",
      "                                                                 up_sampling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 512, 512, 16) 6928        concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 512, 512, 16) 64          conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 512, 512, 16) 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 512, 512, 16) 2320        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 512, 512, 16) 64          conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 512, 512, 16) 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 512, 512, 16) 2320        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 512, 512, 16) 64          conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 512, 512, 16) 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 1024, 1024, 1 0           activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 1024, 1024, 2 0           activation_2[0][0]               \n",
      "                                                                 up_sampling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 1024, 1024, 8 1736        concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 1024, 1024, 8 32          conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 1024, 1024, 8 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 1024, 1024, 8 584         activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 1024, 1024, 8 32          conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 1024, 1024, 8 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 1024, 1024, 8 584         activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 1024, 1024, 8 32          conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 1024, 1024, 8 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 1024, 1024, 1 9           activation_37[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 34,637,337\n",
      "Trainable params: 34,623,081\n",
      "Non-trainable params: 14,256\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_unet_1024()\n",
    "model.summary()\n",
    "adam_opt = Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(optimizer= adam_opt, loss=dice_coef_loss, \n",
    "              metrics=[dice_coef, 'acc','mse', Jaccard_index, Specificity, Sensitivity, precision, recall, f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "102/102 [==============================] - 44s 432ms/step - loss: -0.1003 - dice_coef: 0.1003 - acc: 0.3456 - mean_squared_error: 0.2958 - Jaccard_index: 0.0534 - Specificity: 0.9697 - Sensitivity: 1.4973 - precision: 0.0665 - recall: 0.9382 - f1score: 0.1223 - val_loss: -0.1244 - val_dice_coef: 0.1244 - val_acc: 0.4072 - val_mean_squared_error: 0.2824 - val_Jaccard_index: 0.0677 - val_Specificity: 0.9638 - val_Sensitivity: 1.4759 - val_precision: 0.0894 - val_recall: 0.9582 - val_f1score: 0.1593\n",
      "Epoch 2/25\n",
      "102/102 [==============================] - 33s 320ms/step - loss: -0.1072 - dice_coef: 0.1072 - acc: 0.3912 - mean_squared_error: 0.2962 - Jaccard_index: 0.0574 - Specificity: 0.9705 - Sensitivity: 1.4948 - precision: 0.0728 - recall: 0.9645 - f1score: 0.1330 - val_loss: -0.1292 - val_dice_coef: 0.1292 - val_acc: 0.4441 - val_mean_squared_error: 0.2782 - val_Jaccard_index: 0.0709 - val_Specificity: 0.9652 - val_Sensitivity: 1.4684 - val_precision: 0.0963 - val_recall: 0.9681 - val_f1score: 0.1688\n",
      "Epoch 3/25\n",
      "102/102 [==============================] - 33s 320ms/step - loss: -0.1133 - dice_coef: 0.1133 - acc: 0.4264 - mean_squared_error: 0.2958 - Jaccard_index: 0.0609 - Specificity: 0.9711 - Sensitivity: 1.4923 - precision: 0.0782 - recall: 0.9780 - f1score: 0.1424 - val_loss: -0.1260 - val_dice_coef: 0.1260 - val_acc: 0.4626 - val_mean_squared_error: 0.2816 - val_Jaccard_index: 0.0684 - val_Specificity: 0.9687 - val_Sensitivity: 1.4735 - val_precision: 0.0929 - val_recall: 0.9835 - val_f1score: 0.1654\n",
      "Epoch 4/25\n",
      "102/102 [==============================] - 33s 320ms/step - loss: -0.1197 - dice_coef: 0.1197 - acc: 0.4556 - mean_squared_error: 0.2925 - Jaccard_index: 0.0646 - Specificity: 0.9717 - Sensitivity: 1.4886 - precision: 0.0830 - recall: 0.9870 - f1score: 0.1502 - val_loss: -0.1518 - val_dice_coef: 0.1518 - val_acc: 0.4740 - val_mean_squared_error: 0.2929 - val_Jaccard_index: 0.0846 - val_Specificity: 0.9630 - val_Sensitivity: 1.4777 - val_precision: 0.1139 - val_recall: 0.9898 - val_f1score: 0.1964\n",
      "Epoch 5/25\n",
      "102/102 [==============================] - 33s 320ms/step - loss: -0.1248 - dice_coef: 0.1248 - acc: 0.4855 - mean_squared_error: 0.2883 - Jaccard_index: 0.0676 - Specificity: 0.9722 - Sensitivity: 1.4842 - precision: 0.0868 - recall: 0.9898 - f1score: 0.1564 - val_loss: -0.1472 - val_dice_coef: 0.1472 - val_acc: 0.5169 - val_mean_squared_error: 0.2823 - val_Jaccard_index: 0.0811 - val_Specificity: 0.9665 - val_Sensitivity: 1.4706 - val_precision: 0.1094 - val_recall: 0.9932 - val_f1score: 0.1918\n",
      "Epoch 6/25\n",
      "102/102 [==============================] - 33s 320ms/step - loss: -0.1305 - dice_coef: 0.1305 - acc: 0.5198 - mean_squared_error: 0.2823 - Jaccard_index: 0.0709 - Specificity: 0.9726 - Sensitivity: 1.4789 - precision: 0.0942 - recall: 0.9949 - f1score: 0.1681 - val_loss: -0.1558 - val_dice_coef: 0.1558 - val_acc: 0.5701 - val_mean_squared_error: 0.2680 - val_Jaccard_index: 0.0862 - val_Specificity: 0.9661 - val_Sensitivity: 1.4583 - val_precision: 0.1235 - val_recall: 0.9772 - val_f1score: 0.2134\n",
      "Epoch 7/25\n",
      "102/102 [==============================] - 33s 321ms/step - loss: -0.1353 - dice_coef: 0.1353 - acc: 0.5444 - mean_squared_error: 0.2781 - Jaccard_index: 0.0737 - Specificity: 0.9729 - Sensitivity: 1.4743 - precision: 0.0981 - recall: 0.9930 - f1score: 0.1747 - val_loss: -0.1433 - val_dice_coef: 0.1433 - val_acc: 0.5936 - val_mean_squared_error: 0.2524 - val_Jaccard_index: 0.0789 - val_Specificity: 0.9691 - val_Sensitivity: 1.4470 - val_precision: 0.1178 - val_recall: 0.9618 - val_f1score: 0.2033\n",
      "Epoch 8/25\n",
      "102/102 [==============================] - 33s 321ms/step - loss: -0.1409 - dice_coef: 0.1409 - acc: 0.5665 - mean_squared_error: 0.2723 - Jaccard_index: 0.0770 - Specificity: 0.9733 - Sensitivity: 1.4687 - precision: 0.1021 - recall: 0.9940 - f1score: 0.1813 - val_loss: -0.1556 - val_dice_coef: 0.1556 - val_acc: 0.5919 - val_mean_squared_error: 0.2712 - val_Jaccard_index: 0.0866 - val_Specificity: 0.9680 - val_Sensitivity: 1.4611 - val_precision: 0.1256 - val_recall: 0.9674 - val_f1score: 0.2141\n",
      "Epoch 9/25\n",
      "102/102 [==============================] - 33s 321ms/step - loss: -0.1454 - dice_coef: 0.1454 - acc: 0.5809 - mean_squared_error: 0.2665 - Jaccard_index: 0.0798 - Specificity: 0.9736 - Sensitivity: 1.4620 - precision: 0.1048 - recall: 0.9927 - f1score: 0.1852 - val_loss: -0.1781 - val_dice_coef: 0.1781 - val_acc: 0.6105 - val_mean_squared_error: 0.2660 - val_Jaccard_index: 0.1002 - val_Specificity: 0.9656 - val_Sensitivity: 1.4543 - val_precision: 0.1420 - val_recall: 0.9777 - val_f1score: 0.2397\n",
      "Epoch 10/25\n",
      "102/102 [==============================] - 33s 321ms/step - loss: -0.1537 - dice_coef: 0.1537 - acc: 0.5981 - mean_squared_error: 0.2550 - Jaccard_index: 0.0845 - Specificity: 0.9740 - Sensitivity: 1.4522 - precision: 0.1088 - recall: 0.9940 - f1score: 0.1924 - val_loss: -0.1582 - val_dice_coef: 0.1582 - val_acc: 0.6020 - val_mean_squared_error: 0.2765 - val_Jaccard_index: 0.0881 - val_Specificity: 0.9696 - val_Sensitivity: 1.4629 - val_precision: 0.1235 - val_recall: 0.9664 - val_f1score: 0.2108\n",
      "Epoch 11/25\n",
      "102/102 [==============================] - 33s 321ms/step - loss: -0.1612 - dice_coef: 0.1612 - acc: 0.6164 - mean_squared_error: 0.2401 - Jaccard_index: 0.0895 - Specificity: 0.9744 - Sensitivity: 1.4402 - precision: 0.1145 - recall: 0.9968 - f1score: 0.1998 - val_loss: -0.1709 - val_dice_coef: 0.1709 - val_acc: 0.6229 - val_mean_squared_error: 0.2660 - val_Jaccard_index: 0.0962 - val_Specificity: 0.9688 - val_Sensitivity: 1.4517 - val_precision: 0.1381 - val_recall: 0.9705 - val_f1score: 0.2289\n",
      "Epoch 12/25\n",
      "102/102 [==============================] - 33s 321ms/step - loss: -0.1680 - dice_coef: 0.1680 - acc: 0.6244 - mean_squared_error: 0.2277 - Jaccard_index: 0.0933 - Specificity: 0.9746 - Sensitivity: 1.4295 - precision: 0.1164 - recall: 0.9969 - f1score: 0.2036 - val_loss: -0.1762 - val_dice_coef: 0.1762 - val_acc: 0.6545 - val_mean_squared_error: 0.2151 - val_Jaccard_index: 0.0993 - val_Specificity: 0.9692 - val_Sensitivity: 1.4112 - val_precision: 0.1425 - val_recall: 0.9468 - val_f1score: 0.2372\n",
      "Epoch 13/25\n",
      "102/102 [==============================] - 33s 321ms/step - loss: -0.1717 - dice_coef: 0.1717 - acc: 0.6369 - mean_squared_error: 0.2171 - Jaccard_index: 0.0956 - Specificity: 0.9747 - Sensitivity: 1.4200 - precision: 0.1190 - recall: 0.9953 - f1score: 0.2077 - val_loss: -0.1814 - val_dice_coef: 0.1814 - val_acc: 0.6365 - val_mean_squared_error: 0.2058 - val_Jaccard_index: 0.1023 - val_Specificity: 0.9678 - val_Sensitivity: 1.4033 - val_precision: 0.1344 - val_recall: 0.9254 - val_f1score: 0.2273\n",
      "Epoch 14/25\n",
      "102/102 [==============================] - 33s 321ms/step - loss: -0.1760 - dice_coef: 0.1760 - acc: 0.6377 - mean_squared_error: 0.2088 - Jaccard_index: 0.0983 - Specificity: 0.9748 - Sensitivity: 1.4126 - precision: 0.1195 - recall: 0.9961 - f1score: 0.2085 - val_loss: -0.1924 - val_dice_coef: 0.1924 - val_acc: 0.6583 - val_mean_squared_error: 0.1953 - val_Jaccard_index: 0.1095 - val_Specificity: 0.9671 - val_Sensitivity: 1.3918 - val_precision: 0.1470 - val_recall: 0.9457 - val_f1score: 0.2459\n",
      "Epoch 15/25\n",
      "102/102 [==============================] - 33s 321ms/step - loss: -0.1788 - dice_coef: 0.1788 - acc: 0.6425 - mean_squared_error: 0.2023 - Jaccard_index: 0.1000 - Specificity: 0.9748 - Sensitivity: 1.4063 - precision: 0.1213 - recall: 0.9964 - f1score: 0.2110 - val_loss: -0.1741 - val_dice_coef: 0.1741 - val_acc: 0.6561 - val_mean_squared_error: 0.2004 - val_Jaccard_index: 0.0990 - val_Specificity: 0.9714 - val_Sensitivity: 1.3980 - val_precision: 0.1352 - val_recall: 0.9450 - val_f1score: 0.2239\n",
      "Epoch 16/25\n",
      "102/102 [==============================] - 33s 321ms/step - loss: -0.1812 - dice_coef: 0.1812 - acc: 0.6473 - mean_squared_error: 0.1953 - Jaccard_index: 0.1017 - Specificity: 0.9749 - Sensitivity: 1.4004 - precision: 0.1227 - recall: 0.9976 - f1score: 0.2125 - val_loss: -0.1995 - val_dice_coef: 0.1995 - val_acc: 0.6490 - val_mean_squared_error: 0.2083 - val_Jaccard_index: 0.1146 - val_Specificity: 0.9692 - val_Sensitivity: 1.4031 - val_precision: 0.1448 - val_recall: 0.9644 - val_f1score: 0.2418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25\n",
      "102/102 [==============================] - 33s 321ms/step - loss: -0.1846 - dice_coef: 0.1846 - acc: 0.6478 - mean_squared_error: 0.1894 - Jaccard_index: 0.1037 - Specificity: 0.9750 - Sensitivity: 1.3954 - precision: 0.1227 - recall: 0.9977 - f1score: 0.2133 - val_loss: -0.1866 - val_dice_coef: 0.1866 - val_acc: 0.6534 - val_mean_squared_error: 0.1835 - val_Jaccard_index: 0.1071 - val_Specificity: 0.9686 - val_Sensitivity: 1.3824 - val_precision: 0.1386 - val_recall: 0.9310 - val_f1score: 0.2300\n",
      "Epoch 18/25\n",
      "102/102 [==============================] - 33s 321ms/step - loss: -0.1873 - dice_coef: 0.1873 - acc: 0.6530 - mean_squared_error: 0.1842 - Jaccard_index: 0.1053 - Specificity: 0.9751 - Sensitivity: 1.3909 - precision: 0.1243 - recall: 0.9986 - f1score: 0.2159 - val_loss: -0.1877 - val_dice_coef: 0.1877 - val_acc: 0.6709 - val_mean_squared_error: 0.1813 - val_Jaccard_index: 0.1072 - val_Specificity: 0.9671 - val_Sensitivity: 1.3760 - val_precision: 0.1512 - val_recall: 0.9142 - val_f1score: 0.2457\n",
      "Epoch 19/25\n",
      "102/102 [==============================] - 33s 321ms/step - loss: -0.1889 - dice_coef: 0.1889 - acc: 0.6589 - mean_squared_error: 0.1801 - Jaccard_index: 0.1062 - Specificity: 0.9751 - Sensitivity: 1.3869 - precision: 0.1257 - recall: 0.9980 - f1score: 0.2181 - val_loss: -0.1855 - val_dice_coef: 0.1855 - val_acc: 0.6707 - val_mean_squared_error: 0.1719 - val_Jaccard_index: 0.1055 - val_Specificity: 0.9662 - val_Sensitivity: 1.3686 - val_precision: 0.1431 - val_recall: 0.8911 - val_f1score: 0.2359\n",
      "Epoch 20/25\n",
      "102/102 [==============================] - 33s 322ms/step - loss: -0.1912 - dice_coef: 0.1912 - acc: 0.6708 - mean_squared_error: 0.1752 - Jaccard_index: 0.1077 - Specificity: 0.9751 - Sensitivity: 1.3827 - precision: 0.1284 - recall: 0.9989 - f1score: 0.2229 - val_loss: -0.1926 - val_dice_coef: 0.1926 - val_acc: 0.6933 - val_mean_squared_error: 0.1714 - val_Jaccard_index: 0.1095 - val_Specificity: 0.9687 - val_Sensitivity: 1.3695 - val_precision: 0.1519 - val_recall: 0.9015 - val_f1score: 0.2515\n",
      "Epoch 21/25\n",
      "102/102 [==============================] - 33s 321ms/step - loss: -0.1923 - dice_coef: 0.1923 - acc: 0.6810 - mean_squared_error: 0.1725 - Jaccard_index: 0.1085 - Specificity: 0.9752 - Sensitivity: 1.3800 - precision: 0.1325 - recall: 0.9987 - f1score: 0.2285 - val_loss: -0.2116 - val_dice_coef: 0.2116 - val_acc: 0.6864 - val_mean_squared_error: 0.1758 - val_Jaccard_index: 0.1216 - val_Specificity: 0.9641 - val_Sensitivity: 1.3697 - val_precision: 0.1722 - val_recall: 0.9279 - val_f1score: 0.2781\n",
      "Epoch 22/25\n",
      "102/102 [==============================] - 33s 321ms/step - loss: -0.1931 - dice_coef: 0.1931 - acc: 0.6910 - mean_squared_error: 0.1697 - Jaccard_index: 0.1091 - Specificity: 0.9752 - Sensitivity: 1.3772 - precision: 0.1344 - recall: 0.9988 - f1score: 0.2315 - val_loss: -0.1957 - val_dice_coef: 0.1957 - val_acc: 0.7042 - val_mean_squared_error: 0.1652 - val_Jaccard_index: 0.1117 - val_Specificity: 0.9668 - val_Sensitivity: 1.3626 - val_precision: 0.1561 - val_recall: 0.9088 - val_f1score: 0.2589\n",
      "Epoch 23/25\n",
      "102/102 [==============================] - 33s 321ms/step - loss: -0.1945 - dice_coef: 0.1945 - acc: 0.7032 - mean_squared_error: 0.1677 - Jaccard_index: 0.1098 - Specificity: 0.9752 - Sensitivity: 1.3749 - precision: 0.1391 - recall: 0.9976 - f1score: 0.2394 - val_loss: -0.2008 - val_dice_coef: 0.2008 - val_acc: 0.7075 - val_mean_squared_error: 0.1659 - val_Jaccard_index: 0.1149 - val_Specificity: 0.9646 - val_Sensitivity: 1.3590 - val_precision: 0.1743 - val_recall: 0.9098 - val_f1score: 0.2805\n",
      "Epoch 24/25\n",
      "102/102 [==============================] - 33s 321ms/step - loss: -0.1956 - dice_coef: 0.1956 - acc: 0.7109 - mean_squared_error: 0.1652 - Jaccard_index: 0.1105 - Specificity: 0.9752 - Sensitivity: 1.3725 - precision: 0.1410 - recall: 0.9988 - f1score: 0.2428 - val_loss: -0.2007 - val_dice_coef: 0.2007 - val_acc: 0.7172 - val_mean_squared_error: 0.1648 - val_Jaccard_index: 0.1147 - val_Specificity: 0.9658 - val_Sensitivity: 1.3593 - val_precision: 0.1663 - val_recall: 0.9150 - val_f1score: 0.2713\n",
      "Epoch 25/25\n",
      "102/102 [==============================] - 33s 321ms/step - loss: -0.1974 - dice_coef: 0.1974 - acc: 0.7193 - mean_squared_error: 0.1627 - Jaccard_index: 0.1115 - Specificity: 0.9752 - Sensitivity: 1.3699 - precision: 0.1450 - recall: 0.9987 - f1score: 0.2491 - val_loss: -0.1990 - val_dice_coef: 0.1990 - val_acc: 0.7403 - val_mean_squared_error: 0.1588 - val_Jaccard_index: 0.1138 - val_Specificity: 0.9655 - val_Sensitivity: 1.3533 - val_precision: 0.1752 - val_recall: 0.8671 - val_f1score: 0.2815\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=nb_train_samples//batch_size,\n",
    "                    epochs=25,\n",
    "                    validation_data = validation_generator,\n",
    "                    validation_steps = nb_validation_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Score:  -0.18917928408831358\n",
      "Validation Accuracy:  0.18917928408831358\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate_generator(validation_generator, steps=50)\n",
    "\n",
    "print ('Validation Score: ', score[0])\n",
    "print ('Validation Accuracy: ',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 4s 137ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict_generator(test_generator, verbose=1, steps=nb_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 1024, 1024, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'dice_coef', 'acc', 'mean_squared_error', 'Jaccard_index', 'Specificity', 'Sensitivity', 'precision', 'recall', 'f1score']\n",
      "[-0.16436840794980526, 0.16436840794980526, 0.7540432357788086, 0.1582325802743435, 0.09169803209602832, 0.9730122017860413, 1.3579202795028686, 0.1460312508046627, 0.8863893437385559, 0.24428079396486282]\n"
     ]
    }
   ],
   "source": [
    "test_results = model.evaluate_generator(test_generator, steps=50)\n",
    "\n",
    "print(model.metrics_names)\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training co-effiency    : 0.11151732659588258;\n",
      "Validation co-effiency : 0.11380643830360736\n"
     ]
    }
   ],
   "source": [
    "coef = np.array(history.history['Jaccard_index'])\n",
    "val_coef = np.array(history.history['val_Jaccard_index'])\n",
    "print(\"Training co-effiency    : {};\\nValidation co-effiency : {}\".format(coef[coef==max(coef)][0], val_coef[np.argmax(coef)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "\n",
    "def labelVisualize(num_class,color_dict,img):\n",
    "    img = img[:,:,0] if len(img.shape) == 3 else img\n",
    "    img_out = np.zeros(img.shape + (3,))\n",
    "    for i in range(num_class):\n",
    "        img_out[img == i,:] = color_dict[i]\n",
    "    return img_out / 255\n",
    "\n",
    "def saveResult(save_path,npyfile,flag_multi_class = False,num_class = 2):\n",
    "    for i,item in enumerate(npyfile):\n",
    "        img = labelVisualize(num_class,COLOR_DICT,item) if flag_multi_class else item[:,:,0]\n",
    "        io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
    "\n",
    "# os.mkdir('04.U-Net1_results_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveResult('04.U-Net1_results_dir',prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeData(img,mask):\n",
    "    mean = np.mean(img)\n",
    "    std = np.std(img)\n",
    "    img -= mean\n",
    "    img /= std\n",
    "    mask = mask /255\n",
    "    mask[mask > 0.5] = 1\n",
    "    mask[mask <= 0.5] = 0\n",
    "    return (img,mask)\n",
    "\n",
    "test_data_dir= \"data_augmented/cvc300_test/images/\"\n",
    "test_data_mask_dir = \"data_augmented/cvc300_test/masks/\"\n",
    "test_data_pred_dir = \"04.U-Net1_results_dir\"\n",
    "img_rows, img_cols = 512, 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image as image_utils\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img\n",
    "\n",
    "file_names = next(os.walk(test_data_dir))[2]\n",
    "scores = []\n",
    "for file in file_names:\n",
    "    grey_img = load_img(os.path.join(test_data_dir,file), target_size=(img_rows, img_cols), grayscale=False)\n",
    "    mask_img = load_img(os.path.join(test_data_mask_dir,file), target_size=(img_rows, img_cols), grayscale=True)\n",
    "    img = img_to_array(grey_img)\n",
    "    img_mask = img_to_array(mask_img)\n",
    "    \n",
    "    img, img_mask = normalizeData(img, img_mask)\n",
    "    img = np.reshape(img,(1,)+img.shape)\n",
    "    \n",
    "    pred = model.predict([img])\n",
    "    sess = tf.Session()\n",
    "    score = sess.run(Jaccard_index(img_mask, pred))\n",
    "    print(\"{} -- jaccard index: {}\".format(file,score))\n",
    "    scores.append([file,score])\n",
    "\n",
    "    result_img = array_to_img(pred[0] * 255 )\n",
    "    result_img.save(os.path.join(test_data_pred_dir, file.split('.')[0] + '_predict.jpg'))\n",
    "\n",
    "with open(\"unet_test_result.csv\", 'w') as f:\n",
    "    f.write(\"filename, jaccard_index\\n\")\n",
    "    for i in range(len(scores)):\n",
    "        #print(scores[i])\n",
    "        f.write(\"{},{}\\n\".format(scores[i][0], scores[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img=mpimg.imread('04.U-Net1_results_dir/101_predict.png')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(prediction[1]), cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(prediction[1]), cmap = \"gray\", vmin = 0.0, vmax= 0.09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ =  np.squeeze(np.multiply(prediction[1], 255))\n",
    "print(results_)\n",
    "\n",
    "plt.imshow(results_, cmap = \"gray\", vmin = 0.0, vmax= 0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img=mpimg.imread('04.U-Net1_results_dir/35_predict.png')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['dice_coef'])\n",
    "plt.plot(history.history['val_dice_coef'])\n",
    "plt.title('model dice_coeff')\n",
    "plt.ylabel('dice_coef')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
