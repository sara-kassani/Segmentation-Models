{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 2757913881147328161, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 9214062756\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 408851848666146759\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras import layers, metrics, models, optimizers\n",
    "from keras.optimizers import Adam, RMSprop,SGD\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, concatenate, Flatten, Dense, Activation, Dropout, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Version 2.2.4\n",
      "tensorflow Version 1.9.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Keras Version\", keras.__version__)\n",
    "print(\"tensorflow Version\", tf.__version__)\n",
    "# print(\"dim_ordering:\", K.image_dim_ordering())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "img_rows, img_cols = 256, 256\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data_augmented/cvc300_train/'\n",
    "validation_dir = 'data_augmented/cvc300_validation/'\n",
    "test_dir = 'data_augmented/cvc300_test/'\n",
    "\n",
    "image_folder = 'images'\n",
    "masks_folder = 'masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "\n",
    "\n",
    "def Unet(img_size):\n",
    "    inputs = Input((img_size, img_size, 3))\n",
    "    s = Lambda(lambda x: x / 255)(inputs)\n",
    "\n",
    "    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(s)\n",
    "    c1 = Dropout(0.1)(c1)\n",
    "    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "    c2 = Dropout(0.1)(c2)\n",
    "    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "    c3 = Dropout(0.2)(c3)\n",
    "    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "    c4 = Dropout(0.2)(c4)\n",
    "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "\n",
    "    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "    c5 = Dropout(0.3)(c5)\n",
    "    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "\n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    c8 = Dropout(0.1)(c8)\n",
    "    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    c9 = Dropout(0.1)(c9)\n",
    "    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26112 images belonging to 1 classes.\n",
      "Found 26112 images belonging to 1 classes.\n",
      "Found 8704 images belonging to 1 classes.\n",
      "Found 8704 images belonging to 1 classes.\n",
      "Found 28 images belonging to 1 classes.\n",
      "Found 28 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "seed = 1142\n",
    "data_gen_args = dict(rescale=1. / 255, featurewise_center=True, featurewise_std_normalization=True)\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "masks_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "image_generator = image_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    classes = [image_folder],\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "mask_generator = masks_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    classes = [masks_folder],\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "validation_image_generator = image_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    classes = [image_folder],\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "validation_mask_generator = masks_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    classes = [masks_folder],\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "test_image_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    classes = [image_folder],\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "test_mask_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    classes = [masks_folder],\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = zip(image_generator, mask_generator)\n",
    "validation_generator = zip(validation_image_generator, validation_mask_generator)\n",
    "test_generator = zip(test_image_generator, test_mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_train_samples: 26112\n",
      "nb_validation_samples: 8704\n",
      "nb_test_samples: 28\n",
      "\n",
      "predict_size_train: 1632\n",
      "predict_size_validation: 544\n",
      "predict_size_test: 2\n"
     ]
    }
   ],
   "source": [
    "nb_train_samples = len(image_generator.filenames)\n",
    "nb_validation_samples = len(validation_image_generator.filenames)\n",
    "nb_test_samples = len(test_image_generator.filenames)\n",
    "\n",
    "predict_size_train = int(math.ceil(nb_train_samples / batch_size))\n",
    "predict_size_validation = int(math.ceil(nb_validation_samples / batch_size))\n",
    "predict_size_test = int(math.ceil(nb_test_samples / batch_size))\n",
    "\n",
    "print(\"nb_train_samples:\", nb_train_samples)\n",
    "print(\"nb_validation_samples:\", nb_validation_samples)\n",
    "print(\"nb_test_samples:\", nb_test_samples)\n",
    "\n",
    "print(\"\\npredict_size_train:\", predict_size_train)\n",
    "print(\"predict_size_validation:\", predict_size_validation)\n",
    "print(\"predict_size_test:\", predict_size_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 1.\n",
    "from keras import backend as K\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def Specificity(y_true, y_pred):\n",
    "    true_negatives = K.abs(y_pred)- K.abs(y_true)\n",
    "    return ((true_negatives+smooth)/(y_pred+ smooth))\n",
    "\n",
    "def Sensitivity(y_true, y_pred):\n",
    "    y_true = K.flatten(y_true)\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    return ((y_pred+smooth)/ (y_true+smooth))\n",
    "\n",
    "def Jaccard_index(y_true,y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return ((intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + smooth))\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "    Only computes a batch-wise average of precision.\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "    Only computes a batch-wise average of recall.\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def f1score(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "        Only computes a batch-wise average of recall.\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "        Only computes a batch-wise average of precision.\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 256, 256, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 256, 256, 16) 448         lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 256, 256, 16) 0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 256, 256, 16) 2320        dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 128, 128, 16) 0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 128, 128, 32) 4640        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 128, 128, 32) 0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 128, 128, 32) 9248        dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 64, 64, 32)   0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 64, 64, 64)   18496       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 64, 64, 64)   0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 64, 64, 64)   36928       dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 32, 32, 64)   0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 128)  73856       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 32, 32, 128)  0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 32, 32, 128)  147584      dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 16, 16, 128)  0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 256)  295168      max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 16, 16, 256)  0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 256)  590080      dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 32, 32, 128)  131200      conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 256)  0           conv2d_transpose_5[0][0]         \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 32, 32, 128)  295040      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 32, 32, 128)  0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 32, 32, 128)  147584      dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 64, 64, 64)   32832       conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 64, 64, 128)  0           conv2d_transpose_6[0][0]         \n",
      "                                                                 conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 64, 64, 64)   73792       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 64, 64, 64)   0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 64, 64, 64)   36928       dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 128, 128, 32) 8224        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 128, 128, 64) 0           conv2d_transpose_7[0][0]         \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 128, 128, 32) 18464       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 128, 128, 32) 0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 128, 128, 32) 9248        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTrans (None, 256, 256, 16) 2064        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 256, 256, 32) 0           conv2d_transpose_8[0][0]         \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 256, 256, 16) 4624        concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 256, 256, 16) 0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 256, 256, 16) 2320        dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 256, 256, 1)  17          conv2d_37[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,941,105\n",
      "Trainable params: 1,941,105\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Unet(img_size = 256)\n",
    "model.summary()\n",
    "adam_opt = Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(optimizer= adam_opt, loss=dice_coef_loss, \n",
    "              metrics=[dice_coef, 'acc','mse', Jaccard_index, Specificity, Sensitivity, precision, recall, f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 365s - loss: -1.7285e-01 - dice_coef: 0.1728 - acc: 0.6534 - mean_squared_error: 0.2224 - Jaccard_index: 0.0952 - Specificity: 0.9655 - Sensitivity: 1.1952 - precision: 0.1168 - recall: 0.5148 - f1score: 0.1877 - val_loss: -1.4462e-01 - val_dice_coef: 0.1446 - val_acc: 0.2620 - val_mean_squared_error: 0.6505 - val_Jaccard_index: 0.0782 - val_Specificity: 0.9709 - val_Sensitivity: 1.6547 - val_precision: 0.0873 - val_recall: 0.9884 - val_f1score: 0.1599\n",
      "Epoch 2/50\n",
      " - 363s - loss: -1.9235e-01 - dice_coef: 0.1923 - acc: 0.7210 - mean_squared_error: 0.1474 - Jaccard_index: 0.1072 - Specificity: 0.9627 - Sensitivity: 1.1120 - precision: 0.1506 - recall: 0.3924 - f1score: 0.2072 - val_loss: -1.7526e-01 - val_dice_coef: 0.1753 - val_acc: 0.4301 - val_mean_squared_error: 0.4634 - val_Jaccard_index: 0.0965 - val_Specificity: 0.9681 - val_Sensitivity: 1.4587 - val_precision: 0.1091 - val_recall: 0.8869 - val_f1score: 0.1935\n",
      "Epoch 3/50\n",
      " - 364s - loss: -2.7394e-01 - dice_coef: 0.2739 - acc: 0.7835 - mean_squared_error: 0.0796 - Jaccard_index: 0.1605 - Specificity: 0.9618 - Sensitivity: 1.0417 - precision: 0.2581 - recall: 0.3569 - f1score: 0.2938 - val_loss: -1.0652e-01 - val_dice_coef: 0.1065 - val_acc: 0.7506 - val_mean_squared_error: 0.1192 - val_Jaccard_index: 0.0567 - val_Specificity: 0.9474 - val_Sensitivity: 1.0550 - val_precision: 0.0958 - val_recall: 0.1372 - val_f1score: 0.1111\n",
      "Epoch 4/50\n",
      " - 363s - loss: -3.4078e-01 - dice_coef: 0.3408 - acc: 0.7923 - mean_squared_error: 0.0676 - Jaccard_index: 0.2073 - Specificity: 0.9635 - Sensitivity: 1.0336 - precision: 0.3272 - recall: 0.4245 - f1score: 0.3641 - val_loss: -1.7617e-01 - val_dice_coef: 0.1762 - val_acc: 0.7054 - val_mean_squared_error: 0.1635 - val_Jaccard_index: 0.0972 - val_Specificity: 0.9528 - val_Sensitivity: 1.1156 - val_precision: 0.1352 - val_recall: 0.3374 - val_f1score: 0.1913\n",
      "Epoch 5/50\n",
      " - 432s - loss: -3.7488e-01 - dice_coef: 0.3749 - acc: 0.8001 - mean_squared_error: 0.0603 - Jaccard_index: 0.2328 - Specificity: 0.9640 - Sensitivity: 1.0274 - precision: 0.3730 - recall: 0.4468 - f1score: 0.4014 - val_loss: -1.9717e-01 - val_dice_coef: 0.1972 - val_acc: 0.6993 - val_mean_squared_error: 0.1700 - val_Jaccard_index: 0.1101 - val_Specificity: 0.9544 - val_Sensitivity: 1.1263 - val_precision: 0.1478 - val_recall: 0.3999 - val_f1score: 0.2140\n",
      "Epoch 6/50\n",
      " - 382s - loss: -4.0657e-01 - dice_coef: 0.4066 - acc: 0.8031 - mean_squared_error: 0.0547 - Jaccard_index: 0.2577 - Specificity: 0.9643 - Sensitivity: 1.0227 - precision: 0.4185 - recall: 0.4665 - f1score: 0.4352 - val_loss: -2.0098e-01 - val_dice_coef: 0.2010 - val_acc: 0.6614 - val_mean_squared_error: 0.2101 - val_Jaccard_index: 0.1125 - val_Specificity: 0.9575 - val_Sensitivity: 1.1764 - val_precision: 0.1412 - val_recall: 0.5028 - val_f1score: 0.2188\n",
      "Epoch 7/50\n",
      " - 363s - loss: -4.3472e-01 - dice_coef: 0.4347 - acc: 0.8061 - mean_squared_error: 0.0494 - Jaccard_index: 0.2807 - Specificity: 0.9646 - Sensitivity: 1.0180 - precision: 0.4639 - recall: 0.4796 - f1score: 0.4650 - val_loss: -2.3487e-01 - val_dice_coef: 0.2349 - val_acc: 0.6122 - val_mean_squared_error: 0.2600 - val_Jaccard_index: 0.1337 - val_Specificity: 0.9645 - val_Sensitivity: 1.2468 - val_precision: 0.1570 - val_recall: 0.7534 - val_f1score: 0.2582\n",
      "Epoch 8/50\n",
      " - 363s - loss: -4.6266e-01 - dice_coef: 0.4627 - acc: 0.8133 - mean_squared_error: 0.0451 - Jaccard_index: 0.3041 - Specificity: 0.9650 - Sensitivity: 1.0143 - precision: 0.5097 - recall: 0.4958 - f1score: 0.4959 - val_loss: -2.4607e-01 - val_dice_coef: 0.2461 - val_acc: 0.6415 - val_mean_squared_error: 0.2252 - val_Jaccard_index: 0.1410 - val_Specificity: 0.9626 - val_Sensitivity: 1.2058 - val_precision: 0.1691 - val_recall: 0.6955 - val_f1score: 0.2701\n",
      "Epoch 9/50\n",
      " - 363s - loss: -4.8217e-01 - dice_coef: 0.4822 - acc: 0.8134 - mean_squared_error: 0.0421 - Jaccard_index: 0.3210 - Specificity: 0.9651 - Sensitivity: 1.0117 - precision: 0.5441 - recall: 0.5046 - f1score: 0.5165 - val_loss: -2.7175e-01 - val_dice_coef: 0.2717 - val_acc: 0.6580 - val_mean_squared_error: 0.2094 - val_Jaccard_index: 0.1581 - val_Specificity: 0.9637 - val_Sensitivity: 1.1932 - val_precision: 0.1889 - val_recall: 0.7397 - val_f1score: 0.2986\n",
      "Epoch 10/50\n",
      " - 363s - loss: -5.0169e-01 - dice_coef: 0.5017 - acc: 0.8152 - mean_squared_error: 0.0399 - Jaccard_index: 0.3384 - Specificity: 0.9655 - Sensitivity: 1.0104 - precision: 0.5707 - recall: 0.5213 - f1score: 0.5383 - val_loss: -2.7953e-01 - val_dice_coef: 0.2795 - val_acc: 0.6629 - val_mean_squared_error: 0.2035 - val_Jaccard_index: 0.1632 - val_Specificity: 0.9643 - val_Sensitivity: 1.1879 - val_precision: 0.1952 - val_recall: 0.7544 - val_f1score: 0.3079\n",
      "Epoch 11/50\n",
      " - 363s - loss: -5.2036e-01 - dice_coef: 0.5204 - acc: 0.8167 - mean_squared_error: 0.0381 - Jaccard_index: 0.3555 - Specificity: 0.9656 - Sensitivity: 1.0093 - precision: 0.5974 - recall: 0.5364 - f1score: 0.5582 - val_loss: -2.8209e-01 - val_dice_coef: 0.2821 - val_acc: 0.6615 - val_mean_squared_error: 0.2060 - val_Jaccard_index: 0.1649 - val_Specificity: 0.9647 - val_Sensitivity: 1.1916 - val_precision: 0.1965 - val_recall: 0.7717 - val_f1score: 0.3109\n",
      "Epoch 12/50\n",
      " - 362s - loss: -5.3597e-01 - dice_coef: 0.5360 - acc: 0.8197 - mean_squared_error: 0.0361 - Jaccard_index: 0.3700 - Specificity: 0.9662 - Sensitivity: 1.0082 - precision: 0.6201 - recall: 0.5487 - f1score: 0.5750 - val_loss: -3.1549e-01 - val_dice_coef: 0.3155 - val_acc: 0.6904 - val_mean_squared_error: 0.1717 - val_Jaccard_index: 0.1882 - val_Specificity: 0.9640 - val_Sensitivity: 1.1552 - val_precision: 0.2277 - val_recall: 0.7586 - val_f1score: 0.3475\n",
      "Epoch 13/50\n",
      " - 362s - loss: -5.4842e-01 - dice_coef: 0.5484 - acc: 0.8198 - mean_squared_error: 0.0349 - Jaccard_index: 0.3816 - Specificity: 0.9664 - Sensitivity: 1.0076 - precision: 0.6360 - recall: 0.5602 - f1score: 0.5892 - val_loss: -3.2168e-01 - val_dice_coef: 0.3217 - val_acc: 0.6854 - val_mean_squared_error: 0.1791 - val_Jaccard_index: 0.1926 - val_Specificity: 0.9658 - val_Sensitivity: 1.1675 - val_precision: 0.2288 - val_recall: 0.8124 - val_f1score: 0.3550\n",
      "Epoch 14/50\n",
      " - 362s - loss: -5.6564e-01 - dice_coef: 0.5656 - acc: 0.8221 - mean_squared_error: 0.0330 - Jaccard_index: 0.3982 - Specificity: 0.9664 - Sensitivity: 1.0061 - precision: 0.6630 - recall: 0.5693 - f1score: 0.6065 - val_loss: -3.2484e-01 - val_dice_coef: 0.3248 - val_acc: 0.6879 - val_mean_squared_error: 0.1748 - val_Jaccard_index: 0.1949 - val_Specificity: 0.9653 - val_Sensitivity: 1.1621 - val_precision: 0.2323 - val_recall: 0.8035 - val_f1score: 0.3580\n",
      "Epoch 15/50\n",
      " - 362s - loss: -5.7909e-01 - dice_coef: 0.5791 - acc: 0.8229 - mean_squared_error: 0.0317 - Jaccard_index: 0.4113 - Specificity: 0.9668 - Sensitivity: 1.0058 - precision: 0.6801 - recall: 0.5838 - f1score: 0.6226 - val_loss: -3.2188e-01 - val_dice_coef: 0.3219 - val_acc: 0.6813 - val_mean_squared_error: 0.1825 - val_Jaccard_index: 0.1927 - val_Specificity: 0.9663 - val_Sensitivity: 1.1722 - val_precision: 0.2278 - val_recall: 0.8286 - val_f1score: 0.3556\n",
      "Epoch 16/50\n",
      " - 361s - loss: -5.8767e-01 - dice_coef: 0.5877 - acc: 0.8218 - mean_squared_error: 0.0307 - Jaccard_index: 0.4197 - Specificity: 0.9670 - Sensitivity: 1.0050 - precision: 0.6904 - recall: 0.5887 - f1score: 0.6304 - val_loss: -2.8973e-01 - val_dice_coef: 0.2897 - val_acc: 0.6503 - val_mean_squared_error: 0.2188 - val_Jaccard_index: 0.1701 - val_Specificity: 0.9665 - val_Sensitivity: 1.2093 - val_precision: 0.1985 - val_recall: 0.8418 - val_f1score: 0.3195\n",
      "Epoch 17/50\n",
      " - 362s - loss: -6.0332e-01 - dice_coef: 0.6033 - acc: 0.8255 - mean_squared_error: 0.0292 - Jaccard_index: 0.4355 - Specificity: 0.9672 - Sensitivity: 1.0043 - precision: 0.7137 - recall: 0.6022 - f1score: 0.6481 - val_loss: -3.6668e-01 - val_dice_coef: 0.3667 - val_acc: 0.7120 - val_mean_squared_error: 0.1474 - val_Jaccard_index: 0.2257 - val_Specificity: 0.9661 - val_Sensitivity: 1.1363 - val_precision: 0.2699 - val_recall: 0.8251 - val_f1score: 0.4046\n",
      "Epoch 18/50\n",
      " - 361s - loss: -6.1282e-01 - dice_coef: 0.6128 - acc: 0.8253 - mean_squared_error: 0.0281 - Jaccard_index: 0.4452 - Specificity: 0.9674 - Sensitivity: 1.0037 - precision: 0.7277 - recall: 0.6085 - f1score: 0.6581 - val_loss: -3.3426e-01 - val_dice_coef: 0.3343 - val_acc: 0.6891 - val_mean_squared_error: 0.1759 - val_Jaccard_index: 0.2016 - val_Specificity: 0.9666 - val_Sensitivity: 1.1665 - val_precision: 0.2376 - val_recall: 0.8432 - val_f1score: 0.3687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      " - 362s - loss: -6.2430e-01 - dice_coef: 0.6243 - acc: 0.8224 - mean_squared_error: 0.0271 - Jaccard_index: 0.4569 - Specificity: 0.9674 - Sensitivity: 1.0030 - precision: 0.7445 - recall: 0.6168 - f1score: 0.6704 - val_loss: -3.5900e-01 - val_dice_coef: 0.3590 - val_acc: 0.7087 - val_mean_squared_error: 0.1514 - val_Jaccard_index: 0.2198 - val_Specificity: 0.9657 - val_Sensitivity: 1.1393 - val_precision: 0.2636 - val_recall: 0.8164 - val_f1score: 0.3963\n",
      "Epoch 20/50\n",
      " - 361s - loss: -6.3511e-01 - dice_coef: 0.6351 - acc: 0.8282 - mean_squared_error: 0.0260 - Jaccard_index: 0.4683 - Specificity: 0.9677 - Sensitivity: 1.0025 - precision: 0.7576 - recall: 0.6249 - f1score: 0.6810 - val_loss: -3.6065e-01 - val_dice_coef: 0.3606 - val_acc: 0.7100 - val_mean_squared_error: 0.1514 - val_Jaccard_index: 0.2210 - val_Specificity: 0.9661 - val_Sensitivity: 1.1398 - val_precision: 0.2639 - val_recall: 0.8235 - val_f1score: 0.3975\n",
      "Epoch 21/50\n",
      " - 364s - loss: -6.4495e-01 - dice_coef: 0.6449 - acc: 0.8273 - mean_squared_error: 0.0251 - Jaccard_index: 0.4788 - Specificity: 0.9681 - Sensitivity: 1.0024 - precision: 0.7698 - recall: 0.6357 - f1score: 0.6922 - val_loss: -3.6760e-01 - val_dice_coef: 0.3676 - val_acc: 0.7149 - val_mean_squared_error: 0.1472 - val_Jaccard_index: 0.2263 - val_Specificity: 0.9659 - val_Sensitivity: 1.1353 - val_precision: 0.2706 - val_recall: 0.8202 - val_f1score: 0.4047\n",
      "Epoch 22/50\n",
      " - 362s - loss: -6.5317e-01 - dice_coef: 0.6532 - acc: 0.8277 - mean_squared_error: 0.0244 - Jaccard_index: 0.4878 - Specificity: 0.9681 - Sensitivity: 1.0021 - precision: 0.7794 - recall: 0.6431 - f1score: 0.7013 - val_loss: -3.9145e-01 - val_dice_coef: 0.3914 - val_acc: 0.7199 - val_mean_squared_error: 0.1386 - val_Jaccard_index: 0.2446 - val_Specificity: 0.9670 - val_Sensitivity: 1.1300 - val_precision: 0.2893 - val_recall: 0.8577 - val_f1score: 0.4310\n",
      "Epoch 23/50\n",
      " - 364s - loss: -6.6379e-01 - dice_coef: 0.6638 - acc: 0.8282 - mean_squared_error: 0.0236 - Jaccard_index: 0.4995 - Specificity: 0.9684 - Sensitivity: 1.0021 - precision: 0.7880 - recall: 0.6550 - f1score: 0.7122 - val_loss: -3.9223e-01 - val_dice_coef: 0.3922 - val_acc: 0.7230 - val_mean_squared_error: 0.1376 - val_Jaccard_index: 0.2455 - val_Specificity: 0.9671 - val_Sensitivity: 1.1288 - val_precision: 0.2903 - val_recall: 0.8557 - val_f1score: 0.4316\n",
      "Epoch 24/50\n",
      " - 362s - loss: -6.7049e-01 - dice_coef: 0.6705 - acc: 0.8298 - mean_squared_error: 0.0230 - Jaccard_index: 0.5069 - Specificity: 0.9686 - Sensitivity: 1.0020 - precision: 0.7950 - recall: 0.6621 - f1score: 0.7192 - val_loss: -3.6650e-01 - val_dice_coef: 0.3665 - val_acc: 0.7082 - val_mean_squared_error: 0.1534 - val_Jaccard_index: 0.2255 - val_Specificity: 0.9667 - val_Sensitivity: 1.1436 - val_precision: 0.2666 - val_recall: 0.8472 - val_f1score: 0.4035\n",
      "Epoch 25/50\n",
      " - 363s - loss: -6.8271e-01 - dice_coef: 0.6827 - acc: 0.8287 - mean_squared_error: 0.0222 - Jaccard_index: 0.5207 - Specificity: 0.9688 - Sensitivity: 1.0020 - precision: 0.8063 - recall: 0.6769 - f1score: 0.7332 - val_loss: -4.4032e-01 - val_dice_coef: 0.4403 - val_acc: 0.7464 - val_mean_squared_error: 0.1107 - val_Jaccard_index: 0.2840 - val_Specificity: 0.9666 - val_Sensitivity: 1.1006 - val_precision: 0.3405 - val_recall: 0.8444 - val_f1score: 0.4831\n",
      "Epoch 26/50\n",
      " - 364s - loss: -6.8702e-01 - dice_coef: 0.6870 - acc: 0.8286 - mean_squared_error: 0.0216 - Jaccard_index: 0.5257 - Specificity: 0.9691 - Sensitivity: 1.0019 - precision: 0.8106 - recall: 0.6815 - f1score: 0.7377 - val_loss: -3.4390e-01 - val_dice_coef: 0.3439 - val_acc: 0.6899 - val_mean_squared_error: 0.1745 - val_Jaccard_index: 0.2088 - val_Specificity: 0.9674 - val_Sensitivity: 1.1666 - val_precision: 0.2439 - val_recall: 0.8659 - val_f1score: 0.3790\n",
      "Epoch 27/50\n",
      " - 362s - loss: -6.9794e-01 - dice_coef: 0.6979 - acc: 0.8288 - mean_squared_error: 0.0209 - Jaccard_index: 0.5383 - Specificity: 0.9691 - Sensitivity: 1.0020 - precision: 0.8187 - recall: 0.6942 - f1score: 0.7489 - val_loss: -3.7619e-01 - val_dice_coef: 0.3762 - val_acc: 0.7138 - val_mean_squared_error: 0.1487 - val_Jaccard_index: 0.2328 - val_Specificity: 0.9670 - val_Sensitivity: 1.1397 - val_precision: 0.2744 - val_recall: 0.8548 - val_f1score: 0.4138\n",
      "Epoch 28/50\n",
      " - 365s - loss: -7.0436e-01 - dice_coef: 0.7044 - acc: 0.8344 - mean_squared_error: 0.0204 - Jaccard_index: 0.5458 - Specificity: 0.9695 - Sensitivity: 1.0021 - precision: 0.8239 - recall: 0.7021 - f1score: 0.7558 - val_loss: -3.7297e-01 - val_dice_coef: 0.3730 - val_acc: 0.7101 - val_mean_squared_error: 0.1529 - val_Jaccard_index: 0.2307 - val_Specificity: 0.9672 - val_Sensitivity: 1.1445 - val_precision: 0.2713 - val_recall: 0.8618 - val_f1score: 0.4107\n",
      "Epoch 29/50\n",
      " - 362s - loss: -7.1167e-01 - dice_coef: 0.7117 - acc: 0.8280 - mean_squared_error: 0.0196 - Jaccard_index: 0.5543 - Specificity: 0.9698 - Sensitivity: 1.0019 - precision: 0.8320 - recall: 0.7112 - f1score: 0.7648 - val_loss: -4.1489e-01 - val_dice_coef: 0.4149 - val_acc: 0.7326 - val_mean_squared_error: 0.1259 - val_Jaccard_index: 0.2635 - val_Specificity: 0.9673 - val_Sensitivity: 1.1175 - val_precision: 0.3116 - val_recall: 0.8634 - val_f1score: 0.4558\n",
      "Epoch 30/50\n",
      " - 362s - loss: -7.2092e-01 - dice_coef: 0.7209 - acc: 0.8305 - mean_squared_error: 0.0191 - Jaccard_index: 0.5656 - Specificity: 0.9698 - Sensitivity: 1.0020 - precision: 0.8384 - recall: 0.7234 - f1score: 0.7747 - val_loss: -4.8075e-01 - val_dice_coef: 0.4808 - val_acc: 0.7601 - val_mean_squared_error: 0.0939 - val_Jaccard_index: 0.3184 - val_Specificity: 0.9671 - val_Sensitivity: 1.0846 - val_precision: 0.3826 - val_recall: 0.8569 - val_f1score: 0.5269\n",
      "Epoch 31/50\n",
      " - 362s - loss: -7.2821e-01 - dice_coef: 0.7282 - acc: 0.8320 - mean_squared_error: 0.0185 - Jaccard_index: 0.5744 - Specificity: 0.9700 - Sensitivity: 1.0020 - precision: 0.8451 - recall: 0.7311 - f1score: 0.7821 - val_loss: -4.2815e-01 - val_dice_coef: 0.4282 - val_acc: 0.7373 - val_mean_squared_error: 0.1205 - val_Jaccard_index: 0.2743 - val_Specificity: 0.9671 - val_Sensitivity: 1.1122 - val_precision: 0.3252 - val_recall: 0.8644 - val_f1score: 0.4702\n",
      "Epoch 32/50\n",
      " - 362s - loss: -7.3552e-01 - dice_coef: 0.7355 - acc: 0.8311 - mean_squared_error: 0.0178 - Jaccard_index: 0.5834 - Specificity: 0.9704 - Sensitivity: 1.0019 - precision: 0.8522 - recall: 0.7399 - f1score: 0.7903 - val_loss: -4.4024e-01 - val_dice_coef: 0.4402 - val_acc: 0.7434 - val_mean_squared_error: 0.1133 - val_Jaccard_index: 0.2842 - val_Specificity: 0.9672 - val_Sensitivity: 1.1047 - val_precision: 0.3377 - val_recall: 0.8619 - val_f1score: 0.4831\n",
      "Epoch 33/50\n",
      " - 362s - loss: -7.4011e-01 - dice_coef: 0.7401 - acc: 0.8339 - mean_squared_error: 0.0174 - Jaccard_index: 0.5892 - Specificity: 0.9705 - Sensitivity: 1.0019 - precision: 0.8566 - recall: 0.7451 - f1score: 0.7952 - val_loss: -4.4867e-01 - val_dice_coef: 0.4487 - val_acc: 0.7428 - val_mean_squared_error: 0.1116 - val_Jaccard_index: 0.2913 - val_Specificity: 0.9678 - val_Sensitivity: 1.1047 - val_precision: 0.3451 - val_recall: 0.8830 - val_f1score: 0.4936\n",
      "Epoch 34/50\n",
      " - 362s - loss: -7.4800e-01 - dice_coef: 0.7480 - acc: 0.8311 - mean_squared_error: 0.0169 - Jaccard_index: 0.5990 - Specificity: 0.9706 - Sensitivity: 1.0020 - precision: 0.8635 - recall: 0.7555 - f1score: 0.8043 - val_loss: -4.9276e-01 - val_dice_coef: 0.4928 - val_acc: 0.7640 - val_mean_squared_error: 0.0899 - val_Jaccard_index: 0.3293 - val_Specificity: 0.9672 - val_Sensitivity: 1.0812 - val_precision: 0.3958 - val_recall: 0.8629 - val_f1score: 0.5400\n",
      "Epoch 35/50\n",
      " - 362s - loss: -7.5431e-01 - dice_coef: 0.7543 - acc: 0.8326 - mean_squared_error: 0.0163 - Jaccard_index: 0.6071 - Specificity: 0.9709 - Sensitivity: 1.0019 - precision: 0.8687 - recall: 0.7627 - f1score: 0.8107 - val_loss: -4.5010e-01 - val_dice_coef: 0.4501 - val_acc: 0.7444 - val_mean_squared_error: 0.1107 - val_Jaccard_index: 0.2923 - val_Specificity: 0.9677 - val_Sensitivity: 1.1036 - val_precision: 0.3457 - val_recall: 0.8811 - val_f1score: 0.4943\n",
      "Epoch 36/50\n",
      " - 365s - loss: -7.6066e-01 - dice_coef: 0.7607 - acc: 0.8342 - mean_squared_error: 0.0158 - Jaccard_index: 0.6153 - Specificity: 0.9710 - Sensitivity: 1.0020 - precision: 0.8741 - recall: 0.7720 - f1score: 0.8186 - val_loss: -5.1650e-01 - val_dice_coef: 0.5165 - val_acc: 0.7709 - val_mean_squared_error: 0.0815 - val_Jaccard_index: 0.3506 - val_Specificity: 0.9672 - val_Sensitivity: 1.0727 - val_precision: 0.4231 - val_recall: 0.8633 - val_f1score: 0.5652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50\n",
      " - 364s - loss: -7.6514e-01 - dice_coef: 0.7651 - acc: 0.8324 - mean_squared_error: 0.0153 - Jaccard_index: 0.6212 - Specificity: 0.9713 - Sensitivity: 1.0019 - precision: 0.8783 - recall: 0.7769 - f1score: 0.8232 - val_loss: -5.3298e-01 - val_dice_coef: 0.5330 - val_acc: 0.7743 - val_mean_squared_error: 0.0770 - val_Jaccard_index: 0.3659 - val_Specificity: 0.9673 - val_Sensitivity: 1.0690 - val_precision: 0.4408 - val_recall: 0.8747 - val_f1score: 0.5833\n",
      "Epoch 38/50\n",
      " - 365s - loss: -7.7243e-01 - dice_coef: 0.7724 - acc: 0.8333 - mean_squared_error: 0.0149 - Jaccard_index: 0.6307 - Specificity: 0.9714 - Sensitivity: 1.0020 - precision: 0.8828 - recall: 0.7874 - f1score: 0.8312 - val_loss: -5.3928e-01 - val_dice_coef: 0.5393 - val_acc: 0.7757 - val_mean_squared_error: 0.0743 - val_Jaccard_index: 0.3716 - val_Specificity: 0.9675 - val_Sensitivity: 1.0661 - val_precision: 0.4487 - val_recall: 0.8728 - val_f1score: 0.5897\n",
      "Epoch 39/50\n",
      " - 363s - loss: -7.7442e-01 - dice_coef: 0.7744 - acc: 0.8327 - mean_squared_error: 0.0147 - Jaccard_index: 0.6333 - Specificity: 0.9714 - Sensitivity: 1.0020 - precision: 0.8861 - recall: 0.7901 - f1score: 0.8342 - val_loss: -5.8524e-01 - val_dice_coef: 0.5852 - val_acc: 0.7888 - val_mean_squared_error: 0.0591 - val_Jaccard_index: 0.4162 - val_Specificity: 0.9670 - val_Sensitivity: 1.0496 - val_precision: 0.5114 - val_recall: 0.8601 - val_f1score: 0.6386\n",
      "Epoch 40/50\n",
      " - 361s - loss: -7.7925e-01 - dice_coef: 0.7793 - acc: 0.8343 - mean_squared_error: 0.0142 - Jaccard_index: 0.6398 - Specificity: 0.9716 - Sensitivity: 1.0020 - precision: 0.8903 - recall: 0.7959 - f1score: 0.8393 - val_loss: -5.7279e-01 - val_dice_coef: 0.5728 - val_acc: 0.7870 - val_mean_squared_error: 0.0626 - val_Jaccard_index: 0.4036 - val_Specificity: 0.9669 - val_Sensitivity: 1.0528 - val_precision: 0.4956 - val_recall: 0.8570 - val_f1score: 0.6254\n",
      "Epoch 41/50\n",
      " - 362s - loss: -7.8526e-01 - dice_coef: 0.7853 - acc: 0.8313 - mean_squared_error: 0.0138 - Jaccard_index: 0.6478 - Specificity: 0.9717 - Sensitivity: 1.0020 - precision: 0.8936 - recall: 0.8039 - f1score: 0.8453 - val_loss: -6.1916e-01 - val_dice_coef: 0.6192 - val_acc: 0.7989 - val_mean_squared_error: 0.0487 - val_Jaccard_index: 0.4507 - val_Specificity: 0.9664 - val_Sensitivity: 1.0372 - val_precision: 0.5673 - val_recall: 0.8377 - val_f1score: 0.6734\n",
      "Epoch 42/50\n",
      " - 360s - loss: -7.8925e-01 - dice_coef: 0.7893 - acc: 0.8368 - mean_squared_error: 0.0135 - Jaccard_index: 0.6532 - Specificity: 0.9719 - Sensitivity: 1.0022 - precision: 0.8961 - recall: 0.8101 - f1score: 0.8500 - val_loss: -6.1929e-01 - val_dice_coef: 0.6193 - val_acc: 0.7983 - val_mean_squared_error: 0.0485 - val_Jaccard_index: 0.4509 - val_Specificity: 0.9661 - val_Sensitivity: 1.0363 - val_precision: 0.5707 - val_recall: 0.8335 - val_f1score: 0.6741\n",
      "Epoch 43/50\n",
      " - 363s - loss: -7.9245e-01 - dice_coef: 0.7925 - acc: 0.8332 - mean_squared_error: 0.0132 - Jaccard_index: 0.6575 - Specificity: 0.9720 - Sensitivity: 1.0021 - precision: 0.8996 - recall: 0.8145 - f1score: 0.8541 - val_loss: -6.3049e-01 - val_dice_coef: 0.6305 - val_acc: 0.7991 - val_mean_squared_error: 0.0469 - val_Jaccard_index: 0.4630 - val_Specificity: 0.9668 - val_Sensitivity: 1.0367 - val_precision: 0.5783 - val_recall: 0.8540 - val_f1score: 0.6868\n",
      "Epoch 44/50\n",
      " - 365s - loss: -7.9471e-01 - dice_coef: 0.7947 - acc: 0.8360 - mean_squared_error: 0.0129 - Jaccard_index: 0.6607 - Specificity: 0.9722 - Sensitivity: 1.0022 - precision: 0.9013 - recall: 0.8189 - f1score: 0.8572 - val_loss: -6.1182e-01 - val_dice_coef: 0.6118 - val_acc: 0.7985 - val_mean_squared_error: 0.0516 - val_Jaccard_index: 0.4433 - val_Specificity: 0.9668 - val_Sensitivity: 1.0413 - val_precision: 0.5512 - val_recall: 0.8523 - val_f1score: 0.6662\n",
      "Epoch 45/50\n",
      " - 363s - loss: -7.9880e-01 - dice_coef: 0.7988 - acc: 0.8327 - mean_squared_error: 0.0127 - Jaccard_index: 0.6663 - Specificity: 0.9721 - Sensitivity: 1.0022 - precision: 0.9040 - recall: 0.8236 - f1score: 0.8611 - val_loss: -6.2839e-01 - val_dice_coef: 0.6284 - val_acc: 0.7955 - val_mean_squared_error: 0.0475 - val_Jaccard_index: 0.4606 - val_Specificity: 0.9665 - val_Sensitivity: 1.0366 - val_precision: 0.5780 - val_recall: 0.8483 - val_f1score: 0.6843\n",
      "Epoch 46/50\n",
      " - 364s - loss: -8.0262e-01 - dice_coef: 0.8026 - acc: 0.8367 - mean_squared_error: 0.0124 - Jaccard_index: 0.6716 - Specificity: 0.9724 - Sensitivity: 1.0023 - precision: 0.9058 - recall: 0.8292 - f1score: 0.8651 - val_loss: -6.7531e-01 - val_dice_coef: 0.6753 - val_acc: 0.8124 - val_mean_squared_error: 0.0368 - val_Jaccard_index: 0.5122 - val_Specificity: 0.9665 - val_Sensitivity: 1.0251 - val_precision: 0.6543 - val_recall: 0.8407 - val_f1score: 0.7329\n",
      "Epoch 47/50\n",
      " - 364s - loss: -8.0597e-01 - dice_coef: 0.8060 - acc: 0.8349 - mean_squared_error: 0.0121 - Jaccard_index: 0.6763 - Specificity: 0.9724 - Sensitivity: 1.0024 - precision: 0.9078 - recall: 0.8350 - f1score: 0.8691 - val_loss: -6.7298e-01 - val_dice_coef: 0.6730 - val_acc: 0.8074 - val_mean_squared_error: 0.0373 - val_Jaccard_index: 0.5095 - val_Specificity: 0.9665 - val_Sensitivity: 1.0259 - val_precision: 0.6497 - val_recall: 0.8457 - val_f1score: 0.7315\n",
      "Epoch 48/50\n",
      " - 363s - loss: -8.0806e-01 - dice_coef: 0.8081 - acc: 0.8357 - mean_squared_error: 0.0119 - Jaccard_index: 0.6793 - Specificity: 0.9726 - Sensitivity: 1.0024 - precision: 0.9089 - recall: 0.8379 - f1score: 0.8711 - val_loss: -6.8180e-01 - val_dice_coef: 0.6818 - val_acc: 0.8098 - val_mean_squared_error: 0.0362 - val_Jaccard_index: 0.5195 - val_Specificity: 0.9668 - val_Sensitivity: 1.0259 - val_precision: 0.6563 - val_recall: 0.8579 - val_f1score: 0.7408\n",
      "Epoch 49/50\n",
      " - 363s - loss: -8.1189e-01 - dice_coef: 0.8119 - acc: 0.8347 - mean_squared_error: 0.0116 - Jaccard_index: 0.6846 - Specificity: 0.9726 - Sensitivity: 1.0025 - precision: 0.9115 - recall: 0.8445 - f1score: 0.8760 - val_loss: -7.1327e-01 - val_dice_coef: 0.7133 - val_acc: 0.8139 - val_mean_squared_error: 0.0296 - val_Jaccard_index: 0.5569 - val_Specificity: 0.9663 - val_Sensitivity: 1.0177 - val_precision: 0.7194 - val_recall: 0.8408 - val_f1score: 0.7729\n",
      "Epoch 50/50\n",
      " - 365s - loss: -8.1525e-01 - dice_coef: 0.8153 - acc: 0.8341 - mean_squared_error: 0.0113 - Jaccard_index: 0.6894 - Specificity: 0.9728 - Sensitivity: 1.0026 - precision: 0.9133 - recall: 0.8496 - f1score: 0.8796 - val_loss: -6.5831e-01 - val_dice_coef: 0.6583 - val_acc: 0.8069 - val_mean_squared_error: 0.0411 - val_Jaccard_index: 0.4932 - val_Specificity: 0.9669 - val_Sensitivity: 1.0308 - val_precision: 0.6190 - val_recall: 0.8576 - val_f1score: 0.7162\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=nb_train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose = 2,\n",
    "                    validation_data = validation_generator,\n",
    "                    validation_steps = nb_validation_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Score:  -0.6461014592647553\n",
      "Validation Accuracy:  0.6461014592647553\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate_generator(validation_generator, steps=50)\n",
    "\n",
    "print ('Validation Score: ', score[0])\n",
    "print ('Validation Accuracy: ',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 167ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict_generator(test_generator, verbose=1, steps=nb_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392, 256, 256, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'dice_coef', 'acc', 'mean_squared_error', 'Jaccard_index', 'Specificity', 'Sensitivity', 'precision', 'recall', 'f1score']\n",
      "[-0.689056271144322, 0.6890562742097037, 0.9600789090565273, 0.0392681960016489, 0.5264078148773739, 0.9725590552602495, 1.0321390049798147, 0.5612502528939929, 0.8985275227682931, 0.6889424565860204]\n"
     ]
    }
   ],
   "source": [
    "test_results = model.evaluate_generator(test_generator, steps=50)\n",
    "\n",
    "print(model.metrics_names)\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training co-effiency    : 0.6893735292787645;\n",
      "Validation co-effiency : 0.4931637432754916\n"
     ]
    }
   ],
   "source": [
    "coef = np.array(history.history['Jaccard_index'])\n",
    "val_coef = np.array(history.history['val_Jaccard_index'])\n",
    "print(\"Training co-effiency    : {};\\nValidation co-effiency : {}\".format(coef[coef==max(coef)][0], val_coef[np.argmax(coef)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "\n",
    "def labelVisualize(num_class,color_dict,img):\n",
    "    img = img[:,:,0] if len(img.shape) == 3 else img\n",
    "    img_out = np.zeros(img.shape + (3,))\n",
    "    for i in range(num_class):\n",
    "        img_out[img == i,:] = color_dict[i]\n",
    "    return img_out / 255\n",
    "\n",
    "def saveResult(save_path,npyfile,flag_multi_class = False,num_class = 2):\n",
    "    for i,item in enumerate(npyfile):\n",
    "        img = labelVisualize(num_class,COLOR_DICT,item) if flag_multi_class else item[:,:,0]\n",
    "        io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
    "\n",
    "os.mkdir('05.U-Net2_results_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveResult('05.U-Net2_results_dir',prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeData(img,mask):\n",
    "    mean = np.mean(img)\n",
    "    std = np.std(img)\n",
    "    img -= mean\n",
    "    img /= std\n",
    "    mask = mask /255\n",
    "    mask[mask > 0.5] = 1\n",
    "    mask[mask <= 0.5] = 0\n",
    "    return (img,mask)\n",
    "\n",
    "test_data_dir= \"data_augmented/cvc300_test/images/\"\n",
    "test_data_mask_dir = \"data_augmented/cvc300_test/masks/\"\n",
    "test_data_pred_dir = \"05.U-Net2_results_dir\"\n",
    "img_rows, img_cols = 256, 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image as image_utils\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img\n",
    "\n",
    "file_names = next(os.walk(test_data_dir))[2]\n",
    "scores = []\n",
    "for file in file_names:\n",
    "    grey_img = load_img(os.path.join(test_data_dir,file), target_size=(img_rows, img_cols), grayscale=False)\n",
    "    mask_img = load_img(os.path.join(test_data_mask_dir,file), target_size=(img_rows, img_cols), grayscale=True)\n",
    "    img = img_to_array(grey_img)\n",
    "    img_mask = img_to_array(mask_img)\n",
    "    \n",
    "    img, img_mask = normalizeData(img, img_mask)\n",
    "    img = np.reshape(img,(1,)+img.shape)\n",
    "    \n",
    "    pred = model.predict([img])\n",
    "    sess = tf.Session()\n",
    "    score = sess.run(Jaccard_index(img_mask, pred))\n",
    "    print(\"{} -- jaccard index: {}\".format(file,score))\n",
    "    scores.append([file,score])\n",
    "\n",
    "    result_img = array_to_img(pred[0] * 255 )\n",
    "    result_img.save(os.path.join(test_data_pred_dir, file.split('.')[0] + '_predict.jpg'))\n",
    "\n",
    "with open(\"unet_test_result.csv\", 'w') as f:\n",
    "    f.write(\"filename, jaccard_index\\n\")\n",
    "    for i in range(len(scores)):\n",
    "        #print(scores[i])\n",
    "        f.write(\"{},{}\\n\".format(scores[i][0], scores[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img=mpimg.imread('05.U-Net2_results_dir/102_predict.png')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(prediction[1]), cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(prediction[1]), cmap = \"gray\", vmin = 0.0, vmax= 0.09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ =  np.squeeze(np.multiply(prediction[1], 255))\n",
    "print(results_)\n",
    "\n",
    "plt.imshow(results_, cmap = \"gray\", vmin = 0.0, vmax= 0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img=mpimg.imread('05.U-Net2_results_dir/35_predict.png')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['dice_coef'])\n",
    "plt.plot(history.history['val_dice_coef'])\n",
    "plt.title('model dice_coeff')\n",
    "plt.ylabel('dice_coef')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
