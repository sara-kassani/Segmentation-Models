{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 16192775716432439225, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 9214062756\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 2586003734976851017\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras import layers, metrics, models, optimizers\n",
    "from keras.optimizers import Adam, RMSprop,SGD\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, concatenate, Flatten, Dense, Activation, Dropout, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Version 2.2.4\n",
      "tensorflow Version 1.9.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Keras Version\", keras.__version__)\n",
    "print(\"tensorflow Version\", tf.__version__)\n",
    "# print(\"dim_ordering:\", K.image_dim_ordering())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "img_rows, img_cols = 256, 256\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "epochs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data_augmented/cvc300_train/'\n",
    "validation_dir = 'data_augmented/cvc300_validation/'\n",
    "test_dir = 'data_augmented/cvc300_test/'\n",
    "\n",
    "image_folder = 'images'\n",
    "masks_folder = 'masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Input\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "def Vgg16Unet(img_size):\n",
    "    inputs = Input(shape=(img_size, img_size, 3))\n",
    "    s = Lambda(lambda x: x / 255)(inputs)\n",
    "    vgg16 = VGG16(include_top=False, weights='imagenet',\n",
    "                  input_tensor=s)\n",
    "    for layer in vgg16.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    c1 = vgg16.get_layer(\"block1_conv2\").output\n",
    "    c2 = vgg16.get_layer(\"block2_conv2\").output\n",
    "    c3 = vgg16.get_layer(\"block3_conv3\").output\n",
    "    c4 = vgg16.get_layer(\"block4_conv3\").output\n",
    "    c5 = vgg16.get_layer(\"block5_conv3\").output\n",
    "\n",
    "    u6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(512, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "    c6 = Conv2D(512, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "    c7 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    c8 = Dropout(0.1)(c8)\n",
    "    c8 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    c9 = Dropout(0.1)(c9)\n",
    "    c9 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "    model = Model(inputs=[vgg16.input], outputs=[outputs])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26112 images belonging to 1 classes.\n",
      "Found 26112 images belonging to 1 classes.\n",
      "Found 8704 images belonging to 1 classes.\n",
      "Found 8704 images belonging to 1 classes.\n",
      "Found 28 images belonging to 1 classes.\n",
      "Found 28 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "seed = 1142\n",
    "data_gen_args = dict(rescale=1. / 255, featurewise_center=True, featurewise_std_normalization=True)\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "masks_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "image_generator = image_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    classes = [image_folder],\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "mask_generator = masks_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    classes = [masks_folder],\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "validation_image_generator = image_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    classes = [image_folder],\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "validation_mask_generator = masks_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    classes = [masks_folder],\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "test_image_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    classes = [image_folder],\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "test_mask_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    classes = [masks_folder],\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = zip(image_generator, mask_generator)\n",
    "validation_generator = zip(validation_image_generator, validation_mask_generator)\n",
    "test_generator = zip(test_image_generator, test_mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_train_samples: 26112\n",
      "nb_validation_samples: 8704\n",
      "nb_test_samples: 28\n",
      "\n",
      "predict_size_train: 1632\n",
      "predict_size_validation: 544\n",
      "predict_size_test: 2\n"
     ]
    }
   ],
   "source": [
    "nb_train_samples = len(image_generator.filenames)\n",
    "nb_validation_samples = len(validation_image_generator.filenames)\n",
    "nb_test_samples = len(test_image_generator.filenames)\n",
    "\n",
    "predict_size_train = int(math.ceil(nb_train_samples / batch_size))\n",
    "predict_size_validation = int(math.ceil(nb_validation_samples / batch_size))\n",
    "predict_size_test = int(math.ceil(nb_test_samples / batch_size))\n",
    "\n",
    "print(\"nb_train_samples:\", nb_train_samples)\n",
    "print(\"nb_validation_samples:\", nb_validation_samples)\n",
    "print(\"nb_test_samples:\", nb_test_samples)\n",
    "\n",
    "print(\"\\npredict_size_train:\", predict_size_train)\n",
    "print(\"predict_size_validation:\", predict_size_validation)\n",
    "print(\"predict_size_test:\", predict_size_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 1.\n",
    "from keras import backend as K\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def Specificity(y_true, y_pred):\n",
    "    true_negatives = K.abs(y_pred)- K.abs(y_true)\n",
    "    return ((true_negatives+smooth)/(y_pred+ smooth))\n",
    "\n",
    "def Sensitivity(y_true, y_pred):\n",
    "    y_true = K.flatten(y_true)\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    return ((y_pred+smooth)/ (y_true+smooth))\n",
    "\n",
    "def Jaccard_index(y_true,y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return ((intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + smooth))\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "    Only computes a batch-wise average of precision.\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "    Only computes a batch-wise average of recall.\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def f1score(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "        Only computes a batch-wise average of recall.\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "        Only computes a batch-wise average of precision.\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 256, 256, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 256, 256, 64) 1792        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 256, 256, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 128, 128, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 128, 128, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 128, 128, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 64, 64, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 64, 64, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 32, 32, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 32, 32, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 32, 32, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 32, 32, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 16, 16, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 16, 16, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 16, 16, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 16, 16, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 32, 32, 512)  1049088     block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 1024) 0           conv2d_transpose_1[0][0]         \n",
      "                                                                 block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 512)  4719104     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 512)  0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 512)  2359808     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 64, 64, 256)  524544      conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 512)  0           conv2d_transpose_2[0][0]         \n",
      "                                                                 block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 256)  1179904     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64, 64, 256)  0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 256)  590080      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 128, 128, 128 131200      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 128, 256 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 128 295040      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128, 128, 128 0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 128, 128, 128 147584      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 256, 256, 64) 32832       conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 256, 256, 128 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 256, 256, 64) 73792       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256, 256, 64) 0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 256, 256, 64) 36928       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 256, 256, 1)  65          conv2d_8[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 25,854,657\n",
      "Trainable params: 11,139,969\n",
      "Non-trainable params: 14,714,688\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Vgg16Unet(img_size = 256)\n",
    "model.summary()\n",
    "adam_opt = Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(optimizer= adam_opt, loss=dice_coef_loss, \n",
    "              metrics=[dice_coef, 'acc','mse', Jaccard_index, Specificity, Sensitivity, precision, recall, f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1632/1632 [==============================] - 681s 417ms/step - loss: -0.1483 - dice_coef: 0.1483 - acc: 0.5893 - mean_squared_error: 0.2808 - Jaccard_index: 0.0806 - Specificity: 0.9663 - Sensitivity: 1.2668 - precision: 0.0981 - recall: 0.5459 - f1score: 0.1618 - val_loss: -0.1857 - val_dice_coef: 0.1857 - val_acc: 0.5751 - val_mean_squared_error: 0.3065 - val_Jaccard_index: 0.1031 - val_Specificity: 0.9612 - val_Sensitivity: 1.2803 - val_precision: 0.1224 - val_recall: 0.6420 - val_f1score: 0.2044\n",
      "Epoch 2/150\n",
      "1632/1632 [==============================] - 663s 406ms/step - loss: -0.1604 - dice_coef: 0.1604 - acc: 0.6735 - mean_squared_error: 0.2035 - Jaccard_index: 0.0877 - Specificity: 0.9634 - Sensitivity: 1.1688 - precision: 0.1136 - recall: 0.4367 - f1score: 0.1762 - val_loss: -0.1934 - val_dice_coef: 0.1934 - val_acc: 0.6219 - val_mean_squared_error: 0.2556 - val_Jaccard_index: 0.1079 - val_Specificity: 0.9590 - val_Sensitivity: 1.2224 - val_precision: 0.1317 - val_recall: 0.5675 - val_f1score: 0.2123\n",
      "Epoch 3/150\n",
      "1632/1632 [==============================] - 643s 394ms/step - loss: -0.1627 - dice_coef: 0.1627 - acc: 0.6928 - mean_squared_error: 0.1827 - Jaccard_index: 0.0892 - Specificity: 0.9626 - Sensitivity: 1.1448 - precision: 0.1182 - recall: 0.3999 - f1score: 0.1787 - val_loss: -0.1969 - val_dice_coef: 0.1969 - val_acc: 0.6473 - val_mean_squared_error: 0.2278 - val_Jaccard_index: 0.1102 - val_Specificity: 0.9577 - val_Sensitivity: 1.1909 - val_precision: 0.1375 - val_recall: 0.5172 - val_f1score: 0.2158\n",
      "Epoch 4/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -0.1645 - dice_coef: 0.1645 - acc: 0.7084 - mean_squared_error: 0.1657 - Jaccard_index: 0.0903 - Specificity: 0.9619 - Sensitivity: 1.1257 - precision: 0.1217 - recall: 0.3714 - f1score: 0.1805 - val_loss: -0.1997 - val_dice_coef: 0.1997 - val_acc: 0.6933 - val_mean_squared_error: 0.1785 - val_Jaccard_index: 0.1122 - val_Specificity: 0.9549 - val_Sensitivity: 1.1331 - val_precision: 0.1492 - val_recall: 0.4179 - val_f1score: 0.2179\n",
      "Epoch 5/150\n",
      "1632/1632 [==============================] - 643s 394ms/step - loss: -0.1633 - dice_coef: 0.1633 - acc: 0.7000 - mean_squared_error: 0.1750 - Jaccard_index: 0.0896 - Specificity: 0.9622 - Sensitivity: 1.1358 - precision: 0.1204 - recall: 0.3849 - f1score: 0.1792 - val_loss: -0.1994 - val_dice_coef: 0.1994 - val_acc: 0.7067 - val_mean_squared_error: 0.1642 - val_Jaccard_index: 0.1120 - val_Specificity: 0.9539 - val_Sensitivity: 1.1161 - val_precision: 0.1530 - val_recall: 0.3845 - val_f1score: 0.2171\n",
      "Epoch 6/150\n",
      "1632/1632 [==============================] - 642s 394ms/step - loss: -0.1654 - dice_coef: 0.1654 - acc: 0.7181 - mean_squared_error: 0.1554 - Jaccard_index: 0.0908 - Specificity: 0.9614 - Sensitivity: 1.1138 - precision: 0.1241 - recall: 0.3520 - f1score: 0.1813 - val_loss: -0.1991 - val_dice_coef: 0.1991 - val_acc: 0.7052 - val_mean_squared_error: 0.1656 - val_Jaccard_index: 0.1119 - val_Specificity: 0.9540 - val_Sensitivity: 1.1178 - val_precision: 0.1525 - val_recall: 0.3873 - val_f1score: 0.2169\n",
      "Epoch 7/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -0.1659 - dice_coef: 0.1659 - acc: 0.7220 - mean_squared_error: 0.1510 - Jaccard_index: 0.0911 - Specificity: 0.9612 - Sensitivity: 1.1088 - precision: 0.1255 - recall: 0.3437 - f1score: 0.1817 - val_loss: -0.1953 - val_dice_coef: 0.1953 - val_acc: 0.7294 - val_mean_squared_error: 0.1400 - val_Jaccard_index: 0.1096 - val_Specificity: 0.9522 - val_Sensitivity: 1.0867 - val_precision: 0.1600 - val_recall: 0.3229 - val_f1score: 0.2118\n",
      "Epoch 8/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -0.1661 - dice_coef: 0.1661 - acc: 0.7243 - mean_squared_error: 0.1486 - Jaccard_index: 0.0912 - Specificity: 0.9611 - Sensitivity: 1.1061 - precision: 0.1263 - recall: 0.3391 - f1score: 0.1819 - val_loss: -0.1968 - val_dice_coef: 0.1968 - val_acc: 0.7242 - val_mean_squared_error: 0.1455 - val_Jaccard_index: 0.1106 - val_Specificity: 0.9526 - val_Sensitivity: 1.0934 - val_precision: 0.1584 - val_recall: 0.3372 - val_f1score: 0.2136\n",
      "Epoch 9/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -0.1660 - dice_coef: 0.1660 - acc: 0.7218 - mean_squared_error: 0.1515 - Jaccard_index: 0.0912 - Specificity: 0.9612 - Sensitivity: 1.1092 - precision: 0.1256 - recall: 0.3446 - f1score: 0.1819 - val_loss: -0.1947 - val_dice_coef: 0.1947 - val_acc: 0.7319 - val_mean_squared_error: 0.1373 - val_Jaccard_index: 0.1093 - val_Specificity: 0.9520 - val_Sensitivity: 1.0834 - val_precision: 0.1612 - val_recall: 0.3134 - val_f1score: 0.2108\n",
      "Epoch 10/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -0.1659 - dice_coef: 0.1659 - acc: 0.7221 - mean_squared_error: 0.1512 - Jaccard_index: 0.0912 - Specificity: 0.9612 - Sensitivity: 1.1090 - precision: 0.1257 - recall: 0.3435 - f1score: 0.1817 - val_loss: -0.1885 - val_dice_coef: 0.1885 - val_acc: 0.5922 - val_mean_squared_error: 0.2876 - val_Jaccard_index: 0.1049 - val_Specificity: 0.9604 - val_Sensitivity: 1.2590 - val_precision: 0.1256 - val_recall: 0.6151 - val_f1score: 0.2072\n",
      "Epoch 11/150\n",
      "1632/1632 [==============================] - 642s 394ms/step - loss: -0.1646 - dice_coef: 0.1646 - acc: 0.7085 - mean_squared_error: 0.1648 - Jaccard_index: 0.0903 - Specificity: 0.9619 - Sensitivity: 1.1255 - precision: 0.1217 - recall: 0.3700 - f1score: 0.1803 - val_loss: -0.1966 - val_dice_coef: 0.1966 - val_acc: 0.7255 - val_mean_squared_error: 0.1436 - val_Jaccard_index: 0.1104 - val_Specificity: 0.9525 - val_Sensitivity: 1.0916 - val_precision: 0.1588 - val_recall: 0.3344 - val_f1score: 0.2132\n",
      "Epoch 12/150\n",
      "1632/1632 [==============================] - 642s 394ms/step - loss: -0.1665 - dice_coef: 0.1665 - acc: 0.7262 - mean_squared_error: 0.1467 - Jaccard_index: 0.0916 - Specificity: 0.9610 - Sensitivity: 1.1039 - precision: 0.1267 - recall: 0.3356 - f1score: 0.1824 - val_loss: -0.1866 - val_dice_coef: 0.1866 - val_acc: 0.7523 - val_mean_squared_error: 0.1154 - val_Jaccard_index: 0.1043 - val_Specificity: 0.9503 - val_Sensitivity: 1.0569 - val_precision: 0.1688 - val_recall: 0.2537 - val_f1score: 0.2008\n",
      "Epoch 13/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -0.1663 - dice_coef: 0.1663 - acc: 0.7276 - mean_squared_error: 0.1452 - Jaccard_index: 0.0914 - Specificity: 0.9610 - Sensitivity: 1.1020 - precision: 0.1271 - recall: 0.3328 - f1score: 0.1822 - val_loss: -0.1989 - val_dice_coef: 0.1989 - val_acc: 0.7077 - val_mean_squared_error: 0.1631 - val_Jaccard_index: 0.1118 - val_Specificity: 0.9538 - val_Sensitivity: 1.1145 - val_precision: 0.1534 - val_recall: 0.3808 - val_f1score: 0.2167\n",
      "Epoch 14/150\n",
      "1632/1632 [==============================] - 638s 391ms/step - loss: -0.1660 - dice_coef: 0.1660 - acc: 0.7256 - mean_squared_error: 0.1474 - Jaccard_index: 0.0913 - Specificity: 0.9610 - Sensitivity: 1.1044 - precision: 0.1266 - recall: 0.3362 - f1score: 0.1819 - val_loss: -0.1922 - val_dice_coef: 0.1922 - val_acc: 0.6146 - val_mean_squared_error: 0.2639 - val_Jaccard_index: 0.1073 - val_Specificity: 0.9594 - val_Sensitivity: 1.2316 - val_precision: 0.1303 - val_recall: 0.5786 - val_f1score: 0.2113\n",
      "Epoch 15/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7183 - mean_squared_error: 0.1548 - Jaccard_index: 0.0910 - Specificity: 0.9614 - Sensitivity: 1.1135 - precision: 0.1241 - recall: 0.3511 - f1score: 0.1814 - val_loss: -0.1963 - val_dice_coef: 0.1963 - val_acc: 0.7250 - val_mean_squared_error: 0.1448 - val_Jaccard_index: 0.1103 - val_Specificity: 0.9526 - val_Sensitivity: 1.0925 - val_precision: 0.1587 - val_recall: 0.3345 - val_f1score: 0.2130\n",
      "Epoch 16/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -0.1665 - dice_coef: 0.1665 - acc: 0.7275 - mean_squared_error: 0.1452 - Jaccard_index: 0.0916 - Specificity: 0.9610 - Sensitivity: 1.1022 - precision: 0.1272 - recall: 0.3328 - f1score: 0.1824 - val_loss: -0.1994 - val_dice_coef: 0.1994 - val_acc: 0.7058 - val_mean_squared_error: 0.1654 - val_Jaccard_index: 0.1121 - val_Specificity: 0.9540 - val_Sensitivity: 1.1171 - val_precision: 0.1529 - val_recall: 0.3866 - val_f1score: 0.2172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -0.1664 - dice_coef: 0.1664 - acc: 0.7265 - mean_squared_error: 0.1465 - Jaccard_index: 0.0915 - Specificity: 0.9610 - Sensitivity: 1.1035 - precision: 0.1268 - recall: 0.3351 - f1score: 0.1823 - val_loss: -0.1992 - val_dice_coef: 0.1992 - val_acc: 0.7075 - val_mean_squared_error: 0.1634 - val_Jaccard_index: 0.1120 - val_Specificity: 0.9539 - val_Sensitivity: 1.1148 - val_precision: 0.1534 - val_recall: 0.3816 - val_f1score: 0.2168\n",
      "Epoch 18/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -0.1663 - dice_coef: 0.1663 - acc: 0.7267 - mean_squared_error: 0.1462 - Jaccard_index: 0.0914 - Specificity: 0.9610 - Sensitivity: 1.1032 - precision: 0.1268 - recall: 0.3340 - f1score: 0.1822 - val_loss: -0.1984 - val_dice_coef: 0.1984 - val_acc: 0.7122 - val_mean_squared_error: 0.1585 - val_Jaccard_index: 0.1116 - val_Specificity: 0.9535 - val_Sensitivity: 1.1088 - val_precision: 0.1547 - val_recall: 0.3688 - val_f1score: 0.2159\n",
      "Epoch 19/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -0.1664 - dice_coef: 0.1664 - acc: 0.7244 - mean_squared_error: 0.1486 - Jaccard_index: 0.0914 - Specificity: 0.9611 - Sensitivity: 1.1060 - precision: 0.1265 - recall: 0.3390 - f1score: 0.1822 - val_loss: -0.1965 - val_dice_coef: 0.1965 - val_acc: 0.7232 - val_mean_squared_error: 0.1467 - val_Jaccard_index: 0.1104 - val_Specificity: 0.9527 - val_Sensitivity: 1.0947 - val_precision: 0.1581 - val_recall: 0.3384 - val_f1score: 0.2134\n",
      "Epoch 20/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -0.1665 - dice_coef: 0.1665 - acc: 0.7281 - mean_squared_error: 0.1446 - Jaccard_index: 0.0916 - Specificity: 0.9609 - Sensitivity: 1.1014 - precision: 0.1274 - recall: 0.3314 - f1score: 0.1824 - val_loss: -0.1993 - val_dice_coef: 0.1993 - val_acc: 0.7074 - val_mean_squared_error: 0.1637 - val_Jaccard_index: 0.1122 - val_Specificity: 0.9539 - val_Sensitivity: 1.1150 - val_precision: 0.1535 - val_recall: 0.3824 - val_f1score: 0.2171\n",
      "Epoch 21/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -0.1529 - dice_coef: 0.1529 - acc: 0.7359 - mean_squared_error: 0.1365 - Jaccard_index: 0.0841 - Specificity: 0.9603 - Sensitivity: 1.0914 - precision: 0.1171 - recall: 0.3048 - f1score: nan - val_loss: -1.7734e-05 - val_dice_coef: 1.7734e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7734e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 22/150\n",
      "1632/1632 [==============================] - 640s 392ms/step - loss: -2.1128e-05 - dice_coef: 2.1128e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1128e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7671e-05 - val_dice_coef: 1.7671e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7671e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 23/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -2.1163e-05 - dice_coef: 2.1163e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1163e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7549e-05 - val_dice_coef: 1.7549e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7549e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 24/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -2.1167e-05 - dice_coef: 2.1167e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1167e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7696e-05 - val_dice_coef: 1.7696e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7696e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 25/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -2.1136e-05 - dice_coef: 2.1136e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1136e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7648e-05 - val_dice_coef: 1.7648e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7648e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 26/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -2.1175e-05 - dice_coef: 2.1175e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1175e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7598e-05 - val_dice_coef: 1.7598e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7598e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 27/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -2.1155e-05 - dice_coef: 2.1155e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1155e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7609e-05 - val_dice_coef: 1.7609e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7609e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 28/150\n",
      "1632/1632 [==============================] - 640s 392ms/step - loss: -2.1217e-05 - dice_coef: 2.1217e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1217e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7561e-05 - val_dice_coef: 1.7561e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7561e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 29/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -2.1164e-05 - dice_coef: 2.1164e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1164e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7549e-05 - val_dice_coef: 1.7549e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7549e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 30/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -2.1152e-05 - dice_coef: 2.1152e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1152e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7701e-05 - val_dice_coef: 1.7701e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7701e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 31/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -2.1209e-05 - dice_coef: 2.1209e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1209e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7600e-05 - val_dice_coef: 1.7600e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7600e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 32/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1632/1632 [==============================] - 641s 393ms/step - loss: -2.1187e-05 - dice_coef: 2.1187e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1187e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7611e-05 - val_dice_coef: 1.7611e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7611e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 33/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -2.1109e-05 - dice_coef: 2.1109e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1109e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7580e-05 - val_dice_coef: 1.7580e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7580e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 34/150\n",
      "1632/1632 [==============================] - 646s 396ms/step - loss: -2.1183e-05 - dice_coef: 2.1183e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1183e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7707e-05 - val_dice_coef: 1.7707e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7707e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 35/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -2.1159e-05 - dice_coef: 2.1159e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1159e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7601e-05 - val_dice_coef: 1.7601e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7601e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 36/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -2.1107e-05 - dice_coef: 2.1107e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1107e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7637e-05 - val_dice_coef: 1.7637e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7637e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 37/150\n",
      "1632/1632 [==============================] - 640s 392ms/step - loss: -2.1143e-05 - dice_coef: 2.1143e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1143e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7634e-05 - val_dice_coef: 1.7634e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7634e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 38/150\n",
      "1632/1632 [==============================] - 643s 394ms/step - loss: -2.1176e-05 - dice_coef: 2.1176e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1176e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7581e-05 - val_dice_coef: 1.7581e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7581e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 39/150\n",
      "1632/1632 [==============================] - 639s 391ms/step - loss: -2.1180e-05 - dice_coef: 2.1180e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1180e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7549e-05 - val_dice_coef: 1.7549e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7549e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 40/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -2.1120e-05 - dice_coef: 2.1120e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1120e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7556e-05 - val_dice_coef: 1.7556e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7556e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 41/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -2.1149e-05 - dice_coef: 2.1149e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1149e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7535e-05 - val_dice_coef: 1.7535e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7535e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 42/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -2.1172e-05 - dice_coef: 2.1172e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1172e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7596e-05 - val_dice_coef: 1.7596e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7596e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 43/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -2.1186e-05 - dice_coef: 2.1186e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1186e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7653e-05 - val_dice_coef: 1.7653e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7653e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 44/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -2.1175e-05 - dice_coef: 2.1175e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1175e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7625e-05 - val_dice_coef: 1.7625e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7625e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 45/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -2.1143e-05 - dice_coef: 2.1143e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1143e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7553e-05 - val_dice_coef: 1.7553e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7553e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 46/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -2.1157e-05 - dice_coef: 2.1157e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1157e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7659e-05 - val_dice_coef: 1.7659e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7659e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -2.1144e-05 - dice_coef: 2.1144e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1144e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7602e-05 - val_dice_coef: 1.7602e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7602e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 48/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -2.1164e-05 - dice_coef: 2.1164e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1164e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7571e-05 - val_dice_coef: 1.7571e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7571e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 49/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -2.1193e-05 - dice_coef: 2.1193e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1193e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7755e-05 - val_dice_coef: 1.7755e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7755e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 50/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -2.1189e-05 - dice_coef: 2.1189e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1189e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7593e-05 - val_dice_coef: 1.7593e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7593e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 51/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -2.1139e-05 - dice_coef: 2.1139e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1139e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7630e-05 - val_dice_coef: 1.7630e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7630e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 52/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -2.1179e-05 - dice_coef: 2.1179e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1179e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7624e-05 - val_dice_coef: 1.7624e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7624e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 53/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -2.1174e-05 - dice_coef: 2.1174e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1174e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7618e-05 - val_dice_coef: 1.7618e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7618e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 54/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -2.1178e-05 - dice_coef: 2.1178e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1178e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7622e-05 - val_dice_coef: 1.7622e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7622e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 55/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -2.1145e-05 - dice_coef: 2.1145e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1145e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7631e-05 - val_dice_coef: 1.7631e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7631e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 56/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -2.1197e-05 - dice_coef: 2.1197e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1197e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7587e-05 - val_dice_coef: 1.7587e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7587e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 57/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -2.1137e-05 - dice_coef: 2.1137e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1137e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7614e-05 - val_dice_coef: 1.7614e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7614e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 58/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -2.1134e-05 - dice_coef: 2.1134e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1134e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7580e-05 - val_dice_coef: 1.7580e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7580e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 59/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -2.1191e-05 - dice_coef: 2.1191e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1191e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7630e-05 - val_dice_coef: 1.7630e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7630e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 60/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -2.1141e-05 - dice_coef: 2.1141e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1141e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7753e-05 - val_dice_coef: 1.7753e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7753e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 61/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -2.1164e-05 - dice_coef: 2.1164e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1164e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7587e-05 - val_dice_coef: 1.7587e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7587e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -2.1140e-05 - dice_coef: 2.1140e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1140e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7592e-05 - val_dice_coef: 1.7592e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7592e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 63/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -2.1138e-05 - dice_coef: 2.1138e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1138e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7602e-05 - val_dice_coef: 1.7602e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7602e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 64/150\n",
      "1632/1632 [==============================] - 640s 392ms/step - loss: -2.1140e-05 - dice_coef: 2.1140e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1140e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7497e-05 - val_dice_coef: 1.7497e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7497e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 65/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -2.1169e-05 - dice_coef: 2.1169e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1169e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7674e-05 - val_dice_coef: 1.7674e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7674e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 66/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -2.1124e-05 - dice_coef: 2.1124e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1124e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7602e-05 - val_dice_coef: 1.7602e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7602e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 67/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -2.1118e-05 - dice_coef: 2.1118e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1118e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7595e-05 - val_dice_coef: 1.7595e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7595e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 68/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -2.1130e-05 - dice_coef: 2.1130e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1130e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7572e-05 - val_dice_coef: 1.7572e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7572e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 69/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -2.1141e-05 - dice_coef: 2.1141e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1141e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7659e-05 - val_dice_coef: 1.7659e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7659e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 70/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -2.1149e-05 - dice_coef: 2.1149e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1149e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7630e-05 - val_dice_coef: 1.7630e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7630e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 71/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -2.1160e-05 - dice_coef: 2.1160e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1160e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7619e-05 - val_dice_coef: 1.7619e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7619e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 72/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -2.1199e-05 - dice_coef: 2.1199e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1199e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7533e-05 - val_dice_coef: 1.7533e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7533e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 73/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -2.1151e-05 - dice_coef: 2.1151e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1151e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7610e-05 - val_dice_coef: 1.7610e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7610e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 74/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -2.1133e-05 - dice_coef: 2.1133e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1133e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7606e-05 - val_dice_coef: 1.7606e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7606e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 75/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -2.1163e-05 - dice_coef: 2.1163e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1163e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7575e-05 - val_dice_coef: 1.7575e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7575e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 76/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -2.1136e-05 - dice_coef: 2.1136e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1136e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7612e-05 - val_dice_coef: 1.7612e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7612e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -2.1175e-05 - dice_coef: 2.1175e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1175e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7626e-05 - val_dice_coef: 1.7626e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7626e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 78/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -2.1183e-05 - dice_coef: 2.1183e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1183e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7612e-05 - val_dice_coef: 1.7612e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7612e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 79/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -2.1141e-05 - dice_coef: 2.1141e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1141e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7538e-05 - val_dice_coef: 1.7538e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7538e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 80/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -2.1193e-05 - dice_coef: 2.1193e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1193e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7645e-05 - val_dice_coef: 1.7645e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7645e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 81/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -2.1167e-05 - dice_coef: 2.1167e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1167e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7616e-05 - val_dice_coef: 1.7616e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7616e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 82/150\n",
      "1632/1632 [==============================] - 650s 398ms/step - loss: -2.1161e-05 - dice_coef: 2.1161e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1161e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7586e-05 - val_dice_coef: 1.7586e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7586e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 83/150\n",
      "1632/1632 [==============================] - 646s 396ms/step - loss: -2.1158e-05 - dice_coef: 2.1158e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1158e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7585e-05 - val_dice_coef: 1.7585e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7585e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 84/150\n",
      "1632/1632 [==============================] - 647s 396ms/step - loss: -2.1182e-05 - dice_coef: 2.1182e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1182e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7684e-05 - val_dice_coef: 1.7684e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7684e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 85/150\n",
      "1632/1632 [==============================] - 645s 395ms/step - loss: -2.1160e-05 - dice_coef: 2.1160e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1160e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7521e-05 - val_dice_coef: 1.7521e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7521e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 86/150\n",
      "1632/1632 [==============================] - 644s 395ms/step - loss: -2.1167e-05 - dice_coef: 2.1167e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1167e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7634e-05 - val_dice_coef: 1.7634e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7634e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 87/150\n",
      "1632/1632 [==============================] - 644s 395ms/step - loss: -2.1115e-05 - dice_coef: 2.1115e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1115e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7701e-05 - val_dice_coef: 1.7701e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7701e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 88/150\n",
      "1632/1632 [==============================] - 645s 395ms/step - loss: -2.1148e-05 - dice_coef: 2.1148e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1148e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7649e-05 - val_dice_coef: 1.7649e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7649e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 89/150\n",
      "1632/1632 [==============================] - 643s 394ms/step - loss: -2.1119e-05 - dice_coef: 2.1119e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1119e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7576e-05 - val_dice_coef: 1.7576e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7576e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 90/150\n",
      "1632/1632 [==============================] - 657s 403ms/step - loss: -2.1176e-05 - dice_coef: 2.1176e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1176e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7630e-05 - val_dice_coef: 1.7630e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7630e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 91/150\n",
      "1632/1632 [==============================] - 642s 394ms/step - loss: -2.1179e-05 - dice_coef: 2.1179e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1179e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7596e-05 - val_dice_coef: 1.7596e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7596e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/150\n",
      "1632/1632 [==============================] - 645s 395ms/step - loss: -2.1185e-05 - dice_coef: 2.1185e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1185e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7547e-05 - val_dice_coef: 1.7547e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7547e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 93/150\n",
      "1632/1632 [==============================] - 644s 394ms/step - loss: -2.1176e-05 - dice_coef: 2.1176e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1176e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7496e-05 - val_dice_coef: 1.7496e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7496e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 94/150\n",
      "1632/1632 [==============================] - 644s 394ms/step - loss: -2.1161e-05 - dice_coef: 2.1161e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1161e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7647e-05 - val_dice_coef: 1.7647e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7647e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 95/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -2.1173e-05 - dice_coef: 2.1173e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1173e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7664e-05 - val_dice_coef: 1.7664e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7664e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 96/150\n",
      "1632/1632 [==============================] - 643s 394ms/step - loss: -2.1150e-05 - dice_coef: 2.1150e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1150e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7519e-05 - val_dice_coef: 1.7519e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7519e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 97/150\n",
      "1632/1632 [==============================] - 644s 394ms/step - loss: -2.1110e-05 - dice_coef: 2.1110e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1110e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7587e-05 - val_dice_coef: 1.7587e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7587e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 98/150\n",
      "1632/1632 [==============================] - 644s 395ms/step - loss: -2.1204e-05 - dice_coef: 2.1204e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1204e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7613e-05 - val_dice_coef: 1.7613e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7613e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 99/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -2.1157e-05 - dice_coef: 2.1157e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1157e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7632e-05 - val_dice_coef: 1.7632e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7632e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 100/150\n",
      "1632/1632 [==============================] - 643s 394ms/step - loss: -2.1187e-05 - dice_coef: 2.1187e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1187e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7553e-05 - val_dice_coef: 1.7553e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7553e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 101/150\n",
      "1632/1632 [==============================] - 644s 395ms/step - loss: -2.1168e-05 - dice_coef: 2.1168e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1168e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7586e-05 - val_dice_coef: 1.7586e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7586e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 102/150\n",
      "1632/1632 [==============================] - 644s 394ms/step - loss: -2.1140e-05 - dice_coef: 2.1140e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1140e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7668e-05 - val_dice_coef: 1.7668e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7668e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 103/150\n",
      "1632/1632 [==============================] - 643s 394ms/step - loss: -2.1144e-05 - dice_coef: 2.1144e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1144e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7691e-05 - val_dice_coef: 1.7691e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7691e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 104/150\n",
      "1632/1632 [==============================] - 642s 393ms/step - loss: -2.1185e-05 - dice_coef: 2.1185e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1185e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7609e-05 - val_dice_coef: 1.7609e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7609e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 105/150\n",
      "1632/1632 [==============================] - 643s 394ms/step - loss: -2.1137e-05 - dice_coef: 2.1137e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1137e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7520e-05 - val_dice_coef: 1.7520e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7520e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 106/150\n",
      "1632/1632 [==============================] - 644s 395ms/step - loss: -2.1114e-05 - dice_coef: 2.1114e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1114e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7544e-05 - val_dice_coef: 1.7544e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7544e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/150\n",
      "1632/1632 [==============================] - 642s 394ms/step - loss: -2.1138e-05 - dice_coef: 2.1138e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1138e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7597e-05 - val_dice_coef: 1.7597e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7597e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 108/150\n",
      "1632/1632 [==============================] - 644s 395ms/step - loss: -2.1163e-05 - dice_coef: 2.1163e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1163e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7639e-05 - val_dice_coef: 1.7639e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7639e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 109/150\n",
      "1632/1632 [==============================] - 644s 395ms/step - loss: -2.1148e-05 - dice_coef: 2.1148e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1148e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7702e-05 - val_dice_coef: 1.7702e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7702e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 110/150\n",
      "1632/1632 [==============================] - 643s 394ms/step - loss: -2.1217e-05 - dice_coef: 2.1217e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1217e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7639e-05 - val_dice_coef: 1.7639e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7639e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 111/150\n",
      "1632/1632 [==============================] - 643s 394ms/step - loss: -2.1148e-05 - dice_coef: 2.1148e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1148e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7610e-05 - val_dice_coef: 1.7610e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7610e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 112/150\n",
      "1632/1632 [==============================] - 643s 394ms/step - loss: -2.1149e-05 - dice_coef: 2.1149e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1149e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7597e-05 - val_dice_coef: 1.7597e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7597e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 113/150\n",
      "1632/1632 [==============================] - 644s 395ms/step - loss: -2.1182e-05 - dice_coef: 2.1182e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1182e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7637e-05 - val_dice_coef: 1.7637e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7637e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 114/150\n",
      "1632/1632 [==============================] - 643s 394ms/step - loss: -2.1135e-05 - dice_coef: 2.1135e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1135e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7492e-05 - val_dice_coef: 1.7492e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7492e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 115/150\n",
      "1632/1632 [==============================] - 641s 393ms/step - loss: -2.1146e-05 - dice_coef: 2.1146e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1146e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7535e-05 - val_dice_coef: 1.7535e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7535e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 116/150\n",
      "1632/1632 [==============================] - 644s 394ms/step - loss: -2.1179e-05 - dice_coef: 2.1179e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1179e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7700e-05 - val_dice_coef: 1.7700e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7700e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 117/150\n",
      "1632/1632 [==============================] - 644s 395ms/step - loss: -2.1153e-05 - dice_coef: 2.1153e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1153e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7536e-05 - val_dice_coef: 1.7536e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7536e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 118/150\n",
      "1632/1632 [==============================] - 644s 394ms/step - loss: -2.1138e-05 - dice_coef: 2.1138e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1138e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7629e-05 - val_dice_coef: 1.7629e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7629e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 119/150\n",
      "1632/1632 [==============================] - 645s 395ms/step - loss: -2.1165e-05 - dice_coef: 2.1165e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1165e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7601e-05 - val_dice_coef: 1.7601e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7601e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 120/150\n",
      "1632/1632 [==============================] - 644s 394ms/step - loss: -2.1166e-05 - dice_coef: 2.1166e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1166e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7608e-05 - val_dice_coef: 1.7608e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7608e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 121/150\n",
      "1632/1632 [==============================] - 646s 396ms/step - loss: -2.1167e-05 - dice_coef: 2.1167e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1167e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7565e-05 - val_dice_coef: 1.7565e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7565e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/150\n",
      "1632/1632 [==============================] - 644s 394ms/step - loss: -2.1115e-05 - dice_coef: 2.1115e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1115e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7599e-05 - val_dice_coef: 1.7599e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7599e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 123/150\n",
      "1632/1632 [==============================] - 643s 394ms/step - loss: -2.1115e-05 - dice_coef: 2.1115e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1115e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7596e-05 - val_dice_coef: 1.7596e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7596e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 124/150\n",
      "1632/1632 [==============================] - 645s 395ms/step - loss: -2.1152e-05 - dice_coef: 2.1152e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1152e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7594e-05 - val_dice_coef: 1.7594e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7594e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 125/150\n",
      "1632/1632 [==============================] - 646s 396ms/step - loss: -2.1119e-05 - dice_coef: 2.1119e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1119e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7550e-05 - val_dice_coef: 1.7550e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7550e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 126/150\n",
      "1632/1632 [==============================] - 644s 394ms/step - loss: -2.1159e-05 - dice_coef: 2.1159e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1159e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7599e-05 - val_dice_coef: 1.7599e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7599e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 127/150\n",
      "1632/1632 [==============================] - 644s 395ms/step - loss: -2.1160e-05 - dice_coef: 2.1160e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1160e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7602e-05 - val_dice_coef: 1.7602e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7602e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 128/150\n",
      "1632/1632 [==============================] - 643s 394ms/step - loss: -2.1113e-05 - dice_coef: 2.1113e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1113e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7604e-05 - val_dice_coef: 1.7604e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7604e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 129/150\n",
      "1632/1632 [==============================] - 643s 394ms/step - loss: -2.1095e-05 - dice_coef: 2.1095e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1095e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7624e-05 - val_dice_coef: 1.7624e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7624e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 130/150\n",
      "1632/1632 [==============================] - 643s 394ms/step - loss: -2.1156e-05 - dice_coef: 2.1156e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1156e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7768e-05 - val_dice_coef: 1.7768e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7768e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 131/150\n",
      "1632/1632 [==============================] - 644s 395ms/step - loss: -2.1124e-05 - dice_coef: 2.1124e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1124e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7658e-05 - val_dice_coef: 1.7658e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7658e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 132/150\n",
      "1632/1632 [==============================] - 643s 394ms/step - loss: -2.1207e-05 - dice_coef: 2.1207e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1207e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7602e-05 - val_dice_coef: 1.7602e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7602e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 133/150\n",
      "1632/1632 [==============================] - 643s 394ms/step - loss: -2.1177e-05 - dice_coef: 2.1177e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1177e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7632e-05 - val_dice_coef: 1.7632e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7632e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 134/150\n",
      "1632/1632 [==============================] - 643s 394ms/step - loss: -2.1161e-05 - dice_coef: 2.1161e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1161e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7665e-05 - val_dice_coef: 1.7665e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7665e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 135/150\n",
      "1632/1632 [==============================] - 652s 400ms/step - loss: -2.1193e-05 - dice_coef: 2.1193e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1193e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7595e-05 - val_dice_coef: 1.7595e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7595e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 136/150\n",
      "1632/1632 [==============================] - 643s 394ms/step - loss: -2.1210e-05 - dice_coef: 2.1210e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1210e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7702e-05 - val_dice_coef: 1.7702e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7702e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/150\n",
      "1632/1632 [==============================] - 645s 395ms/step - loss: -2.1175e-05 - dice_coef: 2.1175e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1175e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7535e-05 - val_dice_coef: 1.7535e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7535e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 138/150\n",
      "1632/1632 [==============================] - 644s 394ms/step - loss: -2.1162e-05 - dice_coef: 2.1162e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1162e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7698e-05 - val_dice_coef: 1.7698e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7698e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 139/150\n",
      "1632/1632 [==============================] - 643s 394ms/step - loss: -2.1135e-05 - dice_coef: 2.1135e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1135e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7528e-05 - val_dice_coef: 1.7528e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7528e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 140/150\n",
      "1632/1632 [==============================] - 645s 395ms/step - loss: -2.1175e-05 - dice_coef: 2.1175e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1175e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7586e-05 - val_dice_coef: 1.7586e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7586e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 141/150\n",
      "1632/1632 [==============================] - 643s 394ms/step - loss: -2.1136e-05 - dice_coef: 2.1136e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1136e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7596e-05 - val_dice_coef: 1.7596e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7596e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 142/150\n",
      "1632/1632 [==============================] - 643s 394ms/step - loss: -2.1198e-05 - dice_coef: 2.1198e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1198e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7656e-05 - val_dice_coef: 1.7656e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7656e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 143/150\n",
      "1632/1632 [==============================] - 643s 394ms/step - loss: -2.1162e-05 - dice_coef: 2.1162e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1162e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7593e-05 - val_dice_coef: 1.7593e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7593e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 144/150\n",
      "1632/1632 [==============================] - 641s 392ms/step - loss: -2.1154e-05 - dice_coef: 2.1154e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1154e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7598e-05 - val_dice_coef: 1.7598e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7598e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 145/150\n",
      "1632/1632 [==============================] - 637s 390ms/step - loss: -2.1165e-05 - dice_coef: 2.1165e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1165e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7601e-05 - val_dice_coef: 1.7601e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7601e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 146/150\n",
      "1632/1632 [==============================] - 640s 392ms/step - loss: -2.1199e-05 - dice_coef: 2.1199e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1199e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7582e-05 - val_dice_coef: 1.7582e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7582e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 147/150\n",
      "1632/1632 [==============================] - 640s 392ms/step - loss: -2.1197e-05 - dice_coef: 2.1197e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1197e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7576e-05 - val_dice_coef: 1.7576e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7576e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 148/150\n",
      "1632/1632 [==============================] - 639s 392ms/step - loss: -2.1184e-05 - dice_coef: 2.1184e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1184e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7624e-05 - val_dice_coef: 1.7624e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7624e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 149/150\n",
      "1632/1632 [==============================] - 639s 392ms/step - loss: -2.1166e-05 - dice_coef: 2.1166e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1166e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7637e-05 - val_dice_coef: 1.7637e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7637e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 150/150\n",
      "1632/1632 [==============================] - 639s 391ms/step - loss: -2.1160e-05 - dice_coef: 2.1160e-05 - acc: 0.8261 - mean_squared_error: 0.0408 - Jaccard_index: 2.1160e-05 - Specificity: 0.9533 - Sensitivity: 0.9748 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: nan - val_loss: -1.7634e-05 - val_dice_coef: 1.7634e-05 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 1.7634e-05 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=nb_train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = validation_generator,\n",
    "                    validation_steps = nb_validation_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Score:  -1.7206792072101963e-05\n",
      "Validation Accuracy:  1.7206792072101963e-05\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate_generator(validation_generator, steps=50)\n",
    "\n",
    "print ('Validation Score: ', score[0])\n",
    "print ('Validation Accuracy: ',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 163ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict_generator(test_generator, verbose=1, steps=nb_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392, 256, 256, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'dice_coef', 'acc', 'mean_squared_error', 'Jaccard_index', 'Specificity', 'Sensitivity', 'precision', 'recall', 'f1score']\n",
      "[-2.251913081896159e-05, 2.2519130881326938e-05, 0.9502643043654305, 0.04973569589001792, 2.2519130881326938e-05, 0.9502643043654305, 0.9751321516718183, 0.0, 0.0, nan]\n"
     ]
    }
   ],
   "source": [
    "test_results = model.evaluate_generator(test_generator, steps=50)\n",
    "\n",
    "print(model.metrics_names)\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training co-effiency    : 0.09158190552318725;\n",
      "Validation co-effiency : 0.11208780340316213\n"
     ]
    }
   ],
   "source": [
    "coef = np.array(history.history['Jaccard_index'])\n",
    "val_coef = np.array(history.history['val_Jaccard_index'])\n",
    "print(\"Training co-effiency    : {};\\nValidation co-effiency : {}\".format(coef[coef==max(coef)][0], val_coef[np.argmax(coef)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: '05.U-Net2_results_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-f52167f98bda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"%d_predict.png\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'05.U-Net2_results_dir'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: '05.U-Net2_results_dir'"
     ]
    }
   ],
   "source": [
    "import skimage.io as io\n",
    "\n",
    "def labelVisualize(num_class,color_dict,img):\n",
    "    img = img[:,:,0] if len(img.shape) == 3 else img\n",
    "    img_out = np.zeros(img.shape + (3,))\n",
    "    for i in range(num_class):\n",
    "        img_out[img == i,:] = color_dict[i]\n",
    "    return img_out / 255\n",
    "\n",
    "def saveResult(save_path,npyfile,flag_multi_class = False,num_class = 2):\n",
    "    for i,item in enumerate(npyfile):\n",
    "        img = labelVisualize(num_class,COLOR_DICT,item) if flag_multi_class else item[:,:,0]\n",
    "        io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
    "\n",
    "os.mkdir('05.U-Net2_results_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveResult('05.U-Net2_results_dir',prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeData(img,mask):\n",
    "    mean = np.mean(img)\n",
    "    std = np.std(img)\n",
    "    img -= mean\n",
    "    img /= std\n",
    "    mask = mask /255\n",
    "    mask[mask > 0.5] = 1\n",
    "    mask[mask <= 0.5] = 0\n",
    "    return (img,mask)\n",
    "\n",
    "test_data_dir= \"data_augmented/cvc300_test/images/\"\n",
    "test_data_mask_dir = \"data_augmented/cvc300_test/masks/\"\n",
    "test_data_pred_dir = \"05.U-Net2_results_dir\"\n",
    "img_rows, img_cols = 256, 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image as image_utils\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img\n",
    "\n",
    "file_names = next(os.walk(test_data_dir))[2]\n",
    "scores = []\n",
    "for file in file_names:\n",
    "    grey_img = load_img(os.path.join(test_data_dir,file), target_size=(img_rows, img_cols), grayscale=False)\n",
    "    mask_img = load_img(os.path.join(test_data_mask_dir,file), target_size=(img_rows, img_cols), grayscale=True)\n",
    "    img = img_to_array(grey_img)\n",
    "    img_mask = img_to_array(mask_img)\n",
    "    \n",
    "    img, img_mask = normalizeData(img, img_mask)\n",
    "    img = np.reshape(img,(1,)+img.shape)\n",
    "    \n",
    "    pred = model.predict([img])\n",
    "    sess = tf.Session()\n",
    "    score = sess.run(Jaccard_index(img_mask, pred))\n",
    "    print(\"{} -- jaccard index: {}\".format(file,score))\n",
    "    scores.append([file,score])\n",
    "\n",
    "    result_img = array_to_img(pred[0] * 255 )\n",
    "    result_img.save(os.path.join(test_data_pred_dir, file.split('.')[0] + '_predict.jpg'))\n",
    "\n",
    "with open(\"unet_test_result.csv\", 'w') as f:\n",
    "    f.write(\"filename, jaccard_index\\n\")\n",
    "    for i in range(len(scores)):\n",
    "        #print(scores[i])\n",
    "        f.write(\"{},{}\\n\".format(scores[i][0], scores[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img=mpimg.imread('05.U-Net2_results_dir/102_predict.png')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(prediction[1]), cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(prediction[1]), cmap = \"gray\", vmin = 0.0, vmax= 0.09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ =  np.squeeze(np.multiply(prediction[1], 255))\n",
    "print(results_)\n",
    "\n",
    "plt.imshow(results_, cmap = \"gray\", vmin = 0.0, vmax= 0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img=mpimg.imread('05.U-Net2_results_dir/35_predict.png')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['dice_coef'])\n",
    "plt.plot(history.history['val_dice_coef'])\n",
    "plt.title('model dice_coeff')\n",
    "plt.ylabel('dice_coef')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
