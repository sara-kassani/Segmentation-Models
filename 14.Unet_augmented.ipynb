{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 18146969831970218149, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 9214062756\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 11631932619882281736\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras import layers, metrics, models, optimizers\n",
    "from keras.optimizers import Adam, RMSprop,SGD\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, concatenate, Flatten, Dense, Activation, Dropout, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Version 2.2.4\n",
      "tensorflow Version 1.9.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Keras Version\", keras.__version__)\n",
    "print(\"tensorflow Version\", tf.__version__)\n",
    "# print(\"dim_ordering:\", K.image_dim_ordering())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "img_rows, img_cols = 256, 256\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data_augmented/cvc300_train/'\n",
    "validation_dir = 'data_augmented/cvc300_validation/'\n",
    "test_dir = 'data_augmented/cvc300_test/'\n",
    "\n",
    "image_folder = 'images'\n",
    "masks_folder = 'masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.noise import AlphaDropout\n",
    "\n",
    "\n",
    "def Unet(img_size):\n",
    "    inputs = Input((img_size, img_size, 3))\n",
    "    s = Lambda(lambda x: x / 255)(inputs)\n",
    "\n",
    "    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(s)\n",
    "    c1 = AlphaDropout(0.1)(c1)\n",
    "    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "    c2 = AlphaDropout(0.1)(c2)\n",
    "    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "    c3 = AlphaDropout(0.2)(c3)\n",
    "    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "    c4 = AlphaDropout(0.2)(c4)\n",
    "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "\n",
    "    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "    c5 = AlphaDropout(0.3)(c5)\n",
    "    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "\n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    c6 = AlphaDropout(0.2)(c6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    c7 = AlphaDropout(0.2)(c7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    c8 = AlphaDropout(0.1)(c8)\n",
    "    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    c9 = AlphaDropout(0.1)(c9)\n",
    "    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26112 images belonging to 1 classes.\n",
      "Found 26112 images belonging to 1 classes.\n",
      "Found 8704 images belonging to 1 classes.\n",
      "Found 8704 images belonging to 1 classes.\n",
      "Found 28 images belonging to 1 classes.\n",
      "Found 28 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "seed = 1142\n",
    "data_gen_args = dict(rescale=1. / 255, featurewise_center=True, featurewise_std_normalization=True)\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "masks_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "image_generator = image_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    classes = [image_folder],\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "mask_generator = masks_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    classes = [masks_folder],\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "validation_image_generator = image_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    classes = [image_folder],\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "validation_mask_generator = masks_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    classes = [masks_folder],\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "test_image_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    classes = [image_folder],\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "test_mask_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    classes = [masks_folder],\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = zip(image_generator, mask_generator)\n",
    "validation_generator = zip(validation_image_generator, validation_mask_generator)\n",
    "test_generator = zip(test_image_generator, test_mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_train_samples: 26112\n",
      "nb_validation_samples: 8704\n",
      "nb_test_samples: 28\n",
      "\n",
      "predict_size_train: 1632\n",
      "predict_size_validation: 544\n",
      "predict_size_test: 2\n"
     ]
    }
   ],
   "source": [
    "nb_train_samples = len(image_generator.filenames)\n",
    "nb_validation_samples = len(validation_image_generator.filenames)\n",
    "nb_test_samples = len(test_image_generator.filenames)\n",
    "\n",
    "predict_size_train = int(math.ceil(nb_train_samples / batch_size))\n",
    "predict_size_validation = int(math.ceil(nb_validation_samples / batch_size))\n",
    "predict_size_test = int(math.ceil(nb_test_samples / batch_size))\n",
    "\n",
    "print(\"nb_train_samples:\", nb_train_samples)\n",
    "print(\"nb_validation_samples:\", nb_validation_samples)\n",
    "print(\"nb_test_samples:\", nb_test_samples)\n",
    "\n",
    "print(\"\\npredict_size_train:\", predict_size_train)\n",
    "print(\"predict_size_validation:\", predict_size_validation)\n",
    "print(\"predict_size_test:\", predict_size_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 1.\n",
    "from keras import backend as K\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def Specificity(y_true, y_pred):\n",
    "    true_negatives = K.abs(y_pred)- K.abs(y_true)\n",
    "    return ((true_negatives+smooth)/(y_pred+ smooth))\n",
    "\n",
    "def Sensitivity(y_true, y_pred):\n",
    "    y_true = K.flatten(y_true)\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    return ((y_pred+smooth)/ (y_true+smooth))\n",
    "\n",
    "def Jaccard_index(y_true,y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return ((intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + smooth))\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "    Only computes a batch-wise average of precision.\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "    Only computes a batch-wise average of recall.\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def f1score(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "        Only computes a batch-wise average of recall.\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "        Only computes a batch-wise average of precision.\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 256, 256, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 16) 448         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_1 (AlphaDropout)  (None, 256, 256, 16) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 16) 2320        alpha_dropout_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 16) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 32) 4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_2 (AlphaDropout)  (None, 128, 128, 32) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 32) 9248        alpha_dropout_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 32)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 64)   18496       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_3 (AlphaDropout)  (None, 64, 64, 64)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 64)   36928       alpha_dropout_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 64)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 128)  73856       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_4 (AlphaDropout)  (None, 32, 32, 128)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 128)  147584      alpha_dropout_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 128)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 256)  295168      max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_5 (AlphaDropout)  (None, 16, 16, 256)  0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 256)  590080      alpha_dropout_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 32, 32, 128)  131200      conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 256)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 128)  295040      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_6 (AlphaDropout)  (None, 32, 32, 128)  0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 128)  147584      alpha_dropout_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 64, 64, 64)   32832       conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 128)  0           conv2d_transpose_2[0][0]         \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 64)   73792       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_7 (AlphaDropout)  (None, 64, 64, 64)   0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 64)   36928       alpha_dropout_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 128, 128, 32) 8224        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 128, 64) 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 128, 32) 18464       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_8 (AlphaDropout)  (None, 128, 128, 32) 0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 128, 128, 32) 9248        alpha_dropout_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 256, 256, 16) 2064        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 256, 256, 32) 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 256, 256, 16) 4624        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_9 (AlphaDropout)  (None, 256, 256, 16) 0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 256, 256, 16) 2320        alpha_dropout_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 256, 256, 1)  17          conv2d_18[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,941,105\n",
      "Trainable params: 1,941,105\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Unet(img_size = 256)\n",
    "model.summary()\n",
    "adam_opt = Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(optimizer= adam_opt, loss=dice_coef_loss, \n",
    "              metrics=[dice_coef, 'acc','mse', Jaccard_index, Specificity, Sensitivity, precision, recall, f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1632/1632 [==============================] - 374s 229ms/step - loss: -0.1345 - dice_coef: 0.1345 - acc: 0.5043 - mean_squared_error: 0.3393 - Jaccard_index: 0.0725 - Specificity: 0.9683 - Sensitivity: 1.3587 - precision: 0.0847 - recall: 0.6170 - f1score: 0.1464 - val_loss: -0.1851 - val_dice_coef: 0.1851 - val_acc: 0.6312 - val_mean_squared_error: 0.2071 - val_Jaccard_index: 0.1028 - val_Specificity: 0.9582 - val_Sensitivity: 1.1989 - val_precision: 0.1274 - val_recall: 0.5210 - val_f1score: 0.2033error: 0.3840 - Jaccard_index: 0.0647 - Specificity: - ET - ETA: 58s - loss: -0.1303 - dice_coef: 0.1303 - acc - ETA: 1s - loss: -0.1343 - dice_coef: 0.1343 - acc: 0.5036 - mean_squared_error: 0.3395 - Jaccard_index: 0.0724 - Specificity: 0.9683 - Sensitivity: 1.3592 - precision: 0.0846 - recall: 0.6171\n",
      "Epoch 2/50\n",
      "1632/1632 [==============================] - 370s 227ms/step - loss: -0.1517 - dice_coef: 0.1517 - acc: 0.6155 - mean_squared_error: 0.2637 - Jaccard_index: 0.0824 - Specificity: 0.9658 - Sensitivity: 1.2387 - precision: 0.1000 - recall: 0.5338 - f1score: 0.1669 - val_loss: -0.1917 - val_dice_coef: 0.1917 - val_acc: 0.6109 - val_mean_squared_error: 0.2602 - val_Jaccard_index: 0.1068 - val_Specificity: 0.9597 - val_Sensitivity: 1.2350 - val_precision: 0.1292 - val_recall: 0.5866 - val_f1score: 0.2103TA: 3:51 - loss: -0.1526 - dice_coef: 0.1526 - acc: 0.6036 - mean_squared_error: 0.2780 - Jaccard_index: 0.0829 - Specificity: - ETA: 3:44 - loss: -0.1519 - dice_coef: 0.1519 - acc: 0.6051 - mean_squared_error: 0.2775 - Jaccard_index: 0.0826 - Specificity: 0.9664 - Sensit - ETA: 3:39 - loss: -0.1519 - dice_coef: 0.1519 - acc: 0.6055 - mean_squared_error: 0.2764 - Jaccard_index: 0.0826 - Specificity: 0.9664 - Sensitivity: 1.2543 - precision: 0.0992 - recall: 0.5576 - f - ETA: 3:38 - loss: -0.1518 - dice_coef: 0.1518 - acc: 0.6058 - mean_squared_error: 0.2760 - Jaccard_inde - ETA: 3:31 - loss: -0.1513 - dice_coef: 0.1513 - acc: 0.6070 - mean_squared_error: 0.2751 - Jaccard_index: 0.0822 - Specificity: 0.9662 - Sensitivity: 1.2525 - precisio - ETA: 3:27 - loss: -0.1513 - dice_coef: 0.1513 - acc: 0.6081 - mean_squared_error: 0.2733 - Jaccard_index: 0.0822 - Specificity: 0.9662 - ETA: 14s - loss: -0.1516 - dice_coef: 0.1516 - acc: 0.6151 - mean_squared_error: 0.2643 - Jaccard_index: 0.0824 - Specificity: 0.9658 - Sensitivity: 1 - ETA: 7s - loss: -0.1517 - dice_coef: 0.1517 - acc: 0.6162 - mean_squared_error: 0.2631 - Jaccard_index: 0.0824 - Specificity:\n",
      "Epoch 3/50\n",
      "1632/1632 [==============================] - 368s 226ms/step - loss: -0.1562 - dice_coef: 0.1562 - acc: 0.6456 - mean_squared_error: 0.2317 - Jaccard_index: 0.0851 - Specificity: 0.9646 - Sensitivity: 1.2022 - precision: 0.1052 - recall: 0.4864 - f1score: 0.1718 - val_loss: -0.1959 - val_dice_coef: 0.1959 - val_acc: 0.6390 - val_mean_squared_error: 0.2331 - val_Jaccard_index: 0.1095 - val_Specificity: 0.9582 - val_Sensitivity: 1.2008 - val_precision: 0.1354 - val_recall: 0.5333 - val_f1score: 0.2145- Specificity: 0.9650 - Sensitiv - ETA: 2:47 - loss: -0.1561 - dice_\n",
      "Epoch 4/50\n",
      "1632/1632 [==============================] - 370s 227ms/step - loss: -0.1598 - dice_coef: 0.1598 - acc: 0.6695 - mean_squared_error: 0.2056 - Jaccard_index: 0.0873 - Specificity: 0.9637 - Sensitivity: 1.1729 - precision: 0.1104 - recall: 0.4460 - f1score: 0.1757 - val_loss: -0.1962 - val_dice_coef: 0.1962 - val_acc: 0.6401 - val_mean_squared_error: 0.2338 - val_Jaccard_index: 0.1098 - val_Specificity: 0.9582 - val_Sensitivity: 1.1998 - val_precision: 0.1358 - val_recall: 0.5340 - val_f1score: 0.2149ity: 0.9639 - Sensitivity: 1.1795 - precision: 0.1 - ETA: 1:48 - loss: -0.1590 - dice_coef: 0.1590 - acc: 0.6630 - mean_squared_error: 0.2113 - Jaccard_index: 0.0868 - Specificity: 0.9639 - Sensitivity: 1.1 - - ETA: 1:07 - loss: -0.1595 - dice_coef: 0.1 - ETA: 46s - loss: -0.1596 - dice_coef: 0.1596 - acc: 0.6667 - mean_ - ETA: 21s - loss: -0.1594 - dice_coef: 0.1594 - acc: 0.6682 - mean_squared_error: 0.2067 - Jaccard_index: 0.0871 - Specificity: 0.9638 - Sensitivity: 1.1742 - precision: 0.1100 - re - ETA: 16s - loss: -0.1595 - dice_coef: 0.1595 - acc: 0.6686 \n",
      "Epoch 5/50\n",
      "1632/1632 [==============================] - 371s 227ms/step - loss: -0.1627 - dice_coef: 0.1627 - acc: 0.6888 - mean_squared_error: 0.1855 - Jaccard_index: 0.0892 - Specificity: 0.9629 - Sensitivity: 1.1495 - precision: 0.1151 - recall: 0.4125 - f1score: 0.1788 - val_loss: -0.1970 - val_dice_coef: 0.1970 - val_acc: 0.6443 - val_mean_squared_error: 0.2297 - val_Jaccard_index: 0.1102 - val_Specificity: 0.9579 - val_Sensitivity: 1.1946 - val_precision: 0.1368 - val_recall: 0.5253 - val_f1score: 0.2157ror: 0.1944 - Jaccard_index: 0.0877 - Specificity: 0.9632 - Sensitivity: 1.1597 - precision: 0.1122 - recall:  - ETA: 1:52 - loss: -0.1625 - dice_coef: 0.1625 - acc: 0.6843 - mean_squared_er - ETA: 31s - loss: -0.1629 - dice_coef: 0.1629 - acc: 0.6881 - mean_squared_error: 0.1862 - Jaccard_index: 0.0892 - Specificity: 0.9628 - Sensitivity: 1.1504 - precision: 0. - ETA: 24s -\n",
      "Epoch 6/50\n",
      "1632/1632 [==============================] - 370s 226ms/step - loss: -0.1641 - dice_coef: 0.1641 - acc: 0.6989 - mean_squared_error: 0.1755 - Jaccard_index: 0.0900 - Specificity: 0.9624 - Sensitivity: 1.1374 - precision: 0.1179 - recall: 0.3936 - f1score: 0.1804 - val_loss: -0.1992 - val_dice_coef: 0.1992 - val_acc: 0.6652 - val_mean_squared_error: 0.2076 - val_Jaccard_index: 0.1117 - val_Specificity: 0.9567 - val_Sensitivity: 1.1684 - val_precision: 0.1421 - val_recall: 0.4828 - val_f1score: 0.2178 - loss: -0.1643 - dice_coef: 0.1643 - acc: 0.6955 - mean_squared_error: 0.1770 - Jaccard_index: 0.0901 - Specificity: 0.9624  - ETA: 1:51 - loss: -0.1650 - dice_coef: 0.1650 - acc: 0.6984 - mean_squared_error: 0.1762 - Jaccard_index: 0.0904 - Specificity: 0.9625 - Sensitivity: 1.1385 - precision: 0 - ETA: 1:47 - loss: -0.1651 - dice_coef: 0.1651 - a - ETA: 1:34 - loss: -0.1646 - dice_coef: 0.1646 - acc: 0.6982 - mean_squared_error: 0.1759 - Jaccard_index: 0.0 - ETA: 1:25 - loss: -0.1645 - dice_coef: 0.1645 - acc: 0.6983 - mean_squared_error: 0.1757 - Jaccard_index: 0.0902 - Specificity: 0.9625 - Sensitivity: 1.1378 - precision: 0.1 - ETA: 1:21 - loss: -0.1644 - dice_coef: - ETA: 38s - loss: -0.1642 - dice_coef: 0.1642 - acc: 0.6999 - mean_squared_error: 0.1749 - Jaccard_index: 0.0900 - Specificity: 0.9624 - Sensiti\n",
      "Epoch 7/50\n",
      "1632/1632 [==============================] - 371s 227ms/step - loss: -0.1648 - dice_coef: 0.1648 - acc: 0.7054 - mean_squared_error: 0.1689 - Jaccard_index: 0.0904 - Specificity: 0.9621 - Sensitivity: 1.1295 - precision: 0.1197 - recall: 0.3807 - f1score: 0.1811 - val_loss: -0.1999 - val_dice_coef: 0.1999 - val_acc: 0.6782 - val_mean_squared_error: 0.1939 - val_Jaccard_index: 0.1122 - val_Specificity: 0.9559 - val_Sensitivity: 1.1521 - val_precision: 0.1453 - val_recall: 0.4545 - val_f1score: 0.21830.1\n",
      "Epoch 8/50\n",
      "1632/1632 [==============================] - 372s 228ms/step - loss: -0.1652 - dice_coef: 0.1652 - acc: 0.7102 - mean_squared_error: 0.1640 - Jaccard_index: 0.0907 - Specificity: 0.9618 - Sensitivity: 1.1236 - precision: 0.1211 - recall: 0.3709 - f1score: 0.1815 - val_loss: -0.2001 - val_dice_coef: 0.2001 - val_acc: 0.6902 - val_mean_squared_error: 0.1815 - val_Jaccard_index: 0.1125 - val_Specificity: 0.9551 - val_Sensitivity: 1.1370 - val_precision: 0.1484 - val_recall: 0.4252 - val_f1score: 0.2183f: 0.1652 - acc: 0.7101 - mean_squared_error: 0.1640 - Jaccard_index: 0.0906 - Specificity: 0.9619 - Sens\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1632/1632 [==============================] - 374s 229ms/step - loss: -0.1655 - dice_coef: 0.1655 - acc: 0.7129 - mean_squared_error: 0.1614 - Jaccard_index: 0.0909 - Specificity: 0.9617 - Sensitivity: 1.1203 - precision: 0.1220 - recall: 0.3654 - f1score: 0.1819 - val_loss: -0.1995 - val_dice_coef: 0.1995 - val_acc: 0.6948 - val_mean_squared_error: 0.1770 - val_Jaccard_index: 0.1122 - val_Specificity: 0.9548 - val_Sensitivity: 1.1312 - val_precision: 0.1497 - val_recall: 0.4114 - val_f1score: 0.2176\n",
      "Epoch 10/50\n",
      "1632/1632 [==============================] - 372s 228ms/step - loss: -0.1654 - dice_coef: 0.1654 - acc: 0.7130 - mean_squared_error: 0.1615 - Jaccard_index: 0.0908 - Specificity: 0.9617 - Sensitivity: 1.1202 - precision: 0.1221 - recall: 0.3647 - f1score: 0.1818 - val_loss: -0.1985 - val_dice_coef: 0.1985 - val_acc: 0.6777 - val_mean_squared_error: 0.1949 - val_Jaccard_index: 0.1115 - val_Specificity: 0.9558 - val_Sensitivity: 1.1525 - val_precision: 0.1445 - val_recall: 0.4512 - val_f1score: 0.21701606 - Jaccard_index: 0.0913 - Specificity: 0.9617 - Sensiti - ETA: 14s - loss: -0.1655 - dice_coef: 0.1655 - acc: 0.7137 - mean_squared_error: 0.1615 - Jaccard_index: 0.0909 - Specificity: 0.9618  - ETA: 5s - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7135 - mean_squared_error: 0.1615 - Jaccard_index: 0.0909 - Specificity: 0.9617 - Sensitivity: 1.1203 - precision: 0.1222  - ETA: 2s - loss: -0.1654 - dice_coef: 0.1654 - acc: 0.7133 - mean_squared_error: 0.1615 - Jaccard_index: 0.0908 - Specificity: 0.9617 - Sensitivity: 1.1203 - precision: 0.1221 - re\n",
      "Epoch 11/50\n",
      "1632/1632 [==============================] - 373s 229ms/step - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7141 - mean_squared_error: 0.1604 - Jaccard_index: 0.0910 - Specificity: 0.9616 - Sensitivity: 1.1189 - precision: 0.1224 - recall: 0.3628 - f1score: 0.1820 - val_loss: -0.2001 - val_dice_coef: 0.2001 - val_acc: 0.6916 - val_mean_squared_error: 0.1799 - val_Jaccard_index: 0.1124 - val_Specificity: 0.9550 - val_Sensitivity: 1.1350 - val_precision: 0.1489 - val_recall: 0.4235 - val_f1score: 0.2184: 0.1655 - acc: 0.7141 - mean_squared_error: 0.1605 - Jaccard_index: 0.0909 - Specificity: 0.9616 - Sensitivity: 1.1189 - precision: 0.1223 - recall: 0.3625 - f1score - ETA: 10s - loss: -0.1655 - dice_coef: 0.1655 - acc: 0.7143 - mean_squared_error: 0.1605 - Jaccard_index: 0.0909 - Specificity: 0.9616 - Sensitivity: 1.1189 - precision: 0.1223 - ETA: 6s - loss: -0.1657 - dice_coef: 0.1657 - acc: 0.7142 - mean_squared_error: 0.1605 - Jaccard_index: 0.0910 - Specificity: 0.9\n",
      "Epoch 12/50\n",
      "1632/1632 [==============================] - 370s 227ms/step - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7143 - mean_squared_error: 0.1603 - Jaccard_index: 0.0910 - Specificity: 0.9616 - Sensitivity: 1.1186 - precision: 0.1225 - recall: 0.3622 - f1score: 0.1821 - val_loss: -0.1996 - val_dice_coef: 0.1996 - val_acc: 0.6980 - val_mean_squared_error: 0.1733 - val_Jaccard_index: 0.1122 - val_Specificity: 0.9546 - val_Sensitivity: 1.1272 - val_precision: 0.1505 - val_recall: 0.4042 - val_f1score: 0.21759 - recall: 0.3609 - f1score: 0.18 - ETA: 1:07 - loss: -0.1649 - dice_coef: 0.1649 - acc: 0.7136 - mean_squared_error: 0.1604 - Jaccard_index: 0.0906 - Specificity: 0.9617 - Sensitivit - ETA: 1:01 - loss: -0.1650 - dice_coef: 0.1650 - acc: 0.7137 - mean_squared_error: 0.1604 - Jaccard_index: 0.0906 - Specificity: 0.9616 - Sensitivity: 1.1186 - precision: 0.1220 - recall: 0.3606 - f - ETA: 1:00 - loss: -0.1651 - dice_coef: 0.1651 - acc: 0.7139 - mean_squared_error: 0.1604 - Jaccard_index: 0.0907 - - ETA: 44s - loss: -0.1649 - dice_coef: 0.1649 - acc: 0.7147 - mean_squared_error: 0.1604 - Jaccard_index: 0.0906 - Specificity: 0.9617 - Sensitivity: 1.1187 - precision: 0.1219 - recall: 0.3 - ETA: 41s - loss: -0.1649 - dice_coef: 0.1649 - acc: 0.7138 - mean_squared_error: 0.1604 - Jaccard_index: 0.0905 - Specificity: - ETA: 26s - loss: -0.1650 - dice_coef: 0.1650 - acc: 0.7137 - mean_squared_error: 0.1603 - Jaccard_index: 0.0906 - Specificity: 0.9617 - Sensitivity: 1.1187 - precision: 0.1220 - rec - ETA: 21s - loss: -0.1653 - dice_coef: 0.1653 - acc: 0.7138 - mean_squared_error: 0.1603 - Jaccard_index: 0.0908 - Specificity: 0.9617 - Sensitivity: 1.1186 - precision: 0.1223  - ETA: 15s - loss: -0.1658 - dice_coef: 0.1658 - acc: 0.7137 - mean_squared_error: 0.1602 - Jaccard_index: 0.0911 - Specificity: 0.9616 - Sensitivit - ETA: 7s - loss: -0.1654 - dice_coef: 0.1654 - acc: 0.7139 - mean_squared_error: 0.1603 - Jaccard_index: 0.0909 - Specificity:\n",
      "Epoch 13/50\n",
      "1632/1632 [==============================] - 373s 229ms/step - loss: -0.1657 - dice_coef: 0.1657 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0910 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3627 - f1score: 0.1821 - val_loss: -0.1996 - val_dice_coef: 0.1996 - val_acc: 0.6962 - val_mean_squared_error: 0.1755 - val_Jaccard_index: 0.1122 - val_Specificity: 0.9547 - val_Sensitivity: 1.1293 - val_precision: 0.1501 - val_recall: 0.4100 - val_f1score: 0.2178ice_ - ETA: 2:07 - loss: -0.1665 - dice_coef: 0.1665 - acc: 0.7131 - mean_squared_error: 0.1602 - Jaccard_index: 0.0914 - Specificity: 0.9615 - Sensitivity: 1.1184 - precision: - ETA: 2:03 - loss: -0.1666 - dice_coef: 0.1666 - acc: 0.7126 - mean_squared_error: 0.1602 - Jaccard_index: 0.0915 - Specificity: 0.9614 -  - ETA: 1:57 - ETA: 1:39 - loss: -0.1665 - dice_coef: 0.1665 - acc: 0.7126 - mean_squared_error: 0.160 - E - ETA: 1:10 - loss: -0.1658  - ETA: 49s - loss: -0.1659 - dice_coef: 0.1659 - acc: 0.7136 - mean_squared_error: 0.1602 - Jaccard_index: 0.0911 - Specificity: 0.9616  - ETA: 36s - loss: -0.1657 - dice_coef: 0.1657 - acc: 0.7140 - mean_s - ETA: 11s - loss: -0.1657 - dice_coef: 0.1657 - acc: 0.7142 - mean_squared_error: 0.1602 - Jaccard_index: 0.0910 - Specificity: 0.9617 - Sensitivity: 1.1186 - precision: 0.1225 - - ETA: 7s - loss: -0.1655 - dice_coef: 0.1655 - acc: 0.7146 - mean_squared_error: 0.1602 - Jaccard_index: 0.0909 - Specif\n",
      "Epoch 14/50\n",
      "1632/1632 [==============================] - 372s 228ms/step - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0909 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3621 - f1score: 0.1820 - val_loss: -0.1993 - val_dice_coef: 0.1993 - val_acc: 0.7015 - val_mean_squared_error: 0.1695 - val_Jaccard_index: 0.1121 - val_Specificity: 0.9543 - val_Sensitivity: 1.1225 - val_precision: 0.1515 - val_recall: 0.3960 - val_f1score: 0.2172\n",
      "Epoch 15/50\n",
      "1632/1632 [==============================] - 372s 228ms/step - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7143 - mean_squared_error: 0.1603 - Jaccard_index: 0.0910 - Specificity: 0.9616 - Sensitivity: 1.1186 - precision: 0.1225 - recall: 0.3621 - f1score: 0.1820 - val_loss: -0.1988 - val_dice_coef: 0.1988 - val_acc: 0.7051 - val_mean_squared_error: 0.1659 - val_Jaccard_index: 0.1118 - val_Specificity: 0.9540 - val_Sensitivity: 1.1177 - val_precision: 0.1524 - val_recall: 0.3872 - val_f1score: 0.2166e_coef: 0.1657 - acc: 0.7145 - mean_squar - ETA: 56s - loss: -0.1658 - dice_coef: 0.1658 - acc: 0.71 - ETA: 30s - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7138 - mean_squared_error: 0.1604 - Jaccard_index: 0.0910 - Specificity: 0.9616 - Sensitivi - ETA: 18s - loss: -0.1655 - dice_coef: 0.1655 -\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1632/1632 [==============================] - 370s 227ms/step - loss: -0.1657 - dice_coef: 0.1657 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0910 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3625 - f1score: 0.1821 - val_loss: -0.1991 - val_dice_coef: 0.1991 - val_acc: 0.7050 - val_mean_squared_error: 0.1664 - val_Jaccard_index: 0.1119 - val_Specificity: 0.9540 - val_Sensitivity: 1.1181 - val_precision: 0.1525 - val_recall: 0.3880 - val_f1score: 0.2170ean_squared_error: 0.1604 - Jaccard_index: 0.0909 - Specificity: 0.9616 - Sensitivity: 1.1185 - pr - ETA: 47s - loss: -0.1658 - dice_coef: 0.1658 - acc: 0.7135 - mean_squared_error: 0.1603 - Jaccard_index: 0.0911 - ETA: 1s - loss: -0.1658 - dice_coef: 0.1658 - acc: 0.7145 - mean_squared_error: 0.1602 - Jaccard_index: 0.0911 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1226 - recall: 0.\n",
      "Epoch 17/50\n",
      "1632/1632 [==============================] - 375s 230ms/step - loss: -0.1657 - dice_coef: 0.1657 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0910 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3623 - f1score: 0.1821 - val_loss: -0.1991 - val_dice_coef: 0.1991 - val_acc: 0.7055 - val_mean_squared_error: 0.1654 - val_Jaccard_index: 0.1118 - val_Specificity: 0.9540 - val_Sensitivity: 1.1173 - val_precision: 0.1525 - val_recall: 0.3862 - val_f1score: 0.2167recall: 0.3608 - f1s - ETA - ETA: 1:28 - loss: -0.1653 - dice_coef: 0.1653 - acc: 0.7159 - mean_squared_error: 0.1604 - Jaccard_index: 0.0908 - Specificity: 0.9616 - Sensitivity: 1.1186 - precision: 0.1222 - recall:  - ETA: 1:26 - - ETA: 1:09 - loss: -0.1651 -  - ETA: 46s - loss: -0.1649 - dice_coef: 0.1649 - acc: 0.7155 - mean_squared_error: 0.1605 - Jaccard_i\n",
      "Epoch 18/50\n",
      "1632/1632 [==============================] - 375s 230ms/step - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0909 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3619 - f1score: 0.1820 - val_loss: -0.1988 - val_dice_coef: 0.1988 - val_acc: 0.7057 - val_mean_squared_error: 0.1649 - val_Jaccard_index: 0.1118 - val_Specificity: 0.9540 - val_Sensitivity: 1.1167 - val_precision: 0.1525 - val_recall: 0.3851 - val_f1score: 0.2165rd_index: 0.0907 - Specificity: 0.9616 - Sensitivity: 1.1186 - precision: 0.1223 - recall: 0.3613 - f1sco - ETA: 22s - loss: -0.1651 - dice_coef: 0.1651 - acc: 0.7142 - mean_squared_error: 0.1603 - Jaccard_index: 0.0906 - Specificity: 0.9617 - Sensitivity: 1.1186 - precision: 0.1221 - recall: 0.3610 - f1score: - ETA: 21s - loss: -0.1651 - dice_c\n",
      "Epoch 19/50\n",
      "1632/1632 [==============================] - 376s 230ms/step - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0909 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3618 - f1score: 0.1821 - val_loss: -0.1986 - val_dice_coef: 0.1986 - val_acc: 0.7059 - val_mean_squared_error: 0.1645 - val_Jaccard_index: 0.1116 - val_Specificity: 0.9539 - val_Sensitivity: 1.1164 - val_precision: 0.1525 - val_recall: 0.3835 - val_f1score: 0.2162ean_squared_error: 0.1606 - Jaccard_index: 0.0897 - Specificity: - ETA: 3:59 - loss: -0.1642 - dice_coef: 0.1642 - acc: 0.7197 - mean_squared_error: 0.1604 - Jaccard_index: 0.0902 - Specificity: 0.9618 - Sensitivity: 1.1188 - precision: 0.1218 - recall: 0.3594 - ETA: 3:58 - loss: -0.1649 - dice_coef: 0.1649 - acc: 0.7193 - mean_squared_error: 0.1605 - Jaccard_in - ETA: 3:50 - loss: -0.1646 - dice_coef: 0.1646 - acc: 0.7178 - mean_squared_error: 0.1602 - Jaccard_index: 0.0904 - Specificity: 0.9619 -  - ETA: 3:44 - loss: -0.1656 - dice_coef: 0.1656 - acc: 0. - ETA: 3:31 - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7189 - mean_squared_error: 0.1602 - Jaccard_index: 0.091 - ETA: 3:24 - loss: -0.1655 - dice_coef: 0.1655 - acc: 0.7203 - mean_squared_error: 0.1602 - Jaccard_inde - ETA: 3:14 - loss: -0.1645 - dice_coef: 0.1645 - acc: 0.7197 - mean_squared_error: 0.1604 - Jaccard_index: 0.0903 - Specificity: 0.961 - ETA: 3:08 - loss: -0.1646 - dice_coef: 0.1646 - acc: 0.7199 - mean_squared_error: 0.1605 - Jaccard_index: 0.0903 - Specificity: 0.9617 - Sensitivity: 1.1187 - precision: 0.1221 - recall: 0.3605 - f1score: 0.18 - ETA: 3:08 - loss: -0.1646 - dice_coef: 0.1646 - acc: 0.72 - ETA: 2:55 - loss: -0.16 - ETA: 35s - loss: -0.1655 - dice_coef: 0.1655 - acc: 0.7154 - mean_squared_error: 0.1603 - Jaccard_index: 0.0909 - Specificity: 0.9617 - Sensitivity: 1.1185 - precisio\n",
      "Epoch 20/50\n",
      "1632/1632 [==============================] - 374s 229ms/step - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0910 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3621 - f1score: 0.1821 - val_loss: -0.1970 - val_dice_coef: 0.1970 - val_acc: 0.7074 - val_mean_squared_error: 0.1634 - val_Jaccard_index: 0.1107 - val_Specificity: 0.9537 - val_Sensitivity: 1.1148 - val_precision: 0.1519 - val_recall: 0.3773 - val_f1score: 0.2147\n",
      "Epoch 21/50\n",
      "1632/1632 [==============================] - 373s 228ms/step - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0909 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3624 - f1score: 0.1820 - val_loss: -0.1981 - val_dice_coef: 0.1981 - val_acc: 0.7091 - val_mean_squared_error: 0.1618 - val_Jaccard_index: 0.1112 - val_Specificity: 0.9537 - val_Sensitivity: 1.1129 - val_precision: 0.1531 - val_recall: 0.3769 - val_f1score: 0.2155\n",
      "Epoch 22/50\n",
      "1632/1632 [==============================] - 375s 230ms/step - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0910 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3616 - f1score: 0.1820 - val_loss: -0.1982 - val_dice_coef: 0.1982 - val_acc: 0.7106 - val_mean_squared_error: 0.1607 - val_Jaccard_index: 0.1114 - val_Specificity: 0.9536 - val_Sensitivity: 1.1112 - val_precision: 0.1540 - val_recall: 0.3723 - val_f1score: 0.2159\n",
      "Epoch 23/50\n",
      "1632/1632 [==============================] - 372s 228ms/step - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0909 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3617 - f1score: 0.1820 - val_loss: -0.1984 - val_dice_coef: 0.1984 - val_acc: 0.7107 - val_mean_squared_error: 0.1606 - val_Jaccard_index: 0.1114 - val_Specificity: 0.9536 - val_Sensitivity: 1.1108 - val_precision: 0.1541 - val_recall: 0.3723 - val_f1score: 0.2160ificity: 0.9616 - Sensitivity: 1.1184 - ETA: 28s - loss: -0.1662 - dice_coef: 0.1662 - acc: 0.7136 - mean_squared_error: 0.1602 - Jaccard_index: 0.0913 - Specificity: 0.9 - ETA: 14s - loss: -0.1659 - dice_coef: 0.1659 - acc: 0.7140 - mean_squared_error: 0.1602 - Jaccard_index: 0.0911 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1228 - recall: 0.3625 - f1score - ETA: 13s - loss: -0.1660 - dice_coef: 0.1660 - acc: 0.7141 - mean_squared_erro\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1632/1632 [==============================] - 373s 228ms/step - loss: -0.1657 - dice_coef: 0.1657 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0910 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3627 - f1score: 0.1821 - val_loss: -0.1982 - val_dice_coef: 0.1982 - val_acc: 0.7098 - val_mean_squared_error: 0.1612 - val_Jaccard_index: 0.1114 - val_Specificity: 0.9537 - val_Sensitivity: 1.1120 - val_precision: 0.1537 - val_recall: 0.3752 - val_f1score: 0.2159 - Specificity: 0.9617 - Sensitivity: 1.1186 - precision: 0.1227 - recall: 0.3635 - f1score: 0 - ETA: 49s - loss: -0.1658 - dice_coef: 0.1658 - acc: 0.7143 - mean_squared_error: 0.1602 - Jaccard_index: 0.0911 - Specificity: 0.9617 - Sensitivity: 1.1186 - precision: 0.1228 - recall: 0.3636 - f1sc - ETA: 47s - loss: -0.1658 - dice_coef: 0.1658 - acc: 0.7143 - mean_squared_error: 0.1602 - Ja\n",
      "Epoch 25/50\n",
      "1632/1632 [==============================] - 373s 228ms/step - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0910 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3617 - f1score: 0.1820 - val_loss: -0.1984 - val_dice_coef: 0.1984 - val_acc: 0.7100 - val_mean_squared_error: 0.1610 - val_Jaccard_index: 0.1115 - val_Specificity: 0.9537 - val_Sensitivity: 1.1118 - val_precision: 0.1538 - val_recall: 0.3740 - val_f1score: 0.2160 mean_squared_error: 0.1603 - Jaccard_index: 0.0912 - Specificity: 0.9616 - Sensitivity:  - ETA: 16s - loss: -0.1659 - dice_coef: 0.1659 - acc: 0.7150\n",
      "Epoch 26/50\n",
      "1632/1632 [==============================] - 378s 231ms/step - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0910 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3620 - f1score: 0.1820 - val_loss: -0.1987 - val_dice_coef: 0.1987 - val_acc: 0.7105 - val_mean_squared_error: 0.1607 - val_Jaccard_index: 0.1115 - val_Specificity: 0.9536 - val_Sensitivity: 1.1113 - val_precision: 0.1540 - val_recall: 0.3744 - val_f1score: 0.2163 0.0901 - Specificity: 0.9617 - Sensitivity: 1.1187 - precision: 0.1214 - recall: 0. - ETA: 1:57 - loss: -0.1643 - dice_coef: 0.1643 - acc: 0.7139 - mean_square - ETA: 1:45 - loss: -0.1644 - dice_coef: 0.1644 - ETA: 1:31 - loss: -0.1645 - dice_coef: 0.1645 - acc: 0.7148 - mean_squared_error: 0.1604 - Jaccard_index: 0.0903 - Specificity: 0.9617 - Sensitivity: 1.1187 - precision: 0.1216 - recall: 0.3603 - f1score:  - ETA:  - ETA: 1:12 - loss: -0.1654 - dice_coef: 0.1654 - acc: 0.7150 - mean_squared_error: 0.1602 - Jaccard_index:\n",
      "Epoch 27/50\n",
      "1632/1632 [==============================] - 377s 231ms/step - loss: -0.1657 - dice_coef: 0.1657 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0910 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3624 - f1score: 0.1821 - val_loss: -0.1983 - val_dice_coef: 0.1983 - val_acc: 0.7107 - val_mean_squared_error: 0.1606 - val_Jaccard_index: 0.1114 - val_Specificity: 0.9536 - val_Sensitivity: 1.1109 - val_precision: 0.1541 - val_recall: 0.3727 - val_f1score: 0.2161coef: 0.1657 - acc: 0.7151 - mean_squared_error: 0.1603 - Jaccard_index: 0.0910 - Specificity: 0.9616 - Sensitivity: 1.1185 - pre - ETA: 50s - loss: -0.1660 - dice_coef: 0.1660 - acc: 0.7151 - mean_squared_error: 0.1603 - Jaccard_index: 0.0912 - Specificity: 0.961 - ETA: 36s - loss: -0.1659 - dice_coef: 0.1659 - acc: 0.7148 - mean_squared_error: 0.1602 - Jaccard_index: 0.0911 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1227 - recall: 0.3629  - ETA: 33s - loss: -0.1657 - dice_coef: 0.1657 - acc: 0.7145 - mean_squared_error: 0.1603 - Jaccard_index: 0.0910 - Specificity: 0.9616 - Sensitivity: 1.1185 - pre - ETA: 24s - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0909 - Specificity: 0.9616 - Sensitivity: 1.1185 - pre - ETA: 16s - loss: -0.1657 - dice_coef: 0.1657 - acc: 0.7144 - me\n",
      "Epoch 28/50\n",
      "1632/1632 [==============================] - 377s 231ms/step - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0910 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3627 - f1score: 0.1821 - val_loss: -0.1986 - val_dice_coef: 0.1986 - val_acc: 0.7107 - val_mean_squared_error: 0.1606 - val_Jaccard_index: 0.1115 - val_Specificity: 0.9536 - val_Sensitivity: 1.1110 - val_precision: 0.1541 - val_recall: 0.3742 - val_f1score: 0.21648 - Specificity: 0.9618 - Sensitivity: 1.1188 - precis - ETA: 45s - loss: -0.1652 - dice_coef: 0.1652 - acc: 0.7138 - mean_squared_error: 0.1603 - Jaccard_index: 0.0907 - Specificity: 0 - ETA: 30s - loss: -0.1655 - dice_coef: 0.1655 - acc: 0.7144 - mean_squared_error: 0.1602 - Jaccard_index: 0.0909 - Specificity: 0.9617 - Sensitivity: 1.118 - ETA: 20s - loss: -0.1657 - dice_coef: 0.1657 - acc: 0.7147 - mean_sq - ETA: 2s - loss: -0.1655 - dice_coef: 0.1655 - acc: 0.7146 - mean_squared_error: 0.1603 - Jaccard_index: 0.0909 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1224 - \n",
      "Epoch 29/50\n",
      "1632/1632 [==============================] - 377s 231ms/step - loss: -0.1655 - dice_coef: 0.1655 - acc: 0.7143 - mean_squared_error: 0.1604 - Jaccard_index: 0.0909 - Specificity: 0.9616 - Sensitivity: 1.1186 - precision: 0.1225 - recall: 0.3621 - f1score: 0.1819 - val_loss: -0.1720 - val_dice_coef: 0.1720 - val_acc: 0.6707 - val_mean_squared_error: 0.2043 - val_Jaccard_index: 0.0950 - val_Specificity: 0.9542 - val_Sensitivity: 1.1574 - val_precision: 0.1243 - val_recall: 0.3947 - val_f1score: 0.1877 loss: -0.1662 - dice_coef: 0.1662 - acc: 0.7124 - mean_squared_error: 0.1604 - Jaccard_index: 0.0913 - Specificity: 0 - ETA: 1:11 - loss: -0.1660 - dice_coef: 0.1660 - acc: 0.7130 - mean_squared_error: 0.1604  - ETA: 1:01 - loss: -0.1660 - dice_coef: 0.1660 - acc: 0.7128 - mean_squared_error: 0.1605 - Jaccard_index: 0.0912 - Specificity: 0.9614 - Sensitivity: 1.1185 -  - ETA: 53s - loss: -0.1662 - dice_coef: 0.1662 - acc: 0.7134 - mean_squared_error: 0.1604 - Jaccard_index: 0.0913 - Specificity: 0.9615 - Sensitivity: 1.1185 - precision: 0.1231 - recall: 0.3621 - f1s - ETA: 51s - loss: -0.1661 - dice_coef: 0.1661 - acc: 0.7135 - mean_squared_error: 0.1604 - Jaccard_index: 0.0913 - Specificity: 0.9615 - ETA: 37s - loss: -0.1654 - dice_coef: 0.1654 - acc: 0.7138 - mean_squared_error: 0.1604 - Jaccard_index: 0.0909 - Specificity: 0.9615 - Sensitivity: 1 - ETA: 27s - loss: -0.1658 - dice_coef: 0.1658 - acc: 0.7134 - mean_squared_error: 0.1603 - Jaccard_index: 0.0911 - Specificity: 0.9616 - Sensitivity: 1.1186 - precision: 0.1227 - - ETA: 21s - loss: -0.1654 - dice_coef: 0.1654 - acc: 0.7138 - mean_square - ETA: 3s - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7139 - mean_squared_error: 0.1604 - Jaccard_index: 0.0909 - Specificity: 0.9616 - Sensitivity: 1.1186 - precision: 0\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1632/1632 [==============================] - 372s 228ms/step - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0909 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3619 - f1score: 0.1820 - val_loss: -0.1743 - val_dice_coef: 0.1743 - val_acc: 0.6762 - val_mean_squared_error: 0.1982 - val_Jaccard_index: 0.0964 - val_Specificity: 0.9541 - val_Sensitivity: 1.1510 - val_precision: 0.1271 - val_recall: 0.3902 - val_f1score: 0.1901.9615 - Sensitivity: 1.1184 - precisio - ETA: 1:45 - loss: -0.1660 - dice_ - ETA: 1:29 - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7179 - mean_squared_error: 0.1604 - Jaccard_in - ETA: 1:20 - loss: -0.1658 - dice_coef: 0.1658 - acc: 0.7175 - mean_squared_error: 0.1603 - Jaccard_index: 0.0910 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1227 - recall: 0.3618 - ETA: 1:18 - loss: -0.1659 - dice_coef: 0.1659 - acc: 0.7173 - mean_squared_error: 0.1603 - Jaccard_index: 0.0911 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.122 - ETA: 1:15 - loss: -0.1661 - dice_coef: 0.1661 - acc: 0.7173 - mean_squ - ETA: 28s - loss: -0.1655 - dice_coef: 0.1655 - acc: 0.7154 - mean_squared_error: 0.1603 - Jaccard_index: 0.0909 - Specificity: 0.9617 - Sensitivity: 1.1186 - precision: 0.1225 - recall: 0.3620 - f1score - ETA: 27s - loss: -0.1657 - dice_coef: 0.1657 - acc: 0.7153 - mean_squared_error: 0.1602 - Jaccard_index: 0.0910 - Specificity: 0.9617 - Sensitivity: 1.1185 - precision: 0.1227 - r - ETA: 21s - loss: -0.1654 - dice_coef: 0.1654 - - ETA: 1s - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0909 - Specificity: 0.9617 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3620\n",
      "Epoch 31/50\n",
      "1632/1632 [==============================] - 370s 227ms/step - loss: -0.1655 - dice_coef: 0.1655 - acc: 0.7143 - mean_squared_error: 0.1603 - Jaccard_index: 0.0909 - Specificity: 0.9616 - Sensitivity: 1.1186 - precision: 0.1225 - recall: 0.3620 - f1score: 0.1819 - val_loss: -0.1937 - val_dice_coef: 0.1937 - val_acc: 0.7036 - val_mean_squared_error: 0.1678 - val_Jaccard_index: 0.1084 - val_Specificity: 0.9538 - val_Sensitivity: 1.1192 - val_precision: 0.1482 - val_recall: 0.3789 - val_f1score: 0.211101 - mean_squared_error: 0.1611 - Jaccard_index: 0.0875 - Specificity: 0.9621 - Sensitiv - ETA: 3:57 - loss: -0.1612 - dice_coef: 0.1612 - acc - ETA: 3:35 - loss: -0.1651 - dice_coef: 0.1651 - acc: 0.7149 - mean_squared_error: 0.1604 - Jaccard_index: 0.0906 - Specificity: 0.9617 - Sensitivity: 1.1186 - precision: 0.1225 - re - ETA: 3:32 - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7143 - mean_sq - ETA: 3:03 - loss: -0.1653 - dice_coef: 0.1653 - acc: 0.7123 - mean_squared_error: 0.1604 - Jaccard_index: 0.090 - ETA - ETA: 2:19 - loss: -0.1658 - dice_coef: 0.1658 - acc: 0.7164 - mean_squared_error: 0.1601 - Jaccard_index: 0.0910 - Specificity: 0.9619 - Sensitiv - ETA: 2:14 - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7159 - mean_squared_error: 0.1601 - Jaccard_index: 0.0909 - Specificity: 0.9619 -  - ETA: 2:07 - loss: -0.1654 - dice_co - ETA: 55s - loss: -0.1652 - dice_coef: 0.1652 - acc: 0.7142 - mean_squared_error: 0.1603 - Jaccard_index: 0.0907 - Specificity: 0.9617 - Sensiti - ETA: 43s - loss: -0.1653 - dice_coef: 0.1653 - acc: 0.7145 - mean_squared_error: 0.1603 - Jaccard_index: 0.0908 - Specificity: 0.9617 - Sensitivity: 1.1186 - precision: 0.1224 - recall: - ETA: 39s - loss: -0.1650 - ETA: 8s - loss: -0.1653 - dice_coef: 0.1653 - acc: 0.7149 - mean_squared_error: 0.1604 - Jaccard_index: 0.0\n",
      "Epoch 32/50\n",
      "1632/1632 [==============================] - 371s 228ms/step - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0909 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3626 - f1score: 0.1821 - val_loss: -0.1954 - val_dice_coef: 0.1954 - val_acc: 0.7058 - val_mean_squared_error: 0.1656 - val_Jaccard_index: 0.1096 - val_Specificity: 0.9537 - val_Sensitivity: 1.1167 - val_precision: 0.1503 - val_recall: 0.3772 - val_f1score: 0.213062 - dice_coef: 0.1662 - acc: 0.7136 - mean_squared_error: 0.1603 - Jaccard_index: 0.0 - ETA: 1:04 - loss:  - ETA: 4s - loss: -0.1655 - dice_coef: 0.1655 - acc: 0.7140 - mean_squared_error: 0.1603 - Jaccard_index: 0.0909 - Specificity: 0.9616 - Sensitivity: 1.1185 - \n",
      "Epoch 33/50\n",
      "1632/1632 [==============================] - 375s 230ms/step - loss: -0.1657 - dice_coef: 0.1657 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0910 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3624 - f1score: 0.1822 - val_loss: -0.1982 - val_dice_coef: 0.1982 - val_acc: 0.7101 - val_mean_squared_error: 0.1611 - val_Jaccard_index: 0.1112 - val_Specificity: 0.9536 - val_Sensitivity: 1.1116 - val_precision: 0.1537 - val_recall: 0.3738 - val_f1score: 0.2159ice_coef: 0.1691 - acc: 0.7084 - mean_squared_error: 0.1598 - Jaccard_index: 0.0929 - Specificity: 0.9615 - Sensitivity: 1.1182 - precision: 0.1253 - recall: 0.36 - ETA: 4:00 - loss: -0.1687 - dice_coef: 0.1687 - acc: 0.7090 - mean_squared_error: 0.1598 - Jaccard_index: - ETA: 3:37 - loss: -0.1681 - dice_coef: 0.1681 - acc: 0.7106 - mean_squared_error: 0.1602 - Jaccard_index: 0.0924 - Specificity: 0.9613 - Sensitivity: 1 - ETA: 3:32 - l - ETA: 3: - ETA: 2:58 - loss: -0.1672 - dice_coef: 0.1672 - acc: 0.7144 - mean_squared_error: 0.1602 - Jaccard_index: 0.0918 - Specificity: 0.9615 - Sensitivity: - ETA: 2:53 - loss: -0.1669 - dice_coef: 0.1669 - ETA: 2:40 - loss: -0.1659 - dice_coef: 0.1659 - acc: 0.7142 - mean_sq - ETA: 2:27 - loss: -0.1662 - dice_coef: 0.1662 - acc: 0.7136 - mean_squared_erro - ETA: 1:39 - loss: -0.1669 - dice_coef: 0.1669 - acc: 0.7150 - mean_squared_error: 0.1603 - Jaccard_index: 0.0917 - Specificity - ETA: 50s - loss: -0.1662 - dice_coef: 0.1662 - acc: 0.7140 - mean_squared_error: 0.1603 - Jaccard_index: 0.0913 - - ETA: 33s - loss: -0.1657 - dice_coef: 0.1657 - acc: 0.7137 - mean_squared_error: 0.1604 - Jaccard_index: 0.0910 - Specificity: 0.9615 - Sensitivity: 1.1184  - ETA: 23s - loss: -\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1632/1632 [==============================] - 372s 228ms/step - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0909 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3619 - f1score: 0.1820 - val_loss: -0.1980 - val_dice_coef: 0.1980 - val_acc: 0.7101 - val_mean_squared_error: 0.1611 - val_Jaccard_index: 0.1113 - val_Specificity: 0.9536 - val_Sensitivity: 1.1115 - val_precision: 0.1537 - val_recall: 0.3737 - val_f1score: 0.2157uared_error: 0.1599 - Jaccard_index: 0.0926 - Specificity: 0.961 - ETA: 2:05 - loss: -0.1686 - dice_coef: 0.1686 - acc: 0.7138 - mean_squared_error: 0.1599 - Jaccard_index: 0.0927 - Specificity: 0.9615 - Sensitivity: 1.1182 - precision: 0.1247 - recall: 0.36 - ETA: 2:04 - loss: -0.1685 - dice_coef: 0.1685 - acc: 0.7137 - mean_squared_error: 0.1599 - Jaccard_index: 0.0927 - Specificity: 0.9616 - Sensitivity: 1.1182 - precision: 0.1246 - recall: 0.3666 - f1s - ETA: 2:03 - loss: -0.1687 - dice_coef: 0.1687 - acc: 0.7139 - mean_squared_error: 0.1599 - Jaccard_index: 0.0928 - Specificity: 0.9615 - Sensitivity: 1.1182 - precision: 0.1249 - recall: 0.3668 - f1s - ETA: 2:02 - loss: -0.1685 - dice_coef: 0.1685 - acc: 0.7138 - mean_squared_error: 0.1599 - Jaccard_index: 0.0927 - Specificity: 0.9615 - Sensitivity: 1.1182 - pr - ETA: 1:58 - loss: -0.1681 - dice_coef: 0.1681 - acc: 0.7140 - mean_squared_error: 0.1599 - Jaccard_index: 0.0924 - Specificity: 0.9616 - Sensitivity: 1.1183 - precision: 0.1244 - recall: 0.3659 - - ETA: 1:56 - loss: -0.1681 - dice_coef: 0.1681 - acc: 0.7138 - mean_squared_error: 0.1599 - Jaccard_index: 0.0924 - Specificity: 0.9616 - Sens - ETA: 1:50 - loss: -0.1681 - dice_coef: 0.1681 - acc: 0.7144 - mean_square\n",
      "Epoch 35/50\n",
      "1632/1632 [==============================] - 370s 227ms/step - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0909 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3624 - f1score: 0.1821 - val_loss: -0.1984 - val_dice_coef: 0.1984 - val_acc: 0.7106 - val_mean_squared_error: 0.1607 - val_Jaccard_index: 0.1114 - val_Specificity: 0.9536 - val_Sensitivity: 1.1109 - val_precision: 0.1541 - val_recall: 0.3738 - val_f1score: 0.2162: 0.9616 - Sensitivit - ETA: 23s - los\n",
      "Epoch 36/50\n",
      "1632/1632 [==============================] - 372s 228ms/step - loss: -0.1658 - dice_coef: 0.1658 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0910 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3629 - f1score: 0.1822 - val_loss: -0.1984 - val_dice_coef: 0.1984 - val_acc: 0.7107 - val_mean_squared_error: 0.1606 - val_Jaccard_index: 0.1115 - val_Specificity: 0.9536 - val_Sensitivity: 1.1107 - val_precision: 0.1541 - val_recall: 0.3735 - val_f1score: 0.2162911 - Specificity: 0.9615 - Sensitivity: 1.1184 - precision: 0.1228 - recall: 0.3624 - f1sco - ETA: 45s - loss: -0.1658 - dice_coef: 0.1658 - acc: 0.7150 - mean_squared_error: 0.1603 - Jaccard_index: 0.0910 - Specificity: 0.9615 - ETA: 32s - loss: -0.1657 - dice_coef: 0.1657 - acc: 0.7145 - mean_squared_error: 0.1604 - Jaccard_index: 0.0910 - Specifici - ETA: 17s - loss: -0.1655 - dice_coef: 0.1655 - acc: 0.\n",
      "Epoch 37/50\n",
      "1632/1632 [==============================] - 372s 228ms/step - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0910 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3618 - f1score: 0.1820 - val_loss: -0.1983 - val_dice_coef: 0.1983 - val_acc: 0.7107 - val_mean_squared_error: 0.1606 - val_Jaccard_index: 0.1114 - val_Specificity: 0.9536 - val_Sensitivity: 1.1107 - val_precision: 0.1541 - val_recall: 0.3724 - val_f1score: 0.2160ared_error: 0.1602 - Jaccard_index: 0.0910 - Specificity: 0.9617 - Sensitivity: 1.1185 - precision: 0.1226 - ETA: 7s - loss: -0.1657 - dice_coef: 0.1657 - acc: 0.7145 - mean_squared_error: 0.1603 - Jaccard_index: 0.0910 - Specificit\n",
      "Epoch 38/50\n",
      "1632/1632 [==============================] - 373s 229ms/step - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0909 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3617 - f1score: 0.1820 - val_loss: -0.1983 - val_dice_coef: 0.1983 - val_acc: 0.7107 - val_mean_squared_error: 0.1606 - val_Jaccard_index: 0.1116 - val_Specificity: 0.9536 - val_Sensitivity: 1.1107 - val_precision: 0.1541 - val_recall: 0.3728 - val_f1score: 0.2161\n",
      "Epoch 39/50\n",
      "1632/1632 [==============================] - 370s 227ms/step - loss: -0.1655 - dice_coef: 0.1655 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0909 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3622 - f1score: 0.1819 - val_loss: -0.1454 - val_dice_coef: 0.1454 - val_acc: 0.6115 - val_mean_squared_error: 0.2698 - val_Jaccard_index: 0.0789 - val_Specificity: 0.9551 - val_Sensitivity: 1.2269 - val_precision: 0.0985 - val_recall: 0.4229 - val_f1score: 0.1587\n",
      "Epoch 40/50\n",
      "1632/1632 [==============================] - 370s 227ms/step - loss: -0.1657 - dice_coef: 0.1657 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0909 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3621 - f1score: 0.1821 - val_loss: -0.1490 - val_dice_coef: 0.1490 - val_acc: 0.6227 - val_mean_squared_error: 0.2567 - val_Jaccard_index: 0.0810 - val_Specificity: 0.9549 - val_Sensitivity: 1.2136 - val_precision: 0.1019 - val_recall: 0.4151 - val_f1score: 0.16251658 - acc: 0.7153 - mean_squared_error: 0.1601 - Jacc - ETA: 16s - loss: -0.1660 - dice_coef: 0.1660 - acc: 0.7143 - mean_squared_error: 0.1603 - Jaccard_index: 0.0911 - Specificity: 0.9615 - Sensitivity: 1.1184 - precision: 0.1228 - recall: 0.3622 - ETA: 13s - loss: -0.1659 - dice_coef: 0.1659 - acc: 0.7140 - mean_squared_error: 0.1603 - Jac - ETA: 1s - loss: -0.1657 - dice_coef: 0.1657 - acc: 0.7143 - mean_squared_error: 0.1603 - Jaccard_index: 0.0909 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1226 - recall: 0.3619 -\n",
      "Epoch 41/50\n",
      "1632/1632 [==============================] - 372s 228ms/step - loss: -0.1657 - dice_coef: 0.1657 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0910 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3621 - f1score: 0.1821 - val_loss: -0.1652 - val_dice_coef: 0.1652 - val_acc: 0.6610 - val_mean_squared_error: 0.2136 - val_Jaccard_index: 0.0908 - val_Specificity: 0.9543 - val_Sensitivity: 1.1689 - val_precision: 0.1180 - val_recall: 0.3945 - val_f1score: 0.1802 dice_coef: 0.1645 - acc: 0.7124 - mean_squared_error: 0.1606 - Jacc - ETA: 1:45 - loss: -0.1649 - dice_coef: 0.1649 - acc: 0.7146 - mean_squared_error: 0.1605 - Jaccard_index: 0.0905 - Specificit - ETA: 26s - loss: -0.1657 - dice_coef: 0.1657 - acc: 0.7149 - mean_squared_error: 0.1602 - Jaccard_index: 0.0910 - Specifici - ETA: 11s - loss: -0.1659 - dice_coef: 0.1659 - acc: 0.7141 - mean_squared_error: 0.1602 \n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1632/1632 [==============================] - 374s 229ms/step - loss: -0.1657 - dice_coef: 0.1657 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0910 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3624 - f1score: 0.1821 - val_loss: -0.1765 - val_dice_coef: 0.1765 - val_acc: 0.6814 - val_mean_squared_error: 0.1921 - val_Jaccard_index: 0.0977 - val_Specificity: 0.9540 - val_Sensitivity: 1.1453 - val_precision: 0.1299 - val_recall: 0.3839 - val_f1score: 0.1925r: 0.160 - ETA: 2:12 - loss: -0.1646 - dice_coef: 0.1646 - acc: 0.7157 - mean_squared_error: 0.1604 - Jaccard_index: 0.0903 - Specificity: 0.9617 - Sensit - ETA: 2:07 - loss: -0.1648 - dice_coef: 0.1648 - acc: 0.7154 - mean_squared_error: 0.1603 - Jaccard_index: 0.0905 - Specificity: 0.9617 - Sensitivity: 1.1186 - precision: 0.1220 - recall: 0.36 - ETA: 2:05 - loss: -0.1650 - dice_coef: 0.1650 - acc: 0.7156 - mean_squared_error: 0.1603 - Jaccard_index: 0.0906 - Specif - ETA: 1:57 - loss: -0.1653 - dice_coef: 0.1653 - acc: 0.7157 - mean_squa - ETA: 1:27 - loss: -0.1652 - dice_coef: 0.1652 - acc: 0.7155 - mean_squared_error: 0.1603 - Jaccard_ - ETA: - ETA: 21s - loss: -0.1655 - \n",
      "Epoch 43/50\n",
      "1632/1632 [==============================] - 378s 231ms/step - loss: -0.1655 - dice_coef: 0.1655 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0909 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3619 - f1score: 0.1819 - val_loss: -0.1853 - val_dice_coef: 0.1853 - val_acc: 0.6952 - val_mean_squared_error: 0.1779 - val_Jaccard_index: 0.1032 - val_Specificity: 0.9537 - val_Sensitivity: 1.1289 - val_precision: 0.1395 - val_recall: 0.3785 - val_f1score: 0.2020n_squared_error: 0.1613 - Jaccard_index: 0.0951 - Specificity: 0.9591 - Sensitiv - ETA: 4:03 - loss: -0.1714 - dice_coef: 0.1714 - acc: 0.7202 - mean_squared_error: 0.1612 - Jaccard_index: 0.0944 - Specificity: 0.959 - ETA: 4:02 - loss: -0.1713 - dice_coef: 0.1713 - acc: 0.7197 - mean_squared_error: 0.1606 - Jaccard_index: 0.0944 - Specificity: 0.9604 - Sensitivity: 1.1 - ETA: 3:59 - loss: -0.1711 - dice_coef - ETA: 3:31 - loss: -0.1674 - dice_coef: 0.1674 - acc:  - ETA: 3:19 - loss: -0.1671 - dice_coef: 0.16 - ETA: 3:04 - loss: -0.1673 - dice_coef: 0.1673 - acc: 0.7114 - mean_squared_error: 0.1603 - Jaccard_index: 0.0919 - Specificity: 0.9614 - Sensitivity: 1.1182 - precision: 0.123 - ETA: 2:06 - loss: -0.1661 - dice_coef: 0.1661 - acc: 0.7119 - mean_squared_error: 0.1603 - Jaccard_index: 0.0912 - Specificity: 0.9615 - Sensitivity: 1.118 - ETA: 2:01 - loss: -0.1655 - dice_coef: 0.1655 - acc: 0.7116  - ETA: 43s - loss: -0.1650 - dice_coef: 0.1650 - acc: 0.7129 - mean_squared_error: 0.1602 - Jaccard_index: 0.0906 - Specifi\n",
      "Epoch 44/50\n",
      "1632/1632 [==============================] - 373s 229ms/step - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0909 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3626 - f1score: 0.1821 - val_loss: -0.1906 - val_dice_coef: 0.1906 - val_acc: 0.7017 - val_mean_squared_error: 0.1701 - val_Jaccard_index: 0.1065 - val_Specificity: 0.9537 - val_Sensitivity: 1.1211 - val_precision: 0.1453 - val_recall: 0.3763 - val_f1score: 0.2077\n",
      "Epoch 45/50\n",
      "1632/1632 [==============================] - 372s 228ms/step - loss: -0.1657 - dice_coef: 0.1657 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0910 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3628 - f1score: 0.1821 - val_loss: -0.1894 - val_dice_coef: 0.1894 - val_acc: 0.7003 - val_mean_squared_error: 0.1719 - val_Jaccard_index: 0.1057 - val_Specificity: 0.9537 - val_Sensitivity: 1.1227 - val_precision: 0.1439 - val_recall: 0.3766 - val_f1score: 0.2064\n",
      "Epoch 46/50\n",
      "1632/1632 [==============================] - 373s 229ms/step - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0909 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3618 - f1score: 0.1820 - val_loss: -0.1980 - val_dice_coef: 0.1980 - val_acc: 0.7103 - val_mean_squared_error: 0.1610 - val_Jaccard_index: 0.1112 - val_Specificity: 0.9536 - val_Sensitivity: 1.1113 - val_precision: 0.1537 - val_recall: 0.3727 - val_f1score: 0.2157: 1:54 - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7122 - mean_squared_error: 0.1604 - Jaccard_index: 0.0909 - Specificity: 0.9615 - Sens - ETA:  - ETA: 1:30 - loss: -0.1652 - dice_coef: 0.1652 - acc: 0.7130 - mean_squared_error: 0.1604 - Jaccard_index: 0.0907 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1223 - recall: 0.3607 - f1score - ETA: 1:30 - loss: -0.1652 - dice_coef: 0.1652 - acc: 0.7129 - mean_squared_error: 0.1604 - Jaccard_index: 0.0907 - Spec - ETA: 1:22 - loss: -0.1650 - dice_coef: 0.1650 - acc: 0.7127 - mean_squared_error: 0.1603 - Jaccard_index: 0.0906 - Specific - ETA: 52s - loss: -0.1657 - dice_coef: 0.1657 - acc: 0.7130 - mean_squared_error: 0.1603 - Jaccard_index: 0.0910 -  - ETA: 36s - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7150 - mean_squared_error: 0.1603 - Jaccard_index: 0.0910 -  - ETA: 19s - loss: -0.1658 - dice_coef: 0.1658 - acc: 0.7147 - mean_squared_error: 0.1603 - Jaccard_index: 0.0910 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1227 - recall: 0.3621  - ETA: 16s - loss: -0.1657 - dice_coef: 0.1657 - acc: 0.7147 - mea - ETA: 0s - loss: -0.1657 - dice_coef: 0.1657 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0910 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1226 - recall: 0.3619 - f1score\n",
      "Epoch 47/50\n",
      "1632/1632 [==============================] - 371s 227ms/step - loss: -0.1657 - dice_coef: 0.1657 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0910 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3624 - f1score: 0.1821 - val_loss: -0.1974 - val_dice_coef: 0.1974 - val_acc: 0.7099 - val_mean_squared_error: 0.1614 - val_Jaccard_index: 0.1110 - val_Specificity: 0.9536 - val_Sensitivity: 1.1117 - val_precision: 0.1534 - val_recall: 0.3715 - val_f1score: 0.2152error: 0.1603 - Jaccard_index: 0.0909 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3623 - f1score: 0.18 - ETA: 9s - loss: -0.1657 - dice_coef: 0.1657 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard\n",
      "Epoch 48/50\n",
      "1632/1632 [==============================] - 374s 229ms/step - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0909 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3622 - f1score: 0.1821 - val_loss: -0.1978 - val_dice_coef: 0.1978 - val_acc: 0.7101 - val_mean_squared_error: 0.1613 - val_Jaccard_index: 0.1111 - val_Specificity: 0.9536 - val_Sensitivity: 1.1115 - val_precision: 0.1535 - val_recall: 0.3727 - val_f1score: 0.2155d_error: 0.1602 - Jaccard_index: 0.0908 - Specificity: 0.9617 - Sens - ETA: 1:47 - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7150 - mean_squared_error: 0.1602 - Jaccard_index: 0.0909 - Specificity: 0.9618 - Sensitivity: 1.1186 - precision: 0.1222 - recall: 0.3628 - f1sco - - ETA: 42s - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0909 - Specificity\n",
      "Epoch 49/50\n",
      "1632/1632 [==============================] - 372s 228ms/step - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7143 - mean_squared_error: 0.1603 - Jaccard_index: 0.0909 - Specificity: 0.9616 - Sensitivity: 1.1186 - precision: 0.1225 - recall: 0.3629 - f1score: 0.1821 - val_loss: -0.1872 - val_dice_coef: 0.1872 - val_acc: 0.6973 - val_mean_squared_error: 0.1745 - val_Jaccard_index: 0.1045 - val_Specificity: 0.9538 - val_Sensitivity: 1.1263 - val_precision: 0.1417 - val_recall: 0.3777 - val_f1score: 0.2039 -0.1656 - dice_coef: 0.1656 - acc: 0.7139 - mean_squared_error: 0.1604\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1632/1632 [==============================] - 371s 227ms/step - loss: -0.1656 - dice_coef: 0.1656 - acc: 0.7144 - mean_squared_error: 0.1603 - Jaccard_index: 0.0910 - Specificity: 0.9616 - Sensitivity: 1.1185 - precision: 0.1225 - recall: 0.3622 - f1score: 0.1820 - val_loss: -0.1868 - val_dice_coef: 0.1868 - val_acc: 0.6963 - val_mean_squared_error: 0.1756 - val_Jaccard_index: 0.1041 - val_Specificity: 0.9538 - val_Sensitivity: 1.1274 - val_precision: 0.1408 - val_recall: 0.3785 - val_f1score: 0.2035\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=nb_train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = validation_generator,\n",
    "                    validation_steps = nb_validation_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Score:  -0.1943027137219906\n",
      "Validation Accuracy:  0.1943027137219906\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate_generator(validation_generator, steps=50)\n",
    "\n",
    "print ('Validation Score: ', score[0])\n",
    "print ('Validation Accuracy: ',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 178ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict_generator(test_generator, verbose=1, steps=nb_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392, 256, 256, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'dice_coef', 'acc', 'mean_squared_error', 'Jaccard_index', 'Specificity', 'Sensitivity', 'precision', 'recall', 'f1score']\n",
      "[-0.1855670329289777, 0.18556703312056405, 0.8219895730699812, 0.17691566228866576, 0.10298631981015205, 0.9604331489971706, 1.1338796697344098, 0.12053534224629402, 0.40973154510770526, 0.1855287206385817]\n"
     ]
    }
   ],
   "source": [
    "test_results = model.evaluate_generator(test_generator, steps=50)\n",
    "\n",
    "print(model.metrics_names)\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training co-effiency    : 0.09101687830772397;\n",
      "Validation co-effiency : 0.11224776216926437\n"
     ]
    }
   ],
   "source": [
    "coef = np.array(history.history['Jaccard_index'])\n",
    "val_coef = np.array(history.history['val_Jaccard_index'])\n",
    "print(\"Training co-effiency    : {};\\nValidation co-effiency : {}\".format(coef[coef==max(coef)][0], val_coef[np.argmax(coef)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "\n",
    "def labelVisualize(num_class,color_dict,img):\n",
    "    img = img[:,:,0] if len(img.shape) == 3 else img\n",
    "    img_out = np.zeros(img.shape + (3,))\n",
    "    for i in range(num_class):\n",
    "        img_out[img == i,:] = color_dict[i]\n",
    "    return img_out / 255\n",
    "\n",
    "def saveResult(save_path,npyfile,flag_multi_class = False,num_class = 2):\n",
    "    for i,item in enumerate(npyfile):\n",
    "        img = labelVisualize(num_class,COLOR_DICT,item) if flag_multi_class else item[:,:,0]\n",
    "        io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
    "\n",
    "os.mkdir('05.U-Net2_results_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveResult('05.U-Net2_results_dir',prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeData(img,mask):\n",
    "    mean = np.mean(img)\n",
    "    std = np.std(img)\n",
    "    img -= mean\n",
    "    img /= std\n",
    "    mask = mask /255\n",
    "    mask[mask > 0.5] = 1\n",
    "    mask[mask <= 0.5] = 0\n",
    "    return (img,mask)\n",
    "\n",
    "test_data_dir= \"data_augmented/cvc300_test/images/\"\n",
    "test_data_mask_dir = \"data_augmented/cvc300_test/masks/\"\n",
    "test_data_pred_dir = \"05.U-Net2_results_dir\"\n",
    "img_rows, img_cols = 256, 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image as image_utils\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img\n",
    "\n",
    "file_names = next(os.walk(test_data_dir))[2]\n",
    "scores = []\n",
    "for file in file_names:\n",
    "    grey_img = load_img(os.path.join(test_data_dir,file), target_size=(img_rows, img_cols), grayscale=False)\n",
    "    mask_img = load_img(os.path.join(test_data_mask_dir,file), target_size=(img_rows, img_cols), grayscale=True)\n",
    "    img = img_to_array(grey_img)\n",
    "    img_mask = img_to_array(mask_img)\n",
    "    \n",
    "    img, img_mask = normalizeData(img, img_mask)\n",
    "    img = np.reshape(img,(1,)+img.shape)\n",
    "    \n",
    "    pred = model.predict([img])\n",
    "    sess = tf.Session()\n",
    "    score = sess.run(Jaccard_index(img_mask, pred))\n",
    "    print(\"{} -- jaccard index: {}\".format(file,score))\n",
    "    scores.append([file,score])\n",
    "\n",
    "    result_img = array_to_img(pred[0] * 255 )\n",
    "    result_img.save(os.path.join(test_data_pred_dir, file.split('.')[0] + '_predict.jpg'))\n",
    "\n",
    "with open(\"unet_test_result.csv\", 'w') as f:\n",
    "    f.write(\"filename, jaccard_index\\n\")\n",
    "    for i in range(len(scores)):\n",
    "        #print(scores[i])\n",
    "        f.write(\"{},{}\\n\".format(scores[i][0], scores[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img=mpimg.imread('05.U-Net2_results_dir/102_predict.png')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(prediction[1]), cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(prediction[1]), cmap = \"gray\", vmin = 0.0, vmax= 0.09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ =  np.squeeze(np.multiply(prediction[1], 255))\n",
    "print(results_)\n",
    "\n",
    "plt.imshow(results_, cmap = \"gray\", vmin = 0.0, vmax= 0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img=mpimg.imread('05.U-Net2_results_dir/35_predict.png')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['dice_coef'])\n",
    "plt.plot(history.history['val_dice_coef'])\n",
    "plt.title('model dice_coeff')\n",
    "plt.ylabel('dice_coef')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
