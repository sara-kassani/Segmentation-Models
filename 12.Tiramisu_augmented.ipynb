{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 1958208146573307520, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 9214062756\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 8095788695790984428\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras import layers, metrics, models, optimizers\n",
    "from keras.optimizers import Adam, RMSprop,SGD\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, concatenate, Flatten, Dense, Activation, Dropout, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Version 2.2.4\n",
      "tensorflow Version 1.9.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Keras Version\", keras.__version__)\n",
    "print(\"tensorflow Version\", tf.__version__)\n",
    "# print(\"dim_ordering:\", K.image_dim_ordering())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "img_rows, img_cols = 256, 256\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "epochs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data_augmented/cvc300_train/'\n",
    "validation_dir = 'data_augmented/cvc300_validation/'\n",
    "test_dir = 'data_augmented/cvc300_test/'\n",
    "\n",
    "image_folder = 'images'\n",
    "masks_folder = 'masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "def Tiramisu(img_size):\n",
    "    inp = Input(shape=(img_size, img_size, 3))\n",
    "\n",
    "    x = Conv2D(48, kernel_size=(3, 3), padding='same',\n",
    "               input_shape=(img_size, img_size, 3),\n",
    "               kernel_initializer=\"he_uniform\",\n",
    "               kernel_regularizer=l2(0.0001))(inp)\n",
    "    # (5 * 4)* 2 + 5 + 5 + 1 + 1 +1\n",
    "    # growth_m = 4 * 12\n",
    "    # previous_m = 48\n",
    "\n",
    "    x = _denseBlock(x, 4, 96) # 4*12 = 48 + 48 = 96\n",
    "    x = _transitionDown(x, 96)\n",
    "    x = _denseBlock(x, 4, 144) # 4*12 = 48 + 96 = 144\n",
    "    x = _transitionDown(x, 144)\n",
    "    x = _denseBlock(x, 4, 192) # 4*12 = 48 + 144 = 192\n",
    "    x = _transitionDown(x, 192)\n",
    "    x = _denseBlock(x, 4, 240)# 4*12 = 48 + 192 = 240\n",
    "    x = _transitionDown(x, 240)\n",
    "    x = _denseBlock(x, 4, 288) # 4*12 = 48 + 288 = 336\n",
    "    x = _transitionDown(x, 288)\n",
    "\n",
    "    x = _denseBlock(x, 15, 336) # 4 * 12 = 48 + 288 = 336\n",
    "\n",
    "    x = _transitionUp(x, 384)  # m = 288 + 4x12 + 4x12 = 384.\n",
    "    x = _denseBlock(x, 4, 384)\n",
    "\n",
    "    x = _transitionUp(x, 336) #m = 240 + 4x12 + 4x12 = 336\n",
    "    x = _denseBlock(x, 4, 336)\n",
    "\n",
    "    x = _transitionUp(x, 288) # m = 192 + 4x12 + 4x12 = 288\n",
    "    x = _denseBlock(x, 4, 288)\n",
    "\n",
    "    x = _transitionUp(x, 240) # m = 144 + 4x12 + 4x12 = 240\n",
    "    x = _denseBlock(x, 4, 240)\n",
    "\n",
    "    x = _transitionUp(x, 192) # m = 96 + 4x12 + 4x12 = 192\n",
    "    x = _denseBlock(x, 4, 192)\n",
    "\n",
    "    x = Conv2D(1, kernel_size=(1, 1), padding='same',\n",
    "              kernel_initializer=\"he_uniform\",\n",
    "              kernel_regularizer=l2(0.0001))(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def _denseBlock(x, layers, filters):\n",
    "    for i in range(layers):\n",
    "        x = BatchNormalization(gamma_regularizer=l2(0.0001),\n",
    "                               beta_regularizer=l2(0.0001))(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv2D(filters, (3, 3), padding='same',\n",
    "                   kernel_initializer=\"he_uniform\")(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def _transitionDown(x, filters):\n",
    "    x = BatchNormalization(gamma_regularizer=l2(0.0001),\n",
    "                           beta_regularizer=l2(0.0001))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters, (1, 1), padding='same',\n",
    "               kernel_initializer=\"he_uniform\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def _transitionUp(x, filters):\n",
    "    x = Conv2DTranspose(filters, (3, 3), strides=(2, 2), padding='same',\n",
    "                        kernel_initializer=\"he_uniform\")(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26112 images belonging to 1 classes.\n",
      "Found 26112 images belonging to 1 classes.\n",
      "Found 8704 images belonging to 1 classes.\n",
      "Found 8704 images belonging to 1 classes.\n",
      "Found 28 images belonging to 1 classes.\n",
      "Found 28 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "seed = 1142\n",
    "data_gen_args = dict(rescale=1. / 255, featurewise_center=True, featurewise_std_normalization=True)\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "masks_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "image_generator = image_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    classes = [image_folder],\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "mask_generator = masks_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    classes = [masks_folder],\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "validation_image_generator = image_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    classes = [image_folder],\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "validation_mask_generator = masks_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    classes = [masks_folder],\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "test_image_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    classes = [image_folder],\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "test_mask_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    classes = [masks_folder],\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = zip(image_generator, mask_generator)\n",
    "validation_generator = zip(validation_image_generator, validation_mask_generator)\n",
    "test_generator = zip(test_image_generator, test_mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_train_samples: 26112\n",
      "nb_validation_samples: 8704\n",
      "nb_test_samples: 28\n",
      "\n",
      "predict_size_train: 13056\n",
      "predict_size_validation: 4352\n",
      "predict_size_test: 14\n"
     ]
    }
   ],
   "source": [
    "nb_train_samples = len(image_generator.filenames)\n",
    "nb_validation_samples = len(validation_image_generator.filenames)\n",
    "nb_test_samples = len(test_image_generator.filenames)\n",
    "\n",
    "predict_size_train = int(math.ceil(nb_train_samples / batch_size))\n",
    "predict_size_validation = int(math.ceil(nb_validation_samples / batch_size))\n",
    "predict_size_test = int(math.ceil(nb_test_samples / batch_size))\n",
    "\n",
    "print(\"nb_train_samples:\", nb_train_samples)\n",
    "print(\"nb_validation_samples:\", nb_validation_samples)\n",
    "print(\"nb_test_samples:\", nb_test_samples)\n",
    "\n",
    "print(\"\\npredict_size_train:\", predict_size_train)\n",
    "print(\"predict_size_validation:\", predict_size_validation)\n",
    "print(\"predict_size_test:\", predict_size_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 1.\n",
    "from keras import backend as K\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def Specificity(y_true, y_pred):\n",
    "    true_negatives = K.abs(y_pred)- K.abs(y_true)\n",
    "    return ((true_negatives+smooth)/(y_pred+ smooth))\n",
    "\n",
    "def Sensitivity(y_true, y_pred):\n",
    "    y_true = K.flatten(y_true)\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    return ((y_pred+smooth)/ (y_true+smooth))\n",
    "\n",
    "def Jaccard_index(y_true,y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return ((intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + smooth))\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "    Only computes a batch-wise average of precision.\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "    Only computes a batch-wise average of recall.\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def f1score(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "        Only computes a batch-wise average of recall.\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "        Only computes a batch-wise average of precision.\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 256, 256, 48)      1344      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256, 256, 48)      192       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256, 256, 48)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 256, 256, 96)      41568     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256, 256, 96)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256, 256, 96)      384       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 256, 256, 96)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 256, 256, 96)      83040     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256, 256, 96)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256, 256, 96)      384       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 256, 256, 96)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 256, 256, 96)      83040     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256, 256, 96)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 256, 256, 96)      384       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 256, 256, 96)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 256, 256, 96)      83040     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256, 256, 96)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256, 256, 96)      384       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256, 256, 96)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 256, 256, 96)      9312      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256, 256, 96)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 128, 128, 96)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 128, 128, 96)      384       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 128, 128, 96)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 128, 128, 144)     124560    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128, 128, 144)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 128, 128, 144)     576       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128, 128, 144)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 128, 128, 144)     186768    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128, 128, 144)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 128, 128, 144)     576       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 128, 128, 144)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 128, 128, 144)     186768    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128, 128, 144)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 128, 128, 144)     576       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 128, 128, 144)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 128, 128, 144)     186768    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128, 128, 144)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 128, 128, 144)     576       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 128, 128, 144)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 128, 128, 144)     20880     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128, 128, 144)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 64, 64, 144)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 64, 64, 144)       576       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 64, 64, 144)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 64, 64, 192)       249024    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 64, 64, 192)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 64, 64, 192)       768       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 64, 64, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 64, 64, 192)       331968    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64, 64, 192)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 64, 64, 192)       768       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 64, 64, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 64, 64, 192)       331968    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 64, 64, 192)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 64, 64, 192)       768       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 64, 64, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 64, 64, 192)       331968    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 64, 64, 192)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 64, 64, 192)       768       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 64, 64, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 64, 64, 192)       37056     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 64, 64, 192)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 32, 32, 192)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 32, 32, 192)       768       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 32, 32, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 32, 32, 240)       414960    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 32, 32, 240)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 32, 32, 240)       960       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 32, 32, 240)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 32, 32, 240)       518640    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 32, 32, 240)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 32, 32, 240)       960       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 32, 32, 240)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 32, 32, 240)       518640    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 32, 32, 240)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 32, 32, 240)       960       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 32, 32, 240)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 32, 32, 240)       518640    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 32, 32, 240)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 32, 32, 240)       960       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 32, 32, 240)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 32, 32, 240)       57840     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 32, 32, 240)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 240)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 16, 16, 240)       960       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16, 16, 240)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 16, 16, 288)       622368    \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 16, 16, 288)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 16, 16, 288)       1152      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16, 16, 288)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 16, 16, 288)       746784    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 16, 16, 288)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 16, 16, 288)       1152      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 16, 16, 288)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 16, 16, 288)       746784    \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 16, 16, 288)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 16, 16, 288)       1152      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 16, 16, 288)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 16, 16, 288)       746784    \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 16, 16, 288)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 16, 16, 288)       1152      \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 16, 16, 288)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 16, 16, 288)       83232     \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 16, 16, 288)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 288)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 8, 8, 288)         1152      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 8, 8, 288)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 8, 8, 336)         871248    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 8, 8, 336)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 8, 8, 336)         1344      \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 8, 8, 336)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 8, 8, 336)         1016400   \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 8, 8, 336)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 8, 8, 336)         1344      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 8, 8, 336)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 8, 8, 336)         1016400   \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 8, 8, 336)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 8, 8, 336)         1344      \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 8, 8, 336)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 8, 8, 336)         1016400   \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 8, 8, 336)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 8, 8, 336)         1344      \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 8, 8, 336)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 8, 8, 336)         1016400   \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 8, 8, 336)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 8, 8, 336)         1344      \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 8, 8, 336)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 8, 8, 336)         1016400   \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 8, 8, 336)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 8, 8, 336)         1344      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 8, 8, 336)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 8, 8, 336)         1016400   \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 8, 8, 336)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 8, 8, 336)         1344      \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 8, 8, 336)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 8, 8, 336)         1016400   \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 8, 8, 336)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 8, 8, 336)         1344      \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 8, 8, 336)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 8, 8, 336)         1016400   \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 8, 8, 336)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 8, 8, 336)         1344      \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 8, 8, 336)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 8, 8, 336)         1016400   \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 8, 8, 336)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 8, 8, 336)         1344      \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 8, 8, 336)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 8, 8, 336)         1016400   \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 8, 8, 336)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 8, 8, 336)         1344      \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 8, 8, 336)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 8, 8, 336)         1016400   \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 8, 8, 336)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 8, 8, 336)         1344      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 8, 8, 336)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 8, 8, 336)         1016400   \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 8, 8, 336)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 8, 8, 336)         1344      \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 8, 8, 336)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 8, 8, 336)         1016400   \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 8, 8, 336)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 8, 8, 336)         1344      \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 8, 8, 336)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 8, 8, 336)         1016400   \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 8, 8, 336)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 16, 16, 384)       1161600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 16, 16, 384)       1536      \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 16, 16, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 16, 16, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 16, 16, 384)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 16, 16, 384)       1536      \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 16, 16, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 16, 16, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 16, 16, 384)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 16, 16, 384)       1536      \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 16, 16, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 16, 16, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 16, 16, 384)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 16, 16, 384)       1536      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 16, 16, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 16, 16, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 16, 16, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 32, 32, 336)       1161552   \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 32, 32, 336)       1344      \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 32, 32, 336)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 32, 32, 336)       1016400   \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 32, 32, 336)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 32, 32, 336)       1344      \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 32, 32, 336)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 32, 32, 336)       1016400   \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 32, 32, 336)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 32, 32, 336)       1344      \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 32, 32, 336)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 32, 32, 336)       1016400   \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 32, 32, 336)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 32, 32, 336)       1344      \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 32, 32, 336)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 32, 32, 336)       1016400   \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 32, 32, 336)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 64, 64, 288)       871200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 64, 64, 288)       1152      \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 64, 64, 288)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 64, 64, 288)       746784    \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 64, 64, 288)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 64, 64, 288)       1152      \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 64, 64, 288)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 64, 64, 288)       746784    \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 64, 64, 288)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 64, 64, 288)       1152      \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 64, 64, 288)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 64, 64, 288)       746784    \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 64, 64, 288)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 64, 64, 288)       1152      \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 64, 64, 288)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 64, 64, 288)       746784    \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 64, 64, 288)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 128, 128, 240)     622320    \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 128, 128, 240)     960       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 128, 128, 240)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 128, 128, 240)     518640    \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 128, 128, 240)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 128, 128, 240)     960       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 128, 128, 240)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 128, 128, 240)     518640    \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 128, 128, 240)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 128, 128, 240)     960       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 128, 128, 240)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 128, 128, 240)     518640    \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 128, 128, 240)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 128, 128, 240)     960       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 128, 128, 240)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 128, 128, 240)     518640    \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 128, 128, 240)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 256, 256, 192)     414912    \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 256, 256, 192)     768       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 256, 256, 192)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 256, 256, 192)     331968    \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 256, 256, 192)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 256, 256, 192)     768       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 256, 256, 192)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 256, 256, 192)     331968    \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 256, 256, 192)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 256, 256, 192)     768       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 256, 256, 192)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 256, 256, 192)     331968    \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 256, 256, 192)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 256, 256, 192)     768       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 256, 256, 192)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 256, 256, 192)     331968    \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 256, 256, 192)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 256, 256, 1)       193       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 256, 256, 1)       0         \n",
      "=================================================================\n",
      "Total params: 42,422,737\n",
      "Trainable params: 42,392,113\n",
      "Non-trainable params: 30,624\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Tiramisu(img_size = 256)\n",
    "model.summary()\n",
    "adam_opt = Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(optimizer= adam_opt, loss=dice_coef_loss, \n",
    "              metrics=[dice_coef, 'acc','mse', Jaccard_index, Specificity, Sensitivity, precision, recall, f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "13056/13056 [==============================] - 5523s 423ms/step - loss: 1.3301 - dice_coef: 0.1601 - acc: 0.7135 - mean_squared_error: 0.1586 - Jaccard_index: 0.0922 - Specificity: 0.9619 - Sensitivity: 1.1225 - precision: 0.1191 - recall: 0.3659 - f1score: nan - val_loss: 1.4365 - val_dice_coef: 2.1894e-04 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 2.1517e-04 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 2/150\n",
      "13056/13056 [==============================] - 5493s 421ms/step - loss: 1.2070 - dice_coef: 0.1689 - acc: 0.7047 - mean_squared_error: 0.1694 - Jaccard_index: 0.0974 - Specificity: 0.9628 - Sensitivity: 1.1331 - precision: 0.1244 - recall: 0.4129 - f1score: nan - val_loss: 1.3125 - val_dice_coef: 2.1182e-04 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 2.1093e-04 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 3/150\n",
      "13056/13056 [==============================] - 5493s 421ms/step - loss: 1.0709 - dice_coef: 0.1772 - acc: 0.7036 - mean_squared_error: 0.1709 - Jaccard_index: 0.1026 - Specificity: 0.9635 - Sensitivity: 1.1360 - precision: 0.1306 - recall: 0.4347 - f1score: nan - val_loss: 1.1853 - val_dice_coef: 2.1889e-04 - val_acc: 0.8176 - val_mean_squared_error: 0.0500 - val_Jaccard_index: 2.1501e-04 - val_Specificity: 0.9431 - val_Sensitivity: 0.9693 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: nan\n",
      "Epoch 4/150\n",
      "13056/13056 [==============================] - 5507s 422ms/step - loss: 0.9210 - dice_coef: 0.2123 - acc: 0.7358 - mean_squared_error: 0.1336 - Jaccard_index: 0.1277 - Specificity: 0.9634 - Sensitivity: 1.0983 - precision: 0.1719 - recall: 0.4156 - f1score: nan - val_loss: 0.9250 - val_dice_coef: 0.1614 - val_acc: 0.7561 - val_mean_squared_error: 0.1123 - val_Jaccard_index: 0.0960 - val_Specificity: 0.9496 - val_Sensitivity: 1.0514 - val_precision: 0.1631 - val_recall: 0.2317 - val_f1score: nan\n",
      "Epoch 5/150\n",
      "13056/13056 [==============================] - 5513s 422ms/step - loss: 0.7348 - dice_coef: 0.3147 - acc: 0.7848 - mean_squared_error: 0.0775 - Jaccard_index: 0.2015 - Specificity: 0.9637 - Sensitivity: 1.0425 - precision: 0.3052 - recall: 0.4428 - f1score: nan - val_loss: 0.8551 - val_dice_coef: 0.1610 - val_acc: 0.7103 - val_mean_squared_error: 0.1620 - val_Jaccard_index: 0.0946 - val_Specificity: 0.9521 - val_Sensitivity: 1.1084 - val_precision: 0.1348 - val_recall: 0.3217 - val_f1score: nan\n",
      "Epoch 6/150\n",
      "13056/13056 [==============================] - 5509s 422ms/step - loss: 0.5817 - dice_coef: 0.4059 - acc: 0.8038 - mean_squared_error: 0.0548 - Jaccard_index: 0.2704 - Specificity: 0.9645 - Sensitivity: 1.0221 - precision: 0.4315 - recall: 0.5062 - f1score: nan - val_loss: 0.8155 - val_dice_coef: 0.1454 - val_acc: 0.7528 - val_mean_squared_error: 0.1169 - val_Jaccard_index: 0.0849 - val_Specificity: 0.9490 - val_Sensitivity: 1.0543 - val_precision: 0.1435 - val_recall: 0.2143 - val_f1score: nan\n",
      "Epoch 7/150\n",
      "13056/13056 [==============================] - 5507s 422ms/step - loss: 0.4733 - dice_coef: 0.4643 - acc: 0.8100 - mean_squared_error: 0.0468 - Jaccard_index: 0.3189 - Specificity: 0.9656 - Sensitivity: 1.0170 - precision: 0.5037 - recall: 0.5615 - f1score: nan - val_loss: 0.7300 - val_dice_coef: 0.1856 - val_acc: 0.7642 - val_mean_squared_error: 0.1028 - val_Jaccard_index: 0.1114 - val_Specificity: 0.9504 - val_Sensitivity: 1.0449 - val_precision: 0.1927 - val_recall: 0.2569 - val_f1score: nan\n",
      "Epoch 8/150\n",
      "13056/13056 [==============================] - 5498s 421ms/step - loss: 0.3841 - dice_coef: 0.5128 - acc: 0.8145 - mean_squared_error: 0.0408 - Jaccard_index: 0.3620 - Specificity: 0.9666 - Sensitivity: 1.0140 - precision: 0.5608 - recall: 0.6057 - f1score: nan - val_loss: 0.6715 - val_dice_coef: 0.2085 - val_acc: 0.7644 - val_mean_squared_error: 0.1019 - val_Jaccard_index: 0.1261 - val_Specificity: 0.9514 - val_Sensitivity: 1.0473 - val_precision: 0.2116 - val_recall: 0.3031 - val_f1score: nan\n",
      "Epoch 9/150\n",
      "13056/13056 [==============================] - 5497s 421ms/step - loss: 0.2979 - dice_coef: 0.5678 - acc: 0.8187 - mean_squared_error: 0.0347 - Jaccard_index: 0.4130 - Specificity: 0.9678 - Sensitivity: 1.0117 - precision: 0.6233 - recall: 0.6552 - f1score: nan - val_loss: 0.6903 - val_dice_coef: 0.1618 - val_acc: 0.7961 - val_mean_squared_error: 0.0690 - val_Jaccard_index: 0.0963 - val_Specificity: 0.9478 - val_Sensitivity: 1.0057 - val_precision: 0.2447 - val_recall: 0.1630 - val_f1score: nan\n",
      "Epoch 10/150\n",
      "13056/13056 [==============================] - 5498s 421ms/step - loss: 0.2197 - dice_coef: 0.6202 - acc: 0.8226 - mean_squared_error: 0.0291 - Jaccard_index: 0.4653 - Specificity: 0.9690 - Sensitivity: 1.0096 - precision: 0.6833 - recall: 0.6995 - f1score: nan - val_loss: 0.7102 - val_dice_coef: 0.1180 - val_acc: 0.8106 - val_mean_squared_error: 0.0553 - val_Jaccard_index: 0.0712 - val_Specificity: 0.9458 - val_Sensitivity: 0.9840 - val_precision: 0.2345 - val_recall: 0.1013 - val_f1score: nan\n",
      "Epoch 11/150\n",
      "13056/13056 [==============================] - 5498s 421ms/step - loss: 0.1511 - dice_coef: 0.6662 - acc: 0.8260 - mean_squared_error: 0.0242 - Jaccard_index: 0.5144 - Specificity: 0.9701 - Sensitivity: 1.0077 - precision: 0.7375 - recall: 0.7352 - f1score: nan - val_loss: 0.5937 - val_dice_coef: 0.2127 - val_acc: 0.7697 - val_mean_squared_error: 0.0953 - val_Jaccard_index: 0.1291 - val_Specificity: 0.9511 - val_Sensitivity: 1.0401 - val_precision: 0.2230 - val_recall: 0.2946 - val_f1score: nan\n",
      "Epoch 12/150\n",
      "13056/13056 [==============================] - 5499s 421ms/step - loss: 0.0918 - dice_coef: 0.7039 - acc: 0.8287 - mean_squared_error: 0.0205 - Jaccard_index: 0.5564 - Specificity: 0.9709 - Sensitivity: 1.0065 - precision: 0.7800 - recall: 0.7679 - f1score: nan - val_loss: 0.6733 - val_dice_coef: 0.1118 - val_acc: 0.8079 - val_mean_squared_error: 0.0580 - val_Jaccard_index: 0.0679 - val_Specificity: 0.9456 - val_Sensitivity: 0.9858 - val_precision: 0.2263 - val_recall: 0.1040 - val_f1score: nan\n",
      "Epoch 13/150\n",
      "13056/13056 [==============================] - 5498s 421ms/step - loss: 0.0446 - dice_coef: 0.7301 - acc: 0.8303 - mean_squared_error: 0.0182 - Jaccard_index: 0.5867 - Specificity: 0.9715 - Sensitivity: 1.0058 - precision: 0.8077 - recall: 0.7910 - f1score: nan - val_loss: 0.5580 - val_dice_coef: 0.2063 - val_acc: 0.8002 - val_mean_squared_error: 0.0631 - val_Jaccard_index: 0.1273 - val_Specificity: 0.9491 - val_Sensitivity: 1.0035 - val_precision: 0.3201 - val_recall: 0.2139 - val_f1score: nan\n",
      "Epoch 14/150\n",
      "13056/13056 [==============================] - 5502s 421ms/step - loss: 0.0068 - dice_coef: 0.7478 - acc: 0.8312 - mean_squared_error: 0.0167 - Jaccard_index: 0.6085 - Specificity: 0.9720 - Sensitivity: 1.0056 - precision: 0.8249 - recall: 0.8098 - f1score: nan - val_loss: 0.6505 - val_dice_coef: 0.0940 - val_acc: 0.8105 - val_mean_squared_error: 0.0546 - val_Jaccard_index: 0.0555 - val_Specificity: 0.9452 - val_Sensitivity: 0.9850 - val_precision: 0.2074 - val_recall: 0.0878 - val_f1score: nan\n",
      "Epoch 15/150\n",
      "13056/13056 [==============================] - 5533s 424ms/step - loss: -0.0312 - dice_coef: 0.7655 - acc: 0.8323 - mean_squared_error: 0.0151 - Jaccard_index: 0.6302 - Specificity: 0.9724 - Sensitivity: 1.0052 - precision: 0.8424 - recall: 0.8280 - f1score: nan - val_loss: 0.4975 - val_dice_coef: 0.2265 - val_acc: 0.7730 - val_mean_squared_error: 0.0909 - val_Jaccard_index: 0.1399 - val_Specificity: 0.9515 - val_Sensitivity: 1.0367 - val_precision: 0.2537 - val_recall: 0.3157 - val_f1score: nan\n",
      "Epoch 16/150\n",
      "13056/13056 [==============================] - 5545s 425ms/step - loss: -0.0648 - dice_coef: 0.7781 - acc: 0.8330 - mean_squared_error: 0.0139 - Jaccard_index: 0.6460 - Specificity: 0.9727 - Sensitivity: 1.0050 - precision: 0.8557 - recall: 0.8407 - f1score: nan - val_loss: 0.4495 - val_dice_coef: 0.2533 - val_acc: 0.7798 - val_mean_squared_error: 0.0837 - val_Jaccard_index: 0.1587 - val_Specificity: 0.9517 - val_Sensitivity: 1.0294 - val_precision: 0.2980 - val_recall: 0.3295 - val_f1score: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/150\n",
      "13056/13056 [==============================] - 5544s 425ms/step - loss: -0.0972 - dice_coef: 0.7889 - acc: 0.8336 - mean_squared_error: 0.0130 - Jaccard_index: 0.6600 - Specificity: 0.9730 - Sensitivity: 1.0049 - precision: 0.8656 - recall: 0.8528 - f1score: nan - val_loss: 0.5332 - val_dice_coef: 0.1479 - val_acc: 0.7776 - val_mean_squared_error: 0.0846 - val_Jaccard_index: 0.0874 - val_Specificity: 0.9478 - val_Sensitivity: 1.0241 - val_precision: 0.1925 - val_recall: 0.1701 - val_f1score: nan\n",
      "Epoch 18/150\n",
      "13056/13056 [==============================] - 5551s 425ms/step - loss: -0.1283 - dice_coef: 0.7986 - acc: 0.8341 - mean_squared_error: 0.0123 - Jaccard_index: 0.6727 - Specificity: 0.9732 - Sensitivity: 1.0047 - precision: 0.8756 - recall: 0.8626 - f1score: nan - val_loss: 0.4295 - val_dice_coef: 0.2299 - val_acc: 0.7655 - val_mean_squared_error: 0.0995 - val_Jaccard_index: 0.1421 - val_Specificity: 0.9521 - val_Sensitivity: 1.0479 - val_precision: 0.2402 - val_recall: 0.3327 - val_f1score: nan\n",
      "Epoch 19/150\n",
      "13056/13056 [==============================] - 5553s 425ms/step - loss: -0.1589 - dice_coef: 0.8070 - acc: 0.8346 - mean_squared_error: 0.0115 - Jaccard_index: 0.6838 - Specificity: 0.9734 - Sensitivity: 1.0045 - precision: 0.8834 - recall: 0.8721 - f1score: nan - val_loss: 0.4819 - val_dice_coef: 0.1551 - val_acc: 0.8163 - val_mean_squared_error: 0.0485 - val_Jaccard_index: 0.1000 - val_Specificity: 0.9461 - val_Sensitivity: 0.9795 - val_precision: 0.3711 - val_recall: 0.1280 - val_f1score: nan\n",
      "Epoch 20/150\n",
      "13056/13056 [==============================] - 5547s 425ms/step - loss: -0.1870 - dice_coef: 0.8133 - acc: 0.8349 - mean_squared_error: 0.0110 - Jaccard_index: 0.6925 - Specificity: 0.9735 - Sensitivity: 1.0044 - precision: 0.8894 - recall: 0.8788 - f1score: 0.8811 - val_loss: 0.3928 - val_dice_coef: 0.2233 - val_acc: 0.8080 - val_mean_squared_error: 0.0550 - val_Jaccard_index: 0.1390 - val_Specificity: 0.9488 - val_Sensitivity: 0.9975 - val_precision: 0.4012 - val_recall: 0.2282 - val_f1score: nan\n",
      "Epoch 21/150\n",
      "13056/13056 [==============================] - 5551s 425ms/step - loss: -0.2137 - dice_coef: 0.8189 - acc: 0.8352 - mean_squared_error: 0.0105 - Jaccard_index: 0.7002 - Specificity: 0.9737 - Sensitivity: 1.0043 - precision: 0.8956 - recall: 0.8845 - f1score: 0.8874 - val_loss: 0.3993 - val_dice_coef: 0.1948 - val_acc: 0.8176 - val_mean_squared_error: 0.0456 - val_Jaccard_index: 0.1265 - val_Specificity: 0.9473 - val_Sensitivity: 0.9833 - val_precision: 0.4322 - val_recall: 0.1796 - val_f1score: nan\n",
      "Epoch 22/150\n",
      "13056/13056 [==============================] - 5544s 425ms/step - loss: -0.2418 - dice_coef: 0.8247 - acc: 0.8355 - mean_squared_error: 0.0101 - Jaccard_index: 0.7083 - Specificity: 0.9738 - Sensitivity: 1.0042 - precision: 0.9019 - recall: 0.8893 - f1score: 0.8932 - val_loss: 0.2620 - val_dice_coef: 0.3096 - val_acc: 0.8093 - val_mean_squared_error: 0.0515 - val_Jaccard_index: 0.2068 - val_Specificity: 0.9514 - val_Sensitivity: 1.0017 - val_precision: 0.4907 - val_recall: 0.3322 - val_f1score: nan\n",
      "Epoch 23/150\n",
      " 5463/13056 [===========>..................] - ETA: 49:51 - loss: -0.2605 - dice_coef: 0.8276 - acc: 0.8395 - mean_squared_error: 0.0098 - Jaccard_index: 0.7122 - Specificity: 0.9740 - Sensitivity: 1.0043 - precision: 0.9046 - recall: 0.8937 - f1score: 0.8970"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-4fdd1e3a4c31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                     validation_steps = nb_validation_samples//batch_size)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=nb_train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = validation_generator,\n",
    "                    validation_steps = nb_validation_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate_generator(validation_generator, steps=50)\n",
    "\n",
    "print ('Validation Score: ', score[0])\n",
    "print ('Validation Accuracy: ',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict_generator(test_generator, verbose=1, steps=nb_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = model.evaluate_generator(test_generator, steps=50)\n",
    "\n",
    "print(model.metrics_names)\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = np.array(history.history['Jaccard_index'])\n",
    "val_coef = np.array(history.history['val_Jaccard_index'])\n",
    "print(\"Training co-effiency    : {};\\nValidation co-effiency : {}\".format(coef[coef==max(coef)][0], val_coef[np.argmax(coef)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "\n",
    "def labelVisualize(num_class,color_dict,img):\n",
    "    img = img[:,:,0] if len(img.shape) == 3 else img\n",
    "    img_out = np.zeros(img.shape + (3,))\n",
    "    for i in range(num_class):\n",
    "        img_out[img == i,:] = color_dict[i]\n",
    "    return img_out / 255\n",
    "\n",
    "def saveResult(save_path,npyfile,flag_multi_class = False,num_class = 2):\n",
    "    for i,item in enumerate(npyfile):\n",
    "        img = labelVisualize(num_class,COLOR_DICT,item) if flag_multi_class else item[:,:,0]\n",
    "        io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
    "\n",
    "os.mkdir('05.U-Net2_results_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveResult('05.U-Net2_results_dir',prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeData(img,mask):\n",
    "    mean = np.mean(img)\n",
    "    std = np.std(img)\n",
    "    img -= mean\n",
    "    img /= std\n",
    "    mask = mask /255\n",
    "    mask[mask > 0.5] = 1\n",
    "    mask[mask <= 0.5] = 0\n",
    "    return (img,mask)\n",
    "\n",
    "test_data_dir= \"data_augmented/cvc300_test/images/\"\n",
    "test_data_mask_dir = \"data_augmented/cvc300_test/masks/\"\n",
    "test_data_pred_dir = \"05.U-Net2_results_dir\"\n",
    "img_rows, img_cols = 256, 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image as image_utils\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img\n",
    "\n",
    "file_names = next(os.walk(test_data_dir))[2]\n",
    "scores = []\n",
    "for file in file_names:\n",
    "    grey_img = load_img(os.path.join(test_data_dir,file), target_size=(img_rows, img_cols), grayscale=False)\n",
    "    mask_img = load_img(os.path.join(test_data_mask_dir,file), target_size=(img_rows, img_cols), grayscale=True)\n",
    "    img = img_to_array(grey_img)\n",
    "    img_mask = img_to_array(mask_img)\n",
    "    \n",
    "    img, img_mask = normalizeData(img, img_mask)\n",
    "    img = np.reshape(img,(1,)+img.shape)\n",
    "    \n",
    "    pred = model.predict([img])\n",
    "    sess = tf.Session()\n",
    "    score = sess.run(Jaccard_index(img_mask, pred))\n",
    "    print(\"{} -- jaccard index: {}\".format(file,score))\n",
    "    scores.append([file,score])\n",
    "\n",
    "    result_img = array_to_img(pred[0] * 255 )\n",
    "    result_img.save(os.path.join(test_data_pred_dir, file.split('.')[0] + '_predict.jpg'))\n",
    "\n",
    "with open(\"unet_test_result.csv\", 'w') as f:\n",
    "    f.write(\"filename, jaccard_index\\n\")\n",
    "    for i in range(len(scores)):\n",
    "        #print(scores[i])\n",
    "        f.write(\"{},{}\\n\".format(scores[i][0], scores[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img=mpimg.imread('05.U-Net2_results_dir/102_predict.png')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(prediction[1]), cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(prediction[1]), cmap = \"gray\", vmin = 0.0, vmax= 0.09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ =  np.squeeze(np.multiply(prediction[1], 255))\n",
    "print(results_)\n",
    "\n",
    "plt.imshow(results_, cmap = \"gray\", vmin = 0.0, vmax= 0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img=mpimg.imread('05.U-Net2_results_dir/35_predict.png')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['dice_coef'])\n",
    "plt.plot(history.history['val_dice_coef'])\n",
    "plt.title('model dice_coeff')\n",
    "plt.ylabel('dice_coef')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
