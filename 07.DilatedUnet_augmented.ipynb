{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 4706087965441977017, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 9214062756\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 5659663521025111709\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras import layers, metrics, models, optimizers\n",
    "from keras.optimizers import Adam, RMSprop,SGD\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, concatenate, Flatten, Dense, Activation, Dropout, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Version 2.2.4\n",
      "tensorflow Version 1.9.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Keras Version\", keras.__version__)\n",
    "print(\"tensorflow Version\", tf.__version__)\n",
    "# print(\"dim_ordering:\", K.image_dim_ordering())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "img_rows, img_cols = 512,512\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data_augmented/cvc300_train/'\n",
    "validation_dir = 'data_augmented/cvc300_validation/'\n",
    "test_dir = 'data_augmented/cvc300_test/'\n",
    "\n",
    "image_folder = 'images'\n",
    "masks_folder = 'masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://github.com/lyakaap/Kaggle-Carvana-3rd-place-solution\n",
    "model.compile(optimizer=RMSprop(lr), loss=bce_dice_loss, metrics=[dice_coef])\n",
    "\"\"\"\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers import Input, add, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "def DilatedUnet(\n",
    "        input_shape=(512, 512, 3),\n",
    "        mode='cascade',\n",
    "        filters=44,\n",
    "        n_block=3,\n",
    "        lr=0.0001,\n",
    "        n_class=1\n",
    "):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    enc, skip = encoder(inputs, filters, n_block)\n",
    "    bottle = bottleneck(enc, filters_bottleneck=filters * 2**n_block, mode=mode)\n",
    "    dec = decoder(bottle, skip, filters, n_block)\n",
    "    classify = Conv2D(n_class, (1, 1), activation='sigmoid')(dec)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=classify)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def encoder(x, filters=44, n_block=3, kernel_size=(3, 3), activation='relu'):\n",
    "    skip = []\n",
    "    for i in range(n_block):\n",
    "        x = Conv2D(filters * 2**i, kernel_size, activation=activation, padding='same')(x)\n",
    "        x = Conv2D(filters * 2**i, kernel_size, activation=activation, padding='same')(x)\n",
    "        skip.append(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "    return x, skip\n",
    "\n",
    "\n",
    "def bottleneck(x, filters_bottleneck, mode='cascade', depth=6,\n",
    "               kernel_size=(3, 3), activation='relu'):\n",
    "    dilated_layers = []\n",
    "    if mode == 'cascade':  # used in the competition\n",
    "        for i in range(depth):\n",
    "            x = Conv2D(filters_bottleneck, kernel_size,\n",
    "                       activation=activation, padding='same', dilation_rate=2**i)(x)\n",
    "            dilated_layers.append(x)\n",
    "        return add(dilated_layers)\n",
    "    elif mode == 'parallel':  # Like \"Atrous Spatial Pyramid Pooling\"\n",
    "        for i in range(depth):\n",
    "            dilated_layers.append(\n",
    "                Conv2D(filters_bottleneck, kernel_size,\n",
    "                       activation=activation, padding='same', dilation_rate=2**i)(x)\n",
    "            )\n",
    "        return add(dilated_layers)\n",
    "\n",
    "\n",
    "def decoder(x, skip, filters, n_block=3, kernel_size=(3, 3), activation='relu'):\n",
    "    for i in reversed(range(n_block)):\n",
    "        x = UpSampling2D(size=(2, 2))(x)\n",
    "        x = Conv2D(filters * 2**i, kernel_size, activation=activation, padding='same')(x)\n",
    "        x = concatenate([skip[i], x])\n",
    "        x = Conv2D(filters * 2**i, kernel_size, activation=activation, padding='same')(x)\n",
    "        x = Conv2D(filters * 2**i, kernel_size, activation=activation, padding='same')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26112 images belonging to 1 classes.\n",
      "Found 26112 images belonging to 1 classes.\n",
      "Found 8704 images belonging to 1 classes.\n",
      "Found 8704 images belonging to 1 classes.\n",
      "Found 28 images belonging to 1 classes.\n",
      "Found 28 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "seed = 1142\n",
    "data_gen_args = dict(rescale=1. / 255, featurewise_center=True, featurewise_std_normalization=True)\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "masks_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "image_generator = image_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    classes = [image_folder],\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "mask_generator = masks_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    classes = [masks_folder],\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "validation_image_generator = image_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    classes = [image_folder],\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "validation_mask_generator = masks_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    classes = [masks_folder],\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "test_image_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    classes = [image_folder],\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "test_mask_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    classes = [masks_folder],\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = zip(image_generator, mask_generator)\n",
    "validation_generator = zip(validation_image_generator, validation_mask_generator)\n",
    "test_generator = zip(test_image_generator, test_mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_train_samples: 26112\n",
      "nb_validation_samples: 8704\n",
      "nb_test_samples: 28\n",
      "\n",
      "predict_size_train: 3264\n",
      "predict_size_validation: 1088\n",
      "predict_size_test: 4\n"
     ]
    }
   ],
   "source": [
    "nb_train_samples = len(image_generator.filenames)\n",
    "nb_validation_samples = len(validation_image_generator.filenames)\n",
    "nb_test_samples = len(test_image_generator.filenames)\n",
    "\n",
    "predict_size_train = int(math.ceil(nb_train_samples / batch_size))\n",
    "predict_size_validation = int(math.ceil(nb_validation_samples / batch_size))\n",
    "predict_size_test = int(math.ceil(nb_test_samples / batch_size))\n",
    "\n",
    "print(\"nb_train_samples:\", nb_train_samples)\n",
    "print(\"nb_validation_samples:\", nb_validation_samples)\n",
    "print(\"nb_test_samples:\", nb_test_samples)\n",
    "\n",
    "print(\"\\npredict_size_train:\", predict_size_train)\n",
    "print(\"predict_size_validation:\", predict_size_validation)\n",
    "print(\"predict_size_test:\", predict_size_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 1.\n",
    "from keras import backend as K\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def Specificity(y_true, y_pred):\n",
    "    true_negatives = K.abs(y_pred)- K.abs(y_true)\n",
    "    return ((true_negatives+smooth)/(y_pred+ smooth))\n",
    "\n",
    "def Sensitivity(y_true, y_pred):\n",
    "    y_true = K.flatten(y_true)\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    return ((y_pred+smooth)/ (y_true+smooth))\n",
    "\n",
    "def Jaccard_index(y_true,y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return ((intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + smooth))\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "    Only computes a batch-wise average of precision.\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "    Only computes a batch-wise average of recall.\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def f1score(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "        Only computes a batch-wise average of recall.\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "        Only computes a batch-wise average of precision.\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 512, 512, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 512, 512, 44) 1232        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 512, 512, 44) 17468       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 256, 256, 44) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 256, 256, 88) 34936       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 256, 256, 88) 69784       conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 128, 128, 88) 0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 176 139568      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 128, 128, 176 278960      conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 64, 64, 176)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 352)  557920      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 352)  1115488     conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 64, 64, 352)  1115488     conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 352)  1115488     conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 352)  1115488     conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 352)  1115488     conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 352)  0           conv2d_7[0][0]                   \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 352 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 128, 128, 176 557744      up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 128, 352 0           conv2d_6[0][0]                   \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 128, 128, 176 557744      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 128, 176 278960      conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 256, 256, 176 0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 256, 256, 88) 139480      up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256, 256, 176 0           conv2d_4[0][0]                   \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 256, 256, 88) 139480      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 256, 256, 88) 69784       conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 512, 512, 88) 0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 512, 512, 44) 34892       up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 512, 512, 88) 0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 512, 512, 44) 34892       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 512, 512, 44) 17468       conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 512, 512, 1)  45          conv2d_21[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 8,507,797\n",
      "Trainable params: 8,507,797\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = DilatedUnet()\n",
    "model.summary()\n",
    "adam_opt = Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(optimizer= adam_opt, loss=dice_coef_loss, \n",
    "              metrics=[dice_coef, 'acc','mse', Jaccard_index, Specificity, Sensitivity, precision, recall, f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3264/3264 [==============================] - 2658s 814ms/step - loss: -0.3538 - dice_coef: 0.3538 - acc: 0.7562 - mean_squared_error: 0.0873 - Jaccard_index: 0.2250 - Specificity: 0.9652 - Sensitivity: 1.0702 - precision: 0.3567 - recall: 0.4874 - f1score: nan - val_loss: -0.5120 - val_dice_coef: 0.5120 - val_acc: 0.8144 - val_mean_squared_error: 0.0398 - val_Jaccard_index: 0.3501 - val_Specificity: 0.9562 - val_Sensitivity: 0.9986 - val_precision: 0.6786 - val_recall: 0.4717 - val_f1score: 0.5471\n",
      "Epoch 2/50\n",
      "3264/3264 [==============================] - 2641s 809ms/step - loss: -0.6306 - dice_coef: 0.6306 - acc: 0.8250 - mean_squared_error: 0.0266 - Jaccard_index: 0.4682 - Specificity: 0.9684 - Sensitivity: 1.0056 - precision: 0.7323 - recall: 0.6469 - f1score: 0.6771 - val_loss: -0.6436 - val_dice_coef: 0.6436 - val_acc: 0.8194 - val_mean_squared_error: 0.0299 - val_Jaccard_index: 0.4833 - val_Specificity: 0.9608 - val_Sensitivity: 1.0021 - val_precision: 0.7692 - val_recall: 0.6463 - val_f1score: 0.6926\n",
      "Epoch 3/50\n",
      "3264/3264 [==============================] - 2639s 809ms/step - loss: -0.7452 - dice_coef: 0.7452 - acc: 0.8321 - mean_squared_error: 0.0165 - Jaccard_index: 0.5985 - Specificity: 0.9709 - Sensitivity: 1.0026 - precision: 0.8596 - recall: 0.7617 - f1score: 0.8022 - val_loss: -0.6830 - val_dice_coef: 0.6830 - val_acc: 0.8250 - val_mean_squared_error: 0.0237 - val_Jaccard_index: 0.5291 - val_Specificity: 0.9606 - val_Sensitivity: 0.9950 - val_precision: 0.8890 - val_recall: 0.6384 - val_f1score: 0.7323\n",
      "Epoch 4/50\n",
      "3264/3264 [==============================] - 2643s 810ms/step - loss: -0.8061 - dice_coef: 0.8061 - acc: 0.8349 - mean_squared_error: 0.0115 - Jaccard_index: 0.6779 - Specificity: 0.9727 - Sensitivity: 1.0027 - precision: 0.9064 - recall: 0.8389 - f1score: 0.8689 - val_loss: -0.7226 - val_dice_coef: 0.7226 - val_acc: 0.8260 - val_mean_squared_error: 0.0211 - val_Jaccard_index: 0.5769 - val_Specificity: 0.9623 - val_Sensitivity: 0.9972 - val_precision: 0.8939 - val_recall: 0.7017 - val_f1score: 0.7761\n",
      "Epoch 5/50\n",
      "3264/3264 [==============================] - 2644s 810ms/step - loss: -0.8370 - dice_coef: 0.8370 - acc: 0.8364 - mean_squared_error: 0.0089 - Jaccard_index: 0.7220 - Specificity: 0.9736 - Sensitivity: 1.0029 - precision: 0.9287 - recall: 0.8819 - f1score: 0.9033 - val_loss: -0.7351 - val_dice_coef: 0.7351 - val_acc: 0.8269 - val_mean_squared_error: 0.0198 - val_Jaccard_index: 0.5908 - val_Specificity: 0.9624 - val_Sensitivity: 0.9962 - val_precision: 0.9170 - val_recall: 0.7058 - val_f1score: 0.7888\n",
      "Epoch 6/50\n",
      "3264/3264 [==============================] - 2644s 810ms/step - loss: -0.8556 - dice_coef: 0.8556 - acc: 0.8372 - mean_squared_error: 0.0075 - Jaccard_index: 0.7497 - Specificity: 0.9742 - Sensitivity: 1.0029 - precision: 0.9422 - recall: 0.9079 - f1score: 0.9238 - val_loss: -0.7539 - val_dice_coef: 0.7539 - val_acc: 0.8273 - val_mean_squared_error: 0.0184 - val_Jaccard_index: 0.6143 - val_Specificity: 0.9633 - val_Sensitivity: 0.9975 - val_precision: 0.9195 - val_recall: 0.7374 - val_f1score: 0.8102\n",
      "Epoch 7/50\n",
      "3264/3264 [==============================] - 2644s 810ms/step - loss: -0.8677 - dice_coef: 0.8677 - acc: 0.8378 - mean_squared_error: 0.0065 - Jaccard_index: 0.7681 - Specificity: 0.9745 - Sensitivity: 1.0029 - precision: 0.9513 - recall: 0.9249 - f1score: 0.9374 - val_loss: -0.7580 - val_dice_coef: 0.7580 - val_acc: 0.8267 - val_mean_squared_error: 0.0186 - val_Jaccard_index: 0.6201 - val_Specificity: 0.9639 - val_Sensitivity: 0.9993 - val_precision: 0.9004 - val_recall: 0.7613 - val_f1score: 0.8167\n",
      "Epoch 8/50\n",
      "3264/3264 [==============================] - 2644s 810ms/step - loss: -0.8744 - dice_coef: 0.8744 - acc: 0.8382 - mean_squared_error: 0.0059 - Jaccard_index: 0.7788 - Specificity: 0.9748 - Sensitivity: 1.0030 - precision: 0.9563 - recall: 0.9351 - f1score: 0.9451 - val_loss: -0.7663 - val_dice_coef: 0.7663 - val_acc: 0.8273 - val_mean_squared_error: 0.0179 - val_Jaccard_index: 0.6302 - val_Specificity: 0.9639 - val_Sensitivity: 0.9985 - val_precision: 0.9150 - val_recall: 0.7636 - val_f1score: 0.8242\n",
      "Epoch 9/50\n",
      "3264/3264 [==============================] - 2646s 811ms/step - loss: -0.8812 - dice_coef: 0.8812 - acc: 0.8385 - mean_squared_error: 0.0053 - Jaccard_index: 0.7894 - Specificity: 0.9749 - Sensitivity: 1.0029 - precision: 0.9620 - recall: 0.9442 - f1score: 0.9527 - val_loss: -0.7562 - val_dice_coef: 0.7562 - val_acc: 0.8276 - val_mean_squared_error: 0.0183 - val_Jaccard_index: 0.6193 - val_Specificity: 0.9632 - val_Sensitivity: 0.9969 - val_precision: 0.9277 - val_recall: 0.7406 - val_f1score: 0.8130\n",
      "Epoch 10/50\n",
      "3264/3264 [==============================] - 2645s 810ms/step - loss: -0.8857 - dice_coef: 0.8857 - acc: 0.8387 - mean_squared_error: 0.0050 - Jaccard_index: 0.7966 - Specificity: 0.9751 - Sensitivity: 1.0029 - precision: 0.9659 - recall: 0.9504 - f1score: 0.9578 - val_loss: -0.7692 - val_dice_coef: 0.7692 - val_acc: 0.8275 - val_mean_squared_error: 0.0176 - val_Jaccard_index: 0.6337 - val_Specificity: 0.9640 - val_Sensitivity: 0.9986 - val_precision: 0.9172 - val_recall: 0.7686 - val_f1score: 0.8282\n",
      "Epoch 11/50\n",
      "3264/3264 [==============================] - 2645s 810ms/step - loss: -0.8889 - dice_coef: 0.8889 - acc: 0.8389 - mean_squared_error: 0.0047 - Jaccard_index: 0.8017 - Specificity: 0.9752 - Sensitivity: 1.0029 - precision: 0.9686 - recall: 0.9547 - f1score: 0.9614 - val_loss: -0.7546 - val_dice_coef: 0.7546 - val_acc: 0.8281 - val_mean_squared_error: 0.0182 - val_Jaccard_index: 0.6163 - val_Specificity: 0.9628 - val_Sensitivity: 0.9957 - val_precision: 0.9416 - val_recall: 0.7261 - val_f1score: 0.8106\n",
      "Epoch 12/50\n",
      "3264/3264 [==============================] - 2643s 810ms/step - loss: -0.8915 - dice_coef: 0.8915 - acc: 0.8390 - mean_squared_error: 0.0045 - Jaccard_index: 0.8060 - Specificity: 0.9752 - Sensitivity: 1.0029 - precision: 0.9709 - recall: 0.9583 - f1score: 0.9643 - val_loss: -0.7722 - val_dice_coef: 0.7722 - val_acc: 0.8281 - val_mean_squared_error: 0.0172 - val_Jaccard_index: 0.6384 - val_Specificity: 0.9638 - val_Sensitivity: 0.9975 - val_precision: 0.9334 - val_recall: 0.7615 - val_f1score: 0.8301\n",
      "Epoch 13/50\n",
      "3264/3264 [==============================] - 2662s 816ms/step - loss: -0.8941 - dice_coef: 0.8941 - acc: 0.8392 - mean_squared_error: 0.0042 - Jaccard_index: 0.8104 - Specificity: 0.9753 - Sensitivity: 1.0028 - precision: 0.9738 - recall: 0.9618 - f1score: 0.9676 - val_loss: -0.7510 - val_dice_coef: 0.7510 - val_acc: 0.8283 - val_mean_squared_error: 0.0184 - val_Jaccard_index: 0.6119 - val_Specificity: 0.9625 - val_Sensitivity: 0.9948 - val_precision: 0.9522 - val_recall: 0.7124 - val_f1score: 0.8053\n",
      "Epoch 14/50\n",
      "3264/3264 [==============================] - 2661s 815ms/step - loss: -0.8967 - dice_coef: 0.8967 - acc: 0.8393 - mean_squared_error: 0.0040 - Jaccard_index: 0.8146 - Specificity: 0.9754 - Sensitivity: 1.0028 - precision: 0.9761 - recall: 0.9648 - f1score: 0.9703 - val_loss: -0.7705 - val_dice_coef: 0.7705 - val_acc: 0.8282 - val_mean_squared_error: 0.0172 - val_Jaccard_index: 0.6374 - val_Specificity: 0.9638 - val_Sensitivity: 0.9974 - val_precision: 0.9339 - val_recall: 0.7614 - val_f1score: 0.8291\n",
      "Epoch 15/50\n",
      "3264/3264 [==============================] - 2660s 815ms/step - loss: -0.8985 - dice_coef: 0.8985 - acc: 0.8394 - mean_squared_error: 0.0039 - Jaccard_index: 0.8174 - Specificity: 0.9754 - Sensitivity: 1.0028 - precision: 0.9775 - recall: 0.9668 - f1score: 0.9720 - val_loss: -0.7697 - val_dice_coef: 0.7697 - val_acc: 0.8283 - val_mean_squared_error: 0.0172 - val_Jaccard_index: 0.6359 - val_Specificity: 0.9636 - val_Sensitivity: 0.9970 - val_precision: 0.9386 - val_recall: 0.7547 - val_f1score: 0.8276\n",
      "Epoch 16/50\n",
      "3264/3264 [==============================] - 2660s 815ms/step - loss: -0.9002 - dice_coef: 0.9002 - acc: 0.8395 - mean_squared_error: 0.0037 - Jaccard_index: 0.8202 - Specificity: 0.9755 - Sensitivity: 1.0028 - precision: 0.9793 - recall: 0.9691 - f1score: 0.9740 - val_loss: -0.7692 - val_dice_coef: 0.7692 - val_acc: 0.8279 - val_mean_squared_error: 0.0174 - val_Jaccard_index: 0.6365 - val_Specificity: 0.9638 - val_Sensitivity: 0.9979 - val_precision: 0.9276 - val_recall: 0.7651 - val_f1score: 0.8280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50\n",
      "3264/3264 [==============================] - 2659s 815ms/step - loss: -0.9010 - dice_coef: 0.9010 - acc: 0.8395 - mean_squared_error: 0.0037 - Jaccard_index: 0.8215 - Specificity: 0.9755 - Sensitivity: 1.0028 - precision: 0.9802 - recall: 0.9702 - f1score: 0.9750 - val_loss: -0.7748 - val_dice_coef: 0.7748 - val_acc: 0.8273 - val_mean_squared_error: 0.0175 - val_Jaccard_index: 0.6417 - val_Specificity: 0.9645 - val_Sensitivity: 0.9999 - val_precision: 0.9077 - val_recall: 0.7876 - val_f1score: 0.8351\n",
      "Epoch 18/50\n",
      "3264/3264 [==============================] - 2658s 814ms/step - loss: -0.9021 - dice_coef: 0.9021 - acc: 0.8396 - mean_squared_error: 0.0035 - Jaccard_index: 0.8234 - Specificity: 0.9755 - Sensitivity: 1.0027 - precision: 0.9813 - recall: 0.9715 - f1score: 0.9763 - val_loss: -0.7697 - val_dice_coef: 0.7697 - val_acc: 0.8280 - val_mean_squared_error: 0.0174 - val_Jaccard_index: 0.6360 - val_Specificity: 0.9637 - val_Sensitivity: 0.9974 - val_precision: 0.9329 - val_recall: 0.7609 - val_f1score: 0.8286\n",
      "Epoch 19/50\n",
      "3264/3264 [==============================] - 2658s 814ms/step - loss: -0.9029 - dice_coef: 0.9029 - acc: 0.8396 - mean_squared_error: 0.0035 - Jaccard_index: 0.8249 - Specificity: 0.9755 - Sensitivity: 1.0027 - precision: 0.9823 - recall: 0.9727 - f1score: 0.9773 - val_loss: -0.7668 - val_dice_coef: 0.7668 - val_acc: 0.8282 - val_mean_squared_error: 0.0175 - val_Jaccard_index: 0.6318 - val_Specificity: 0.9634 - val_Sensitivity: 0.9967 - val_precision: 0.9394 - val_recall: 0.7503 - val_f1score: 0.8250\n",
      "Epoch 20/50\n",
      "3264/3264 [==============================] - 2658s 814ms/step - loss: -0.9031 - dice_coef: 0.9031 - acc: 0.8397 - mean_squared_error: 0.0034 - Jaccard_index: 0.8251 - Specificity: 0.9755 - Sensitivity: 1.0027 - precision: 0.9825 - recall: 0.9732 - f1score: 0.9777 - val_loss: -0.7741 - val_dice_coef: 0.7741 - val_acc: 0.8281 - val_mean_squared_error: 0.0171 - val_Jaccard_index: 0.6414 - val_Specificity: 0.9640 - val_Sensitivity: 0.9979 - val_precision: 0.9306 - val_recall: 0.7699 - val_f1score: 0.8333\n",
      "Epoch 21/50\n",
      "3264/3264 [==============================] - 2648s 811ms/step - loss: -0.9049 - dice_coef: 0.9049 - acc: 0.8397 - mean_squared_error: 0.0033 - Jaccard_index: 0.8281 - Specificity: 0.9756 - Sensitivity: 1.0027 - precision: 0.9839 - recall: 0.9748 - f1score: 0.9792 - val_loss: -0.7714 - val_dice_coef: 0.7714 - val_acc: 0.8281 - val_mean_squared_error: 0.0173 - val_Jaccard_index: 0.6384 - val_Specificity: 0.9638 - val_Sensitivity: 0.9975 - val_precision: 0.9332 - val_recall: 0.7626 - val_f1score: 0.8302\n",
      "Epoch 22/50\n",
      "3264/3264 [==============================] - 2635s 807ms/step - loss: -0.9041 - dice_coef: 0.9041 - acc: 0.8397 - mean_squared_error: 0.0034 - Jaccard_index: 0.8269 - Specificity: 0.9756 - Sensitivity: 1.0027 - precision: 0.9830 - recall: 0.9740 - f1score: 0.9783 - val_loss: -0.7732 - val_dice_coef: 0.7732 - val_acc: 0.8283 - val_mean_squared_error: 0.0170 - val_Jaccard_index: 0.6403 - val_Specificity: 0.9638 - val_Sensitivity: 0.9972 - val_precision: 0.9391 - val_recall: 0.7625 - val_f1score: 0.8324\n",
      "Epoch 23/50\n",
      "3264/3264 [==============================] - 2628s 805ms/step - loss: -0.9065 - dice_coef: 0.9065 - acc: 0.8398 - mean_squared_error: 0.0032 - Jaccard_index: 0.8308 - Specificity: 0.9756 - Sensitivity: 1.0027 - precision: 0.9855 - recall: 0.9771 - f1score: 0.9812 - val_loss: -0.7738 - val_dice_coef: 0.7738 - val_acc: 0.8277 - val_mean_squared_error: 0.0173 - val_Jaccard_index: 0.6416 - val_Specificity: 0.9642 - val_Sensitivity: 0.9987 - val_precision: 0.9212 - val_recall: 0.7775 - val_f1score: 0.8340\n",
      "Epoch 24/50\n",
      "3264/3264 [==============================] - 2624s 804ms/step - loss: -0.9064 - dice_coef: 0.9064 - acc: 0.8398 - mean_squared_error: 0.0032 - Jaccard_index: 0.8307 - Specificity: 0.9756 - Sensitivity: 1.0027 - precision: 0.9854 - recall: 0.9768 - f1score: 0.9810 - val_loss: -0.7738 - val_dice_coef: 0.7738 - val_acc: 0.8280 - val_mean_squared_error: 0.0172 - val_Jaccard_index: 0.6409 - val_Specificity: 0.9640 - val_Sensitivity: 0.9981 - val_precision: 0.9290 - val_recall: 0.7717 - val_f1score: 0.8340\n",
      "Epoch 25/50\n",
      "3264/3264 [==============================] - 2623s 804ms/step - loss: -0.9065 - dice_coef: 0.9065 - acc: 0.8398 - mean_squared_error: 0.0032 - Jaccard_index: 0.8307 - Specificity: 0.9756 - Sensitivity: 1.0027 - precision: 0.9856 - recall: 0.9772 - f1score: 0.9813 - val_loss: -0.7779 - val_dice_coef: 0.7779 - val_acc: 0.8282 - val_mean_squared_error: 0.0170 - val_Jaccard_index: 0.6454 - val_Specificity: 0.9640 - val_Sensitivity: 0.9979 - val_precision: 0.9316 - val_recall: 0.7745 - val_f1score: 0.8374\n",
      "Epoch 26/50\n",
      "3264/3264 [==============================] - 2628s 805ms/step - loss: -0.9073 - dice_coef: 0.9073 - acc: 0.8398 - mean_squared_error: 0.0031 - Jaccard_index: 0.8321 - Specificity: 0.9756 - Sensitivity: 1.0027 - precision: 0.9862 - recall: 0.9778 - f1score: 0.9819 - val_loss: -0.7682 - val_dice_coef: 0.7682 - val_acc: 0.8281 - val_mean_squared_error: 0.0175 - val_Jaccard_index: 0.6337 - val_Specificity: 0.9635 - val_Sensitivity: 0.9969 - val_precision: 0.9376 - val_recall: 0.7541 - val_f1score: 0.8265\n",
      "Epoch 27/50\n",
      "3264/3264 [==============================] - 2630s 806ms/step - loss: -0.9075 - dice_coef: 0.9075 - acc: 0.8399 - mean_squared_error: 0.0031 - Jaccard_index: 0.8324 - Specificity: 0.9757 - Sensitivity: 1.0027 - precision: 0.9863 - recall: 0.9785 - f1score: 0.9823 - val_loss: -0.7724 - val_dice_coef: 0.7724 - val_acc: 0.8280 - val_mean_squared_error: 0.0173 - val_Jaccard_index: 0.6390 - val_Specificity: 0.9638 - val_Sensitivity: 0.9977 - val_precision: 0.9318 - val_recall: 0.7665 - val_f1score: 0.8318\n",
      "Epoch 28/50\n",
      "3264/3264 [==============================] - 2629s 806ms/step - loss: -0.9081 - dice_coef: 0.9081 - acc: 0.8399 - mean_squared_error: 0.0030 - Jaccard_index: 0.8334 - Specificity: 0.9757 - Sensitivity: 1.0027 - precision: 0.9870 - recall: 0.9795 - f1score: 0.9832 - val_loss: -0.7756 - val_dice_coef: 0.7756 - val_acc: 0.8275 - val_mean_squared_error: 0.0175 - val_Jaccard_index: 0.6424 - val_Specificity: 0.9643 - val_Sensitivity: 0.9992 - val_precision: 0.9151 - val_recall: 0.7831 - val_f1score: 0.8360\n",
      "Epoch 29/50\n",
      "3264/3264 [==============================] - 2630s 806ms/step - loss: -0.9086 - dice_coef: 0.9086 - acc: 0.8399 - mean_squared_error: 0.0030 - Jaccard_index: 0.8343 - Specificity: 0.9757 - Sensitivity: 1.0027 - precision: 0.9871 - recall: 0.9801 - f1score: 0.9835 - val_loss: -0.7710 - val_dice_coef: 0.7710 - val_acc: 0.8279 - val_mean_squared_error: 0.0174 - val_Jaccard_index: 0.6373 - val_Specificity: 0.9639 - val_Sensitivity: 0.9980 - val_precision: 0.9276 - val_recall: 0.7677 - val_f1score: 0.8309\n",
      "Epoch 30/50\n",
      "3264/3264 [==============================] - 2629s 805ms/step - loss: -0.9090 - dice_coef: 0.9090 - acc: 0.8399 - mean_squared_error: 0.0030 - Jaccard_index: 0.8350 - Specificity: 0.9757 - Sensitivity: 1.0027 - precision: 0.9874 - recall: 0.9807 - f1score: 0.9840 - val_loss: -0.7731 - val_dice_coef: 0.7731 - val_acc: 0.8280 - val_mean_squared_error: 0.0173 - val_Jaccard_index: 0.6396 - val_Specificity: 0.9639 - val_Sensitivity: 0.9980 - val_precision: 0.9281 - val_recall: 0.7700 - val_f1score: 0.8331\n",
      "Epoch 31/50\n",
      "3264/3264 [==============================] - 2629s 806ms/step - loss: -0.9093 - dice_coef: 0.9093 - acc: 0.8399 - mean_squared_error: 0.0029 - Jaccard_index: 0.8355 - Specificity: 0.9757 - Sensitivity: 1.0027 - precision: 0.9878 - recall: 0.9811 - f1score: 0.9844 - val_loss: -0.7768 - val_dice_coef: 0.7768 - val_acc: 0.8280 - val_mean_squared_error: 0.0171 - val_Jaccard_index: 0.6455 - val_Specificity: 0.9642 - val_Sensitivity: 0.9985 - val_precision: 0.9261 - val_recall: 0.7794 - val_f1score: 0.8373\n",
      "Epoch 32/50\n",
      "3264/3264 [==============================] - 2629s 806ms/step - loss: -0.9097 - dice_coef: 0.9097 - acc: 0.8400 - mean_squared_error: 0.0029 - Jaccard_index: 0.8362 - Specificity: 0.9757 - Sensitivity: 1.0027 - precision: 0.9879 - recall: 0.9816 - f1score: 0.9847 - val_loss: -0.7727 - val_dice_coef: 0.7727 - val_acc: 0.8277 - val_mean_squared_error: 0.0175 - val_Jaccard_index: 0.6390 - val_Specificity: 0.9640 - val_Sensitivity: 0.9983 - val_precision: 0.9239 - val_recall: 0.7731 - val_f1score: 0.8328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "3264/3264 [==============================] - 2629s 806ms/step - loss: -0.9100 - dice_coef: 0.9100 - acc: 0.8400 - mean_squared_error: 0.0029 - Jaccard_index: 0.8366 - Specificity: 0.9757 - Sensitivity: 1.0027 - precision: 0.9882 - recall: 0.9819 - f1score: 0.9850 - val_loss: -0.7726 - val_dice_coef: 0.7726 - val_acc: 0.8281 - val_mean_squared_error: 0.0172 - val_Jaccard_index: 0.6402 - val_Specificity: 0.9638 - val_Sensitivity: 0.9976 - val_precision: 0.9331 - val_recall: 0.7657 - val_f1score: 0.8318\n",
      "Epoch 34/50\n",
      "3264/3264 [==============================] - 2623s 804ms/step - loss: -0.9101 - dice_coef: 0.9101 - acc: 0.8400 - mean_squared_error: 0.0029 - Jaccard_index: 0.8370 - Specificity: 0.9757 - Sensitivity: 1.0027 - precision: 0.9884 - recall: 0.9824 - f1score: 0.9854 - val_loss: -0.7667 - val_dice_coef: 0.7667 - val_acc: 0.8280 - val_mean_squared_error: 0.0177 - val_Jaccard_index: 0.6316 - val_Specificity: 0.9635 - val_Sensitivity: 0.9971 - val_precision: 0.9351 - val_recall: 0.7530 - val_f1score: 0.8252\n",
      "Epoch 35/50\n",
      "3264/3264 [==============================] - 2627s 805ms/step - loss: -0.9103 - dice_coef: 0.9103 - acc: 0.8400 - mean_squared_error: 0.0028 - Jaccard_index: 0.8371 - Specificity: 0.9757 - Sensitivity: 1.0027 - precision: 0.9887 - recall: 0.9825 - f1score: 0.9856 - val_loss: -0.7691 - val_dice_coef: 0.7691 - val_acc: 0.8281 - val_mean_squared_error: 0.0174 - val_Jaccard_index: 0.6359 - val_Specificity: 0.9637 - val_Sensitivity: 0.9974 - val_precision: 0.9337 - val_recall: 0.7608 - val_f1score: 0.8283\n",
      "Epoch 36/50\n",
      "3264/3264 [==============================] - 2627s 805ms/step - loss: -0.9105 - dice_coef: 0.9105 - acc: 0.8400 - mean_squared_error: 0.0028 - Jaccard_index: 0.8374 - Specificity: 0.9757 - Sensitivity: 1.0027 - precision: 0.9889 - recall: 0.9828 - f1score: 0.9858 - val_loss: -0.7739 - val_dice_coef: 0.7739 - val_acc: 0.8280 - val_mean_squared_error: 0.0172 - val_Jaccard_index: 0.6416 - val_Specificity: 0.9640 - val_Sensitivity: 0.9980 - val_precision: 0.9291 - val_recall: 0.7718 - val_f1score: 0.8339\n",
      "Epoch 37/50\n",
      "3264/3264 [==============================] - 2626s 804ms/step - loss: -0.9108 - dice_coef: 0.9108 - acc: 0.8400 - mean_squared_error: 0.0028 - Jaccard_index: 0.8381 - Specificity: 0.9757 - Sensitivity: 1.0027 - precision: 0.9891 - recall: 0.9830 - f1score: 0.9860 - val_loss: -0.7724 - val_dice_coef: 0.7724 - val_acc: 0.8282 - val_mean_squared_error: 0.0172 - val_Jaccard_index: 0.6402 - val_Specificity: 0.9637 - val_Sensitivity: 0.9972 - val_precision: 0.9371 - val_recall: 0.7636 - val_f1score: 0.8317\n",
      "Epoch 38/50\n",
      "3264/3264 [==============================] - 2625s 804ms/step - loss: -0.9110 - dice_coef: 0.9110 - acc: 0.8400 - mean_squared_error: 0.0028 - Jaccard_index: 0.8383 - Specificity: 0.9758 - Sensitivity: 1.0027 - precision: 0.9892 - recall: 0.9832 - f1score: 0.9862 - val_loss: -0.7739 - val_dice_coef: 0.7739 - val_acc: 0.8275 - val_mean_squared_error: 0.0174 - val_Jaccard_index: 0.6409 - val_Specificity: 0.9643 - val_Sensitivity: 0.9992 - val_precision: 0.9161 - val_recall: 0.7817 - val_f1score: 0.8345\n",
      "Epoch 39/50\n",
      "3264/3264 [==============================] - 2625s 804ms/step - loss: -0.9111 - dice_coef: 0.9111 - acc: 0.8400 - mean_squared_error: 0.0028 - Jaccard_index: 0.8386 - Specificity: 0.9758 - Sensitivity: 1.0027 - precision: 0.9893 - recall: 0.9833 - f1score: 0.9862 - val_loss: -0.7742 - val_dice_coef: 0.7742 - val_acc: 0.8282 - val_mean_squared_error: 0.0171 - val_Jaccard_index: 0.6421 - val_Specificity: 0.9639 - val_Sensitivity: 0.9976 - val_precision: 0.9353 - val_recall: 0.7680 - val_f1score: 0.8343\n",
      "Epoch 40/50\n",
      "3264/3264 [==============================] - 2624s 804ms/step - loss: -0.9111 - dice_coef: 0.9111 - acc: 0.8400 - mean_squared_error: 0.0028 - Jaccard_index: 0.8386 - Specificity: 0.9758 - Sensitivity: 1.0026 - precision: 0.9896 - recall: 0.9838 - f1score: 0.9866 - val_loss: -0.7745 - val_dice_coef: 0.7745 - val_acc: 0.8277 - val_mean_squared_error: 0.0175 - val_Jaccard_index: 0.6425 - val_Specificity: 0.9641 - val_Sensitivity: 0.9987 - val_precision: 0.9201 - val_recall: 0.7785 - val_f1score: 0.8341\n",
      "Epoch 41/50\n",
      "3264/3264 [==============================] - 2624s 804ms/step - loss: -0.9114 - dice_coef: 0.9114 - acc: 0.8400 - mean_squared_error: 0.0027 - Jaccard_index: 0.8390 - Specificity: 0.9758 - Sensitivity: 1.0027 - precision: 0.9895 - recall: 0.9843 - f1score: 0.9869 - val_loss: -0.7748 - val_dice_coef: 0.7748 - val_acc: 0.8279 - val_mean_squared_error: 0.0172 - val_Jaccard_index: 0.6417 - val_Specificity: 0.9641 - val_Sensitivity: 0.9985 - val_precision: 0.9238 - val_recall: 0.7764 - val_f1score: 0.8355\n",
      "Epoch 42/50\n",
      "3264/3264 [==============================] - 2623s 804ms/step - loss: -0.9118 - dice_coef: 0.9118 - acc: 0.8401 - mean_squared_error: 0.0027 - Jaccard_index: 0.8396 - Specificity: 0.9758 - Sensitivity: 1.0027 - precision: 0.9898 - recall: 0.9846 - f1score: 0.9871 - val_loss: -0.7731 - val_dice_coef: 0.7731 - val_acc: 0.8281 - val_mean_squared_error: 0.0173 - val_Jaccard_index: 0.6399 - val_Specificity: 0.9638 - val_Sensitivity: 0.9977 - val_precision: 0.9321 - val_recall: 0.7666 - val_f1score: 0.8328\n",
      "Epoch 43/50\n",
      "3264/3264 [==============================] - 2623s 804ms/step - loss: -0.9118 - dice_coef: 0.9118 - acc: 0.8401 - mean_squared_error: 0.0027 - Jaccard_index: 0.8398 - Specificity: 0.9758 - Sensitivity: 1.0027 - precision: 0.9899 - recall: 0.9847 - f1score: 0.9872 - val_loss: -0.7731 - val_dice_coef: 0.7731 - val_acc: 0.8280 - val_mean_squared_error: 0.0172 - val_Jaccard_index: 0.6408 - val_Specificity: 0.9639 - val_Sensitivity: 0.9978 - val_precision: 0.9314 - val_recall: 0.7693 - val_f1score: 0.8333\n",
      "Epoch 44/50\n",
      "3264/3264 [==============================] - 2623s 804ms/step - loss: -0.9119 - dice_coef: 0.9119 - acc: 0.8401 - mean_squared_error: 0.0027 - Jaccard_index: 0.8397 - Specificity: 0.9758 - Sensitivity: 1.0027 - precision: 0.9899 - recall: 0.9847 - f1score: 0.9872 - val_loss: -0.7748 - val_dice_coef: 0.7748 - val_acc: 0.8282 - val_mean_squared_error: 0.0171 - val_Jaccard_index: 0.6430 - val_Specificity: 0.9638 - val_Sensitivity: 0.9975 - val_precision: 0.9361 - val_recall: 0.7683 - val_f1score: 0.8347\n",
      "Epoch 45/50\n",
      "3264/3264 [==============================] - 2623s 804ms/step - loss: -0.9123 - dice_coef: 0.9123 - acc: 0.8401 - mean_squared_error: 0.0027 - Jaccard_index: 0.8405 - Specificity: 0.9758 - Sensitivity: 1.0027 - precision: 0.9902 - recall: 0.9851 - f1score: 0.9876 - val_loss: -0.7718 - val_dice_coef: 0.7718 - val_acc: 0.8281 - val_mean_squared_error: 0.0173 - val_Jaccard_index: 0.6391 - val_Specificity: 0.9638 - val_Sensitivity: 0.9975 - val_precision: 0.9337 - val_recall: 0.7634 - val_f1score: 0.8308\n",
      "Epoch 46/50\n",
      "3264/3264 [==============================] - 2638s 808ms/step - loss: -0.9123 - dice_coef: 0.9123 - acc: 0.8401 - mean_squared_error: 0.0027 - Jaccard_index: 0.8404 - Specificity: 0.9758 - Sensitivity: 1.0027 - precision: 0.9903 - recall: 0.9854 - f1score: 0.9878 - val_loss: -0.7748 - val_dice_coef: 0.7748 - val_acc: 0.8282 - val_mean_squared_error: 0.0171 - val_Jaccard_index: 0.6422 - val_Specificity: 0.9639 - val_Sensitivity: 0.9976 - val_precision: 0.9350 - val_recall: 0.7685 - val_f1score: 0.8347\n",
      "Epoch 47/50\n",
      "3264/3264 [==============================] - 2638s 808ms/step - loss: -0.9125 - dice_coef: 0.9125 - acc: 0.8401 - mean_squared_error: 0.0026 - Jaccard_index: 0.8409 - Specificity: 0.9758 - Sensitivity: 1.0027 - precision: 0.9904 - recall: 0.9857 - f1score: 0.9880 - val_loss: -0.7725 - val_dice_coef: 0.7725 - val_acc: 0.8281 - val_mean_squared_error: 0.0173 - val_Jaccard_index: 0.6396 - val_Specificity: 0.9638 - val_Sensitivity: 0.9977 - val_precision: 0.9324 - val_recall: 0.7660 - val_f1score: 0.8320\n",
      "Epoch 48/50\n",
      "3264/3264 [==============================] - 2639s 808ms/step - loss: -0.9125 - dice_coef: 0.9125 - acc: 0.8401 - mean_squared_error: 0.0026 - Jaccard_index: 0.8409 - Specificity: 0.9758 - Sensitivity: 1.0027 - precision: 0.9905 - recall: 0.9859 - f1score: 0.9882 - val_loss: -0.7746 - val_dice_coef: 0.7746 - val_acc: 0.8280 - val_mean_squared_error: 0.0172 - val_Jaccard_index: 0.6417 - val_Specificity: 0.9640 - val_Sensitivity: 0.9982 - val_precision: 0.9277 - val_recall: 0.7743 - val_f1score: 0.8352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "3264/3264 [==============================] - 2639s 808ms/step - loss: -0.9129 - dice_coef: 0.9129 - acc: 0.8401 - mean_squared_error: 0.0026 - Jaccard_index: 0.8415 - Specificity: 0.9758 - Sensitivity: 1.0027 - precision: 0.9906 - recall: 0.9860 - f1score: 0.9883 - val_loss: -0.7689 - val_dice_coef: 0.7689 - val_acc: 0.8282 - val_mean_squared_error: 0.0175 - val_Jaccard_index: 0.6350 - val_Specificity: 0.9635 - val_Sensitivity: 0.9968 - val_precision: 0.9396 - val_recall: 0.7554 - val_f1score: 0.8279\n",
      "Epoch 50/50\n",
      "3264/3264 [==============================] - 2639s 809ms/step - loss: -0.9127 - dice_coef: 0.9127 - acc: 0.8401 - mean_squared_error: 0.0026 - Jaccard_index: 0.8413 - Specificity: 0.9758 - Sensitivity: 1.0027 - precision: 0.9907 - recall: 0.9861 - f1score: 0.9884 - val_loss: -0.7764 - val_dice_coef: 0.7764 - val_acc: 0.8279 - val_mean_squared_error: 0.0172 - val_Jaccard_index: 0.6444 - val_Specificity: 0.9642 - val_Sensitivity: 0.9987 - val_precision: 0.9236 - val_recall: 0.7806 - val_f1score: 0.8372\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=nb_train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = validation_generator,\n",
    "                    validation_steps = nb_validation_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Score:  -0.7849679028987885\n",
      "Validation Accuracy:  0.7849679028987885\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate_generator(validation_generator, steps=50)\n",
    "\n",
    "print ('Validation Score: ', score[0])\n",
    "print ('Validation Accuracy: ',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 7s 246ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict_generator(test_generator, verbose=1, steps=nb_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196, 512, 512, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'dice_coef', 'acc', 'mean_squared_error', 'Jaccard_index', 'Specificity', 'Sensitivity', 'precision', 'recall', 'f1score']\n",
      "[-0.8210394735308899, 0.8210394735308899, 0.9837139611956717, 0.016248789931722414, 0.7092016657878613, 0.9699039459228516, 0.999576981040253, 0.8749787334738106, 0.7907110562269715, 0.8210282692278938]\n"
     ]
    }
   ],
   "source": [
    "test_results = model.evaluate_generator(test_generator, steps=50)\n",
    "\n",
    "print(model.metrics_names)\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = np.array(history.history['Jaccard_index'])\n",
    "val_coef = np.array(history.history['val_Jaccard_index'])\n",
    "print(\"Training co-effiency    : {};\\nValidation co-effiency : {}\".format(coef[coef==max(coef)][0], val_coef[np.argmax(coef)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "\n",
    "def labelVisualize(num_class,color_dict,img):\n",
    "    img = img[:,:,0] if len(img.shape) == 3 else img\n",
    "    img_out = np.zeros(img.shape + (3,))\n",
    "    for i in range(num_class):\n",
    "        img_out[img == i,:] = color_dict[i]\n",
    "    return img_out / 255\n",
    "\n",
    "def saveResult(save_path,npyfile,flag_multi_class = False,num_class = 2):\n",
    "    for i,item in enumerate(npyfile):\n",
    "        img = labelVisualize(num_class,COLOR_DICT,item) if flag_multi_class else item[:,:,0]\n",
    "        io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
    "\n",
    "os.mkdir('05.U-Net2_results_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveResult('05.U-Net2_results_dir',prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeData(img,mask):\n",
    "    mean = np.mean(img)\n",
    "    std = np.std(img)\n",
    "    img -= mean\n",
    "    img /= std\n",
    "    mask = mask /255\n",
    "    mask[mask > 0.5] = 1\n",
    "    mask[mask <= 0.5] = 0\n",
    "    return (img,mask)\n",
    "\n",
    "test_data_dir= \"data_augmented/cvc300_test/images/\"\n",
    "test_data_mask_dir = \"data_augmented/cvc300_test/masks/\"\n",
    "test_data_pred_dir = \"05.U-Net2_results_dir\"\n",
    "img_rows, img_cols = 256, 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image as image_utils\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img\n",
    "\n",
    "file_names = next(os.walk(test_data_dir))[2]\n",
    "scores = []\n",
    "for file in file_names:\n",
    "    grey_img = load_img(os.path.join(test_data_dir,file), target_size=(img_rows, img_cols), grayscale=False)\n",
    "    mask_img = load_img(os.path.join(test_data_mask_dir,file), target_size=(img_rows, img_cols), grayscale=True)\n",
    "    img = img_to_array(grey_img)\n",
    "    img_mask = img_to_array(mask_img)\n",
    "    \n",
    "    img, img_mask = normalizeData(img, img_mask)\n",
    "    img = np.reshape(img,(1,)+img.shape)\n",
    "    \n",
    "    pred = model.predict([img])\n",
    "    sess = tf.Session()\n",
    "    score = sess.run(Jaccard_index(img_mask, pred))\n",
    "    print(\"{} -- jaccard index: {}\".format(file,score))\n",
    "    scores.append([file,score])\n",
    "\n",
    "    result_img = array_to_img(pred[0] * 255 )\n",
    "    result_img.save(os.path.join(test_data_pred_dir, file.split('.')[0] + '_predict.jpg'))\n",
    "\n",
    "with open(\"unet_test_result.csv\", 'w') as f:\n",
    "    f.write(\"filename, jaccard_index\\n\")\n",
    "    for i in range(len(scores)):\n",
    "        #print(scores[i])\n",
    "        f.write(\"{},{}\\n\".format(scores[i][0], scores[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img=mpimg.imread('05.U-Net2_results_dir/102_predict.png')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(prediction[1]), cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(prediction[1]), cmap = \"gray\", vmin = 0.0, vmax= 0.09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ =  np.squeeze(np.multiply(prediction[1], 255))\n",
    "print(results_)\n",
    "\n",
    "plt.imshow(results_, cmap = \"gray\", vmin = 0.0, vmax= 0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img=mpimg.imread('05.U-Net2_results_dir/35_predict.png')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['dice_coef'])\n",
    "plt.plot(history.history['val_dice_coef'])\n",
    "plt.title('model dice_coeff')\n",
    "plt.ylabel('dice_coef')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
